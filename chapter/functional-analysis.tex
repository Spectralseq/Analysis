\chapter{Functional Analysis}
Throughout this chapter, the term vector space will refer to a vector space over the complex field $\C$ or over the real field $\R$. We let $\K$ denote either of these fields.
\section{Hilbert spaces}
\subsection{Basic properties}
Let $H$ be a complex vector space. An inner product (or scalar product) on $H$ is a map $(x,y)\mapsto\langle x,y\rangle$ from $H\times H\to\C$ such that:
\begin{itemize}
\item $\langle ax+by,z\rangle=a\langle x,z\rangle+b\langle y,z\rangle$ for any $x,y,z\in H$ and $a,b\in\C$.
\item $\langle x,y\rangle=\widebar{\langle y,x\rangle}$ for all $x,y\in H$.
\item $\langle x,x\rangle\geq 0$ for $x\in H$, with equality if and only if $x=0$.
\end{itemize}
A complex vector space equipped with an inner product is called a \textbf{pre-Hilbert} space. Note that in the complex case $\langle x,\alpha y\rangle=\widebar{\alpha}\langle x,y\rangle$. In this case we say that the inner product is \textbf{conjugate-linear} in the second argument. Letting $\|x\|=\sqrt{\langle x,x\rangle}$, we obtain a norm on $H$. The triangle inequality after obvious transformations reduces to the Cauchy inequality.
\begin{proposition}[\textbf{Cauchy-Schwarz Inequality}]
Let $H$ be a complex vector space equipped with an inner product. The inner product and norm satisfy the Cauchy-Schwarz inequality
\[\langle x,y\rangle\leq\|x\|\|y\|\]
for $x,y\in H$, with equality if and only if $x$ and $y$ are linearly dependent.
\end{proposition}
\begin{proof}
We observe that
\[0\leq\langle x-ty,x-ty\rangle=\|x\|^2-2t\langle x,y\rangle+t^2\|y\|^2\]
holds for all $t\in\R$. Therefore
\[4|\langle x,y\rangle|^2-4\|x\|^2\|y\|^2\geq 0.\]
This is the desired inequality.
\end{proof}
\begin{corollary}
The function $x\mapsto\|x\|$ is a norm on $H$.
\end{corollary}
\begin{proposition}
The inner product $\langle\cdot\,,\cdot\rangle:H\times H\to\C$ is continuous with respect to the norm topology.
\end{proposition}
\begin{proof}
By the Schwarz inequality,
\[|\langle x_n,y_n\rangle-\langle x,y\rangle|=|\langle x_n,y_n-y\rangle+\langle x_n-x,y\rangle|\leq\|x_n\|\cdot\|y_n-y\|+\|x_n-x\|\cdot\|y\|.\]
Thus if $x_n\to x$ and $y_n\to y$, then $\langle x_n,y_n\rangle\to\langle x,y\rangle$. This implies the claim.
\end{proof}
\begin{proposition}[\textbf{parallelogram law}]
For all $x,y\in H$, we have
\begin{align}\label{parallelogram law}
\|x+y\|^2+\|x-y\|^2=2(\|x\|^2+\|y\|^2).
\end{align}
\end{proposition}
\begin{proof}
Add the two formulas $\|x\pm y\|^2=\|x\|^2+\|y\|^2\pm\Re\langle x,y\rangle$.
\end{proof}
\begin{proposition}[\textbf{Polarization identity}]
Let $x,y\in H$, then
\[\|\langle x,y\rangle=\frac{1}{4}\sum_{k=0}^{3}i^k\|x+i^ky\|^2.\]
\end{proposition}
\begin{proof}
This follows from a direct computation
\[\|x\pm y\|^2=\|x\|^2+\|y\|^2\pm 2\Re\langle x,y\rangle,\]
and
\[\|x\pm iy\|^2=\|x\|^2+\|y\|^2\pm 2\Im\langle x,y\rangle.\]
Therefore the claim follows.
\end{proof}
\begin{definition}
A \textbf{Hilbert space} is a vector space $H$ over $\C$ together with an inner product $\langle\cdot,\cdot\rangle$ such that relative to the metric $d(x,y)=\|x-y\|$ induced by the norm, $H$ is a complete metric space.
\end{definition}
\begin{example}
Let $(X,\mathcal{A},\mu)$ be a measure space, and let $L^2(\mu)$ be the set of all measurable functions $f:X\to\C$ such that $\int|f|^2d\mu<+\infty$. From the inequality $ab\leq(a^2+b^2)/2$, we see that if $f,g\in L^2(\mu)$ then $f+g\in L^2(\mu)$. It follows easily that the formula
\[\langle f,g\rangle=\int f\widebar{g}d\mu\]
defines an inner product on $L^2(\mu)$. In fact, $L^2(\mu)$ is a Hilbert space for any measure $\mu$.\par
An important special case of this construction is obtained by taking $\mu$ to be counting measure on $(A,2^A)$, where $A$ is any nonempty set; in this situation $L^2(\mu)$ is usually denoted by $\ell^2(A)$. Thus, $\ell^2(A)$ is the set of functions $f:A\to\C$ such that the sum $\sum_{\alpha\in A}|f(\alpha)|^2$ is finite, where the sum is defined to be
\[\sum_{\alpha\in A}|f(\alpha)|^2=\sup\{\sum_{\alpha\in E_0}|f(\alpha)|^2:A_0\sub A\text{ is finite}\},\]
in view of our definition of integration.
\end{example}
Suppose $X$ is a vector space with an inner product $\langle\cdot,\cdot\rangle$ and the norm is defined by the inner product. What happens if $(X,d)$ is not complete?
\begin{proposition}
Let $(X,\langle\cdot,\cdot\rangle_X)$ be a inner product space and $H$ be its completion. Then there is an inner product $\langle\cdot,\cdot\rangle_H$ on $H$ such that $\langle x,y\rangle_H=\langle x,y\rangle_X$ for $x,y\in X$ and the metric on $H$ is induced by this inner product. That is, the completion of $X$ is a Hilbert space.
\end{proposition}
\begin{proof}
Consider the collection of all Cauchy sequences $\{x_n\}$ with $x_n\in X$. One defines an equivalence relation in this collection by saying that $\{x_n\}$ is equivalent to $\{y_n\}$ if $\{x_n-y_n\}$ converges to $0$. The collection of equivalence classes is then taken to be $H$. One then easily verifies that $H$ inherits the structure of a vector space, with an inner product $\langle x,y\rangle$ defined as $\lim_n\langle x_n,y_n\rangle$, where $\{x_n\}$ and $\{y_n\}$ are Cauchy sequences in $X$, representing, respectively, the elements $x$ and $y$ in $H$. Next, if $x\in X$ we take the constant sequence $\{x_n=x\}$ to represent $x$ as an element of $H$, giving $X\sub H$. To see that $H$ is complete, let $\{x^{(k)}\}$ be a Cauchy sequence in $H$, with each $x^{(k)}$ represented by $\{x^{(k)}_n\}$, and $x^{(k)}_n\in X$. If we define $x\in H$ as represented by the sequence ffng with $x_n=x^{(n)}_{N(n)}$, where $N(n)$ is so that $|x_{N(n)}^{(n)}-x^{(n)}_k|<1/n$ for $k\geq N(n)$, then we note that $x^{(k)}\to x$ in $H$.
\end{proof}
\begin{example}\label{Bergman space is Banach}
Let $D\sub\C$ be a domain, let $1\leq p<+\infty$, and let $A^p(D)$ be the \textbf{Bergman space} consisting of all holomorphic complex functions $f$ on $D$ such that $f\in L^p(D)$, where $D$ is considered with the usual Lebesgue measure. Then $A^p(D)$ with the norm from $L^p(D)$ is a Banach space, and a Hilbert space with $p=2$.\par
To see this, let $\{f_n\}$ be a Cauchy sequence in $A^p(D)$. Then it converges in $L^p(D)$ to some function $f\in L^p(D)$. However, we have to show that this function $f$ has a version holomorphic in $D$. We show that on every closed disc $K\sub D$ the sequence $\{f_n\}$ converges uniformly. Let us take a closed disc $S\sub D$ with the same center as $K$ and a radius $R>0$ larger than the radius of $K$. The desired convergence follows from the following estimate for every function $f\in A^p(D)$ and $z_0\in K$:
\begin{align}\label{Bergman space is Banach-1}
|f(z_0)|\leq\pi^{-1/p}R^{-2/p}\|f\|_{L^p(D)}.
\end{align}
This estimate is deduced from the Cauchy formula
\[f(z_0)=\frac{1}{2\pi i}\int_{\partial_r}\frac{f(\zeta)}{\zeta-z_0}\dif\zeta,\]
where $\gamma_r$ is the circumference of radius $r\leq R$ centered at $z_0$. Writing this formula in polar coordinates and multiplying both parts by $r>0$, we arrive at the estimate
\[r|f(z_0)|\leq\frac{r}{2\pi}\int_{0}^{2\pi}|f(z_0+re^{i\theta})|\dif\theta.\]
After integration in $r$ from $0$ to $R$ we obtain the inequality
\[R^2|f(z_0)|\leq\frac{1}{\pi}\int_{\partial K}|f(z)|\mathrm{d}x\mathrm{d}y.\]
From this we conlude that
\[|f(z_0)|\leq\frac{1}{\pi R^2}\int_{S}|f(z)|\mathrm{d}x\mathrm{d}y\leq\frac{1}{\pi R^2}\cdot\lambda(K)^{1/q}\|f\|_{L^p(D)}=\pi^{-1/p}R^{-2/p}\|f\|_{L^p(D)}.\]
Since $A^p(D)$ is a subspace in the separable space $L^p(D)$, it is also separable.
\end{example}
Let $X$ be a complex vector space. Not every norm on $X$ can be obtained from an inner product. The simplest example is the following norm on the plane: $\|x\|=\max(|x_1|,|x_2|)$. The points $(1,0)$ and $(-1,-1)$ do not satisfy the parallelogram law:
\[\|x+y\|^2+\|x-y\|^2=\|(0,-1)\|^2+\|(2,1)\|^2=1+4=5\]
while
\[2(\|x\|^2+\|y\|^2)=2(1+1)=4.\]
In fact, the parallelogram law is a sufficient condition for a norm to be generated by an inner product.
\begin{proposition}[\textbf{Jordan-von Neumann}]\label{parallelogram law construct inner product}
Let $X$ be a normed vector space. It the norm of $X$ satisfies the parallelogram law, then it is generated by an inner product.
\end{proposition}
\begin{proof}
If the norm is described by an inner product (as we hope), then it must satisfy
\[\begin{cases}
\Re\langle x,y\rangle=\dfrac{1}{4}(\|x+y\|^2-\|x-y\|^2),\\[8pt]
\langle x,y\rangle=\Re\langle x,y\rangle-i\Re\langle ix,y\rangle.
\end{cases}\]
So we only need to verify the above formula indeed defines an inner product. We need to prove
\begin{itemize}
\item[(\rmnum{1})] $(\alpha x,y)=\alpha(x,y)$ for all $\alpha\in\C$ and $x,y\in X$.
\item[(\rmnum{2})] $(x_1+x_2,y)=(x_1,y)+(x_2,y)$ for all $x_1,x_2,y\in x$.
\item[(\rmnum{3})] $\langle y,x\rangle=\widebar{\langle x,y\rangle}$ for all $x,y\in X$.
\end{itemize}

First we note that by the parallelogram law,
\begin{align*}
\|x_1+y+x_2\|^2+\|x_1+y-x_2\|^2=2(\|x_1+y\|^2+\|y\|^2),\\
\|x_1-y+x_2\|^2+\|x_1-y-x_2\|^2=2(\|x_1-y\|^2+\|y\|^2).
\end{align*}
Substract these two equalities, we get
\begin{equation}\label{parallelogram law construct inner product-1}
\begin{aligned}
&\Re\langle x_1+x_2,y\rangle+\Re\langle x_1-x_2,y\rangle\\
&=\frac{1}{4}(\|x_1+x_2+y\|^2-\|x_1+x_2-y\|^2+\|x_1-x_2+y\|^2-\|x_1-x_2-y\|^2)\\
&=\frac{1}{4}(\|x_1+y+x_2\|^2+\|x_1+y-x_2\|^2-\|x_1-y+x_2\|^2-\|x_1-y-x_2\|^2)\\
&=\frac{1}{2}(\|x_1+y\|^2-\|x_1-y\|^2)=\Re\langle x_1,y\rangle.
\end{aligned}
\end{equation}
Setting $x=0$ in the parallelogram law, we get $\|-y\|^2=\|y\|^2$, and so we get $\Re\langle 0,y\rangle=0$ in the definition. Therefore $(\ref{parallelogram law construct inner product-1})$ with $x_1=x_2=x$ implies $\Re\langle 2x,y\rangle=2\Re\langle x,y\rangle$. In turn this gives
\[\Re\langle x_1+x_2,y\rangle+\Re\langle x_1-x_2,y\rangle=\Re\langle 2x_1,y\rangle\]
or if we repalce $x_1,x_2$ by $(x_1+x_2)/2$ and $(x_1-x_2)/2$,
\[\Re\langle x_1,y\rangle+\Re\langle x_2,y\rangle=\Re\langle x_1+x_2,y\rangle.\]
Now by the definition of $\langle x,y\rangle$, this proves (\rmnum{2}).\par
For (\rmnum{1}), define
\[S=\{\alpha\in\C:\langle\alpha x,y\rangle=\alpha\langle x,y\rangle\text{ for all $x,y\in X$}\}.\]
Clearly $1\in S$, and by (\rmnum{2}) we see
\[\alpha,\beta\in S\Longrightarrow\alpha\pm\beta\in S\text{ and }\alpha/\beta\in S (\beta\neq 0),\]
so it follows immediately that $\Q\sub S$. Note that $\Re\langle\alpha x,y\rangle$ and $\langle\alpha x,y\rangle$ is continuous in $\alpha$: in fact, by triangle inequality, $\|\alpha x\pm y\|$ is continuous in $\alpha$, so this implies $\R\in S$. Now, since $-1\in S$, we see
\[\langle ix,y\rangle=\Re\langle ix,y\rangle-i\Re\langle(i)^2 x,y\rangle=\Re\langle ix,y\rangle+i\Re\langle x,y\rangle=i(\Re\langle x,y\rangle-i\Re\langle ix,y\rangle)=i\langle x,y\rangle.\]
Therefore $\C\sub S$, and (\rmnum{1}) follows.\par
Now we prove (\rmnum{3}). First note that $\|ix\|=|i|\|x\|=\|x\|$, so $\Re\langle ix,iy\rangle=\Re\langle x,y\rangle$. Since it is clear that $\Re\langle x,y\rangle=\Re\langle y,x\rangle$, we combine these to conclude
\[\Re\langle ix,y\rangle=\Re\langle i^2x,iy\rangle=-\Re\langle x,iy\rangle=-\Re\langle iy,x\rangle\]
and so
\begin{align*}
\langle y,x\rangle=\Re\langle y,x\rangle-i\Re\langle iy,x\rangle=\Re\langle x,y\rangle+i\Re\langle ix,y\rangle=\widebar{\langle x,y\rangle}.
\end{align*}
Finally, if remains to show $\|x\|^2=\langle x,x\rangle$. From (\rmnum{3}) we see $\langle x,x\rangle\in\R$, so
\[\langle x,x\rangle=\Re\langle x,x\rangle=\frac{1}{4}\|2x\|^2=\|x\|^2.\]
This completes the proof.
\end{proof}
\subsection{Orthogonality}
The greatest advantage of a Hilbert space is its underlying concept of orthogonality.
\begin{definition}
If $H$ is a Hilbert space and $x,y\in H$, then $x$ and $y$ are \textbf{orthogonal} if $\langle x,y\rangle=0$. In symbols, $x\bot y$. If $A,B\sub H$, then $A\bot B$ iff $x\bot y$ for every $x\in A$ and $y\in B$.
\end{definition}
\begin{proposition}[\textbf{The Pythagorean Theorem}]
If $x_1,\dots,x_n\in H$ are pairwise orthogonal vectors in $H$, then
\[\|x_1+\cdots+x_n\|^2=\|x_1\|^2+\cdots+\|x_n\|^2.\]
\end{proposition}
\begin{proof}
If $x_1\bot x_2$ then
\[\|x_1+x_2\|^2=\|x_1\|^2+\|x_2\|^2+2\Re\langle x_1,x_2\rangle=\|x_1\|^2+\|x_2\|^2.\]
The remainder of the proof proceeds by induction.
\end{proof}
\begin{theorem}\label{Hilbert space closed convex minimal element}
Let $H$ be a Hilbert space, $C\sub H$ be a nonempty closed convex subset of $H$, and $x\in H$. Then there exists a unique element $y_0\in C$ such that
\[\|x-y_0\|=d(x,C)=\inf\{\|x-y\|:y\in C\}.\]
\end{theorem}
\begin{proof}
By repalce $C-x$ with $C$, we may assume that $x=0$. Define $\delta=d(0,C)\geq 0$ and choose a sequence $\{y_n\}$ in $C$ with $\lim_n\|y_n\|=\delta$. We prove that $\{y_n\}$ is a Cauchy sequence. Fix a constant $\eps>0$. Then there exists an integer $N>0$ such that for $n\geq N$, we have
\[\|y_n\|^2<\delta^2+\frac{\eps^2}{4}.\]
Let $i,j\geq N$. Then $(y_i+y_j)/2\in C$ because $C$ is convex and hence $\|y_i+y_j\|\geq 2\delta$. By parallelogram law we have
\begin{align*}
\|y_i-y_j\|^2=2\|y_i\|^2+2\|y_j\|^2-\|y_i+y_j\|^2<4(\delta^2+\eps^2/4)-4\delta^2=\eps^2.
\end{align*}
Thus $\{y_n\}$ is a Cauchy sequence. Since $H$ is complete and $C$ is closed, $\{y_n\}$ has a limit $y_0$ in $C$. It follows from the continuity of norm that $\|y_0\|=\delta$.\par
For the uniqueness, if there are two elements $y_0,y_1\in C$ with $\|y_0\|=\|y_1\|=\delta$. Then $(y_0+y_1)/2\in C$ because $C$ is convex and so $\|y_0+y_1\|\geq 2\delta$. Thus
\[\|y_0-y_1\|^2=2\|y_0\|^2+2\|y_1\|^2-\|y_0+y_1\|^2=4\delta^2-\|y_0+y_1\|^2\leq 0.\]
and therefore $y_0=y_1$. This proves the theorem.
\end{proof}
If the convex set in the preceding theorem is in fact a closed linear subspace of $H$, more can be said. For this, we first prove a lemma.
\begin{lemma}\label{Hilbert space nearest iff}
Let $M$ be a linear subspace of a Hilbert space $H$ and $x\in H\setminus M$. Then the following conditions are equivalent for a vector $m_0\in M$:
\begin{itemize}
\item[(\rmnum{1})] $x-m_0\bot M$.
\item[(\rmnum{2})] $\|x-m_0\|=\inf\{\|x-m\|:m\in M\}=d(x,M)$.
\end{itemize}
\end{lemma}
\begin{proof}
First assume that $x-m_0\bot M$, then for any $m\in M$, we have
\[\|x-m\|^2=\|x-m_0+m_0-m\|^2=\|x-m_0\|^2+\|m_0-m\|^2\geq\|x-m_0\|^2\]
where we use the Pythagorean theorem. This implies (\rmnum{2}).\par
Conversely, assume that $\|x-m_0\|=\inf\{\|x-m\|:m\in M\}=d(x,M)$. If $m\in M$ then $m_0\pm m\in M$, so
\[\|x-m_0\|^2\leq\|x-m_0\pm m\|^2=\|x-m_0\|^2+\|m\|^2\pm 2\Re\langle x-m_0,m\rangle.\]
Thus $2|\Re\langle x-m_0,m\rangle|\leq\|m\|^2$. Fix $m\in M$ and let $t\geq 0$, then we get
\[2|\Re\langle x-m_0,tm\rangle|\leq t^2\|m\|^2.\]
Divide by $t$ from the equation above and let $t\to 0$, we then get $\Re\langle x-m_0,m\rangle=0$. Similarly, repalce $m$ by $im$ we can show that $\Im\langle x-m_0,m\rangle=0$. Thus $x-m_0\bot m$ and the claim follows.
\end{proof}
\begin{corollary}\label{Hilbert space closed subspace orthogonal}
If $M$ is a closed linear subspace of $H$, $x\in H$. Then there exists a unique element $m_0\in M$ such that $x-m_0\bot M$.
\end{corollary}
We will see, as we proceed, that Hilbert spaces have several features that are not shared by general Banach spaces. One of these is that every closed subspace of a Hilbert space has a complement, i.e. another closed subspace whose direct sum with the original subspace is the entire Hilbert space. To explain this, we define the \textbf{orthogonal complement} of a subset $S\sub H$ by
\[S^\bot=\{x\in H:x\bot S\}.\]
It follows directly from the definitions that $S^\bot$ is a subspace of $H$ no matter what $S$ is.
\begin{proposition}\label{Hilbert space orthogonal complement prop}
Let $H$ be a Hilbert space and let $S,T$ be subsets of $H$.
\begin{itemize}
\item[(a)] $S^\bot\sub T^\bot$ iff $S\sups T$;
\item[(b)] $S^\bot=\langle S\rangle^\bot=\widebar{\langle S\rangle}^\bot$;
\item[(c)] $S\sub S^{\bot\bot}=(S^\bot)^\bot$ and $S^\bot=S^{\bot\bot\bot}$;  
\item[(d)] $S^\bot$ is a closed subspace;
\item[(e)] $S^{\bot\bot}=\widebar{\langle S\rangle}$; in particular, if $M$ is a closed subspace of $H$ then $M^{\bot\bot}=M$ and $H=M\oplus M^\bot$;
\item[(f)] if $\{S_i\}$ is a collection of subsets of $H$ then $(\bigcup_iS_i)^\bot=\bigcap_iS_i^\bot$;
\item[(g)] if $\{M_i\}$ is a collection of closed subspaces of $H$ then $(\bigcap_iM_i)^\bot=\widebar{\langle\bigcup_iM_i^\bot\rangle}$.
\end{itemize}
\end{proposition}
\begin{proof}
Since $S\sub\langle S\rangle\sub\widebar{\langle S\rangle}$, it follows that $\widebar{\langle S\rangle}^\bot\sub\langle S\rangle^\bot\sub S^\bot$. Let $x\in S^\bot$ and $y\in\widebar{\langle S\rangle}$. Choose a net $(y_\alpha)$ from $\langle S\rangle$ which converges to $y$. Since $\langle x,y_\alpha\rangle=0$ for every $\alpha$ and $\langle x,\cdot\rangle$ is continuous, it follows that $\langle x,y\rangle=\lim_\alpha\langle x,y_\alpha\rangle=0$. Thus $S^\bot\sub\widebar{\langle S\rangle}^\bot$ and (b) follows.\par
For any $x\in S$ and $y\in S^\bot$, we have $\langle x,y\rangle=0$. Hence $S\sub S^{\bot\bot}$. By (a) this implies that $S^{\bot\bot\bot}\sub S^{\bot}$; equality follows from the fact that $S^\bot\sub(S^\bot)^{\bot\bot}$.\par
By (b) and (c), $S^{\bot\bot}=\widebar{\langle S\rangle}^{\bot\bot}\sups\widebar{\langle S\rangle}$. If this inclusion is proper, there is an $x\in S^{\bot\bot}\setminus\widebar{\langle S\rangle}$. Then by (b), there exist $y\in S^\bot$ such that $\langle x,y\rangle=1$. Thus $y\notin S^{\bot\bot\bot}=S^\bot$, which is a contradiction.\par
Now assume that $M$ is a closed subspace of $H$. Clearly $M\cap M^\bot=\{0\}$. Let $x\in H$, then by Corollary~\ref{Hilbert space closed subspace orthogonal} there exists a unique element $\xi\in M$ such that $x-\xi\in M^{\bot}$, and so $x\in \oplus E^\bot$. This proves the second part of (e).\par
Part (f) is clear. By (e), $M_i=M_i^{\bot\bot}$ for each $i$, therefore
\begin{align*}
\bigcap_iM_i=\bigcap_iM_i^{\bot\bot}=\Big(\bigcup_iM_i^\bot\Big)^{\bot}=\Big(\widebar{\Big\langle\bigcup_iM_i^\bot\Big\rangle}\Big)^\bot.
\end{align*}
Hence by (e), we get (g).
\end{proof}
\begin{proposition}\label{Hilbert orthogonal projection prop}
Let $M$ be a closed linear subspace of $H$. For $x\in H$, let $Px$ be the unique element in $M$ such that $x-Px\bot M$. Then
\begin{itemize}
\item[(a)] $P$ is a linear transformation on $H$;
\item[(b)] $\|P\|=1$, in particular $P$ is continuous.
\item[(c)] $P^2=P$.
\item[(d)] $N(P)=M^\bot$ and $R(P)=M$.
\end{itemize}
\end{proposition}
\begin{proof}
By Lemma~\ref{Hilbert space nearest iff} we have $\|x-Px\|=d(x,M)$. The linearity of $P$ follows from that of the inner product. If $x\in H$ then $x=(x-Px)+Px$ and $(x-Px)\bot Px$, thus
\[\|x\|=\|x-Px\|^2+\|Px\|^2.\]
This implies $\|Px\|^2\leq\|x\|^2$, so $\|P\|=1$. Since $P$ is the identity on $M$, we get $\|P\|=1$. The rest is clear by definition. This completes the proof.
\end{proof}
\begin{corollary}
Every closed subspace in a Hilbert space $H$ is complemented.
\end{corollary}
\begin{proof}
This follows from Proposition~\ref{TVS topological complement iff}.
\end{proof}
\begin{theorem}[\textbf{Riesz}]\label{Hilber space Riesz}
Let $H$ be a Hilbert space and let $f:H\to\C$ be a bounded linear functional. Then there exists a unique element $y\in H$ such that
\[f(x)=\langle x,y\rangle.\]
Thus the map $H\to H^*,y\mapsto\langle\cdot,y\rangle$ is an anti-linear isometry of normed vector spaces.
\end{theorem}
\begin{proof}
Uniqueness is easy: if $f(x)=\langle x,y\rangle=\langle x,z\rangle$, then $\langle x,y-z\rangle=0$ for any $x\in X$, and hence $y=z$.\par
If $f=0$ then the vector $y=0$ satisfies the condition. Hence assume $f\neq 0$ and define
\[K=\{x\in H:f(x)=0\}.\]
Then $K$ is a proper closed subspace of $X$, so $K^\bot\neq\{0\}$ by Proposition~\ref{Hilbert space orthogonal complement prop}. Pick $z\in K^{\bot}$ with $\|z\|=1$. For any $x\in X$, the element $u=f(x)z-f(z)x$ is in $K$, so
\[0=\langle u,z\rangle=f(x)\langle z,z\rangle-f(z)\langle x,z\rangle=f(x)-\langle x,\widebar{f(z)}z\rangle.\]
Therefore $f(x)=\langle x,y\rangle$ with $y=\widebar{f(z)}$.
\end{proof}
Due to Theorem~\ref{Hilber space Riesz}, we can define an inner product on the dual space $H^*$ by
\begin{align}\label{Hilbert space inner product on dual}
\langle x^*,y^*\rangle_{H^*}=\widebar{\langle x,y\rangle}_H
\end{align}
where $x,y\in H$ are the elements in $H$ such that $x^*=\langle\cdot,x\rangle_H$ and $y^*=\langle\cdot,y\rangle_H$. Note that the conjugation in $(\ref{Hilbert space inner product on dual})$ is added for the $\C$-linearity: for $\alpha\in\C$ we have
\begin{align*}
\langle\alpha x^*,y^*\rangle_{H^*}&=\langle\alpha\langle\cdot,x\rangle_H,\langle\cdot,y\rangle_H\rangle_{H^*}=\big\langle\langle\cdot,\widebar{\alpha}x\rangle_H,\langle\cdot,y\rangle_H\big\rangle_{H^*}=\widebar{\langle\widebar{\alpha}x,y\rangle}=\alpha\langle x,y\rangle_H=\alpha\langle x^*,y^*\rangle_{H^*}.
\end{align*}
Thus if we let $R:H^*\to H$ denote the Riesz isomorphism, then
\[\langle Rx^*,Ry^*\rangle=\widebar{\langle x,y\rangle}.\]
In other words, $R$ becomes a unitary operator from $H^*$ to $H$.
\begin{corollary}\label{Hilbert space is reflexive}
Hilbert spaces are reflexive.
\end{corollary}
\begin{proof}
Let $H$ be a Hilbert space. Then the dual space $H^*$ is also a Hilbert space with the inner product defined by $(\ref{Hilbert space inner product on dual})$. For an element $x^*\in H^*$, we write $x\in H$ for its image under the Riesz isomorphism. Let $x^{**}\in H^{**}$, then by Riesz isomorphism, there exists a unique element $x^*\in H^*$ such that
\[x^{**}(y^*)=\langle y^*,x^*\rangle_{H^*}\for y^*\in H^*.\]
By the definition of $\langle\cdot\,,\cdot\rangle_{H^*}$, this means
\[\langle x^{**},y^*\rangle=\widebar{\langle y,x\rangle}_H=\langle x,y\rangle_H=\langle y^*,x\rangle=\langle J_H(x),y^*\rangle\for y^*\in H.\]
Thus $J_X(x)=x^{**}$, so $H$ is reflexive.
\end{proof}
A subset $\{e_{\alpha}\}_{\alpha\in A}$ of $H$ is called \textbf{orthonormal} if $\|e_{\alpha}\|=1$ for all $\alpha$ and $e_{\alpha}\perp e_\beta$ whenever $\alpha\neq\beta$. If $\{x_n\}_{n=1}^{\infty}$ is a linearly independent sequence in $H$, there is a standard inductive procedure, called the \textbf{Gram-Schmidt process}, for converting $\{x_n\}$ into an orthonormal sequence $\{e_n\}$ such that the linear span of $\{x_i\}_{i=1}^{n}$ coincides with the linear span of $\{u_i\}_{i=1}^{n}$ for all $n$.
\begin{proposition}[\textbf{Bessel's Inequality}]
If $\{e_{\alpha}\}_{\alpha\in A}$ is an orthonormal set in $H$, then for any $x\in H$,
\[\sum_{\alpha\in A}|\langle x,e_{\alpha}\rangle|^2\leq\|x\|^2.\]
In particular, $\{\alpha:\langle x,e_{\alpha}\rangle\neq 0\}$ is countable.
\end{proposition}
\begin{proof}
It suffices to show that $\sum_{\alpha\in A_0}|\langle x,e_{\alpha}\rangle|^2\leq\|x\|^2$ for any finite $A_0\sub A$. But
\begin{align*}
0\leq\Big\|x-\sum_{\alpha\in A_0}\langle x,e_{\alpha}\rangle e_{\alpha}\Big\|^2&=\|x\|^2-2\mathrm{Re}\langle x,\sum_{\alpha\in A_0}\langle x,e_{\alpha}\rangle e_{\alpha}\rangle+\Big\|\sum_{\alpha\in A_0}\langle x,e_{\alpha}\rangle e_{\alpha}\Big\|^2\\
&=\|x\|^2-2\sum|\langle x,e_{\alpha}\rangle|^2+\sum_{\alpha\in A_0}|\langle x,e_{\alpha}\rangle|^2\\
&=\|x\|^2-\sum_{\alpha\in A_0}|\langle x,e_{\alpha}\rangle|^2.
\end{align*}
This proves first claim. For the second claim, observe that
\[\{\alpha:\langle x,e_{\alpha}\rangle\neq 0\}=\bigcup_{n}\{\alpha:|\langle x,e_{\alpha}\rangle|>1/n\}.\]
If the left side is uncountable, then there exist $N$ such that $A_N:=\{\alpha:|\langle x,e_{\alpha}\rangle|>1/N\}$ is uncountable. But then
\[\sum_{\alpha\in A}|\langle x,e_{\alpha}\rangle|^2\geq\sum_{\alpha\in A_N}|\langle x,e_{\alpha}\rangle|^2\geq\frac{|A_N|}{N}=+\infty.\]
This is a contradiction.
\end{proof}
\begin{corollary}
Let $\{e_\alpha\}$ be an orthonormal set in a Hilbert space $H$. Then, for every $x\in H$, the series $\sum_{\alpha}\langle x,e_\alpha\rangle e_\alpha$ converges and its sum is the closest to $x$ element of the closed linear subspace generated by the vectors $e_{\alpha}$.
\end{corollary}
\begin{proof}
Bessel's inequality yields convergence of the series $\sum_{\alpha}\langle x,e_\alpha\rangle e_\alpha$, in which at most countably many elements are nonzero. Its sum is the projection of $x$ onto the aforementioned subspace, so the claim follows.
\end{proof}
\begin{theorem}\label{Hilbert space orthonormal basis iff}
If $\{e_{\alpha}\}_{\alpha\in A}$ is an orthonormal set in $H$, the following are equivalent:
\begin{itemize}
\item[(\rmnum{1})] If $\langle x,e_{\alpha}\rangle=0$ for all $\alpha\in A$, then $x=0$.
\item[(\rmnum{2})] $\widebar{\langle\{e_\alpha:\alpha\in A\}\rangle}=H$.
\item[(\rmnum{3})] For each $x\in H$, $x=\sum_{\alpha\in A}\langle x,e_{\alpha}\rangle e_{\alpha}$.
\item[(\rmnum{4})] For each $x,y\in H$ we have $\langle x,y\rangle=\sum_{\alpha\in A}\langle x,e_\alpha\rangle\langle e_\alpha,y\rangle$.
\item[(\rmnum{5})] For each $x\in H$ we have $\|x\|^2=\sum_{\alpha\in A}|\langle x,e_{\alpha}\rangle|^2$.
\end{itemize}
\end{theorem}
\begin{proof}
By Proposition~\ref{Hilbert space orthogonal complement prop}$(b,e)$, $\{e_\alpha\}^\bot=0$ iff $\widebar{\langle\{e_\alpha\}\rangle}=H$, thus $(\rmnum{1})\Leftrightarrow(\rmnum{2})$. If $x\in H$, let $\{\alpha_n\}$ be any enumeration of the $\alpha$'s for which $\langle x,e_{\alpha}\rangle\neq 0$. By Bessel's inequality the series $\sum_i|\langle x,e_{\alpha_i}\rangle|^2$ converges, so by the Pythagorean theorem,
\[\Big\|\sum_{i=n}^{m}\langle x,e_{\alpha_i}\rangle e_{\alpha_i}\Big\|^2=\sum_{i=n}^{m}|\langle x,e_{\alpha_i}\rangle|^2\to 0.\]
The series $\sum_i\langle x,e_{\alpha_i}\rangle e_{\alpha_i}$ therefore converges since $H$ is complete. If $s=\sum_i\langle x,e_{\alpha_i}\rangle e_{\alpha_i}$, then clearly $\langle x-s,e_{\alpha}\rangle=0$ for all $\alpha$, so by (\rmnum{1}) we get $x=s$. This shows $(\rmnum{1})\Rightarrow(\rmnum{3})$.\par
For $(\rmnum{3})\Rightarrow(\rmnum{4})$, we have
\[\langle\sum_{i=1}^{n}\langle x,e_{\alpha_i}\rangle e_{\alpha_i},\sum_{i=1}^{n}\langle y,e_{\alpha_i}\rangle e_{\alpha_i}\rangle=\sum_{i=1}^{n}\langle x,e_{\alpha_i}\rangle\langle e_{\alpha_i},y\rangle.\]
Letting $n\to+\infty$ and use the continuity of the inner product, we get (\rmnum{4}).\par
Finally, that $(\rmnum{4})\Rightarrow(\rmnum{5})\Rightarrow(\rmnum{1})$ is obvious. This completes the proof.
\end{proof}
An orthonormal set having the properties in Theorem~\ref{Hilbert space orthonormal basis iff} is called an \textbf{orthonormal basis} for $H$. For example, let $H=\ell^2(A)$. For each $\alpha\in A$, define $e_\alpha(\beta)=\delta_{\alpha\beta}$. The set $\{e_\alpha\}_{\alpha\in A}$ is clearly orthonormal, and for any $f\in\ell^2(A)$ we have $\langle x,e_\alpha\rangle=f(\alpha)$ from which it follows that $\{e_\alpha\}$ is an orthonormal basis.
\begin{proposition}\label{Hilbert space orthonormal basis exist}
If $E$ is an orthonormal set in $H$, then there is a basis for $H$ that contains $E$. In particular, every Hilbert space has an orthonormal basis.
\end{proposition}
\begin{proof}
A routine application of Zorn's lemma shows that the collection of orthonormal sets containing $E$, ordered by inclusion, has a maximal element; and maximality is equivalent to property (\rmnum{1}) in Theorem~\ref{Hilbert space orthonormal basis iff}.
\end{proof}
Just as in finite dimensional spaces, a basis in Hilbert space can be used to define a concept of dimension. For this purpose the next result is pivotal.
\begin{proposition}\label{Hilbert space orthonormal basis card}
If $H$ is a Hilbert space, any two orthonormal bases have the same cardinality.
\end{proposition}
\begin{proof}
Let $E$ and $F$ be two orthonormal bases for $H$ and put $\eps=\mathrm{card}(E)$, $\eta=\mathrm{card}(F)$. If $\eps$ or $\eta$ is finite, then $\eps=\eta$. Suppose that $\eps$ and $\eta$ are infinite. For each $e\in E$, let $F_e=\{f\in F:\langle e,f\rangle\neq 0\}$; so $F_e$ is countable. By Proposition~\ref{Hilbert space orthonormal basis iff}, each $f\in F$ belongs to at least one set $F_e$ for some $e\in E$. That is, $F=\bigcup_{e\in E}F_e$. Hence $\eta\leq\aleph_0\eps=\eps$. Similarly, $\eps\leq\eta$.
\end{proof}
\begin{definition}
The \textbf{dimension} of a Hilbert space is the cardinality of a orthonormal basis and is denoted by $\dim H$.
\end{definition}
Note that a orthonormal basis for $H$ is not a Hamel basis for $H$. Thus the dimension we define here does not coincide with the dimension of $H$ as a vector space.
\begin{proposition}\label{Hilbert space separable iff}
A Hilbert space $H$ is separable if and only if it has a countable orthonormal basis, in which case every orthonormal basis for $H$ is countable.
\end{proposition}
\begin{proof}
If $\{x_n\}$ is a countable dense set in $H$, by discarding recursively any $x_n$ that is in the linear span of $x_1,\dots,x_{n-1}$ we obtain a linearly independent sequence $\{y_n\}$ whose linear span is dense in $H$. Application of the Gram-Schmidt process to $\{y_n\}$ yields an orthonormal sequence $\{e_n\}$ whose linear span is dense in $H$ and which is therefore a basis.\par
Conversely, if $\{e_n\}$ is a countable orthonormal basis, the finite linear combinations of the $e_n$'s with coefficients in a countable dense subset of $\C$ form a countable dense set in $H$.
\end{proof}
\begin{example}
Let $L^2$ be defined by the Lebesgue measure. Then we know $C([0,1])$ is dense in $L^2([0,1])$. By Stone-Weierstrass theorem, polynomials are dense in $C([0,1])$ in the uniform norm, and hence is dense in $L^2$ norm. Therefore polynomials are dense in $L^2([0,1])$, and therefore $L^2([0,1])$ is separable. Since $\R=\bigcup_n[-n,n]$, we see $L^2(\R)$ is separable, and a similar argument shows that $L^2(\R^n)$ is dense for every $n$. 
\end{example}
\begin{example}
Let $A$ be an uncountable set and consider $\ell^2(A)$. Functions $e_{\alpha}$ of the form $e_{\alpha}(\beta)=\delta_{\alpha\beta}$ form an uncountable orthonormal basis in $\ell^2(A)$, hence $\ell^2(A)$ is nonseparable.
\end{example}
\subsection{Operators on Hilbert space}
\begin{proposition}
Let $H$ and $K$ be Hilbert spaces and $A:H\to K$ a linear transformation. The following statements are equivalent.
\begin{itemize}
\item[(\rmnum{1})] $A$ is continuous.
\item[(\rmnum{2})] $A$ is continuous at $0$.
\item[(\rmnum{3})] There is a constant $C>0$ such that $\|Ax\|\leq C\|x\|$ for all $x\in H$. 
\end{itemize}
\end{proposition}
For Hilbert spaces $H_1,H_2$, we use $\mathcal{B}(H_1,H_2)$ to denote all bounded operators from $H_1$ to $H_2$. Also, we will use $\mathcal{B}(H)$ to denote bounded linear operators from $H$ to $H$. Now we give some examples of operators on Hilbert spaces.
\begin{proposition}\label{L^2 space multiplication map}
Let $(X,\mathcal{A},\mu)$ be a measure space and put $H=L^2(\mu)$. If $\phi\in L^\infty(\mu)$, define $M_\phi:H\to H$ by $M_\phi f=\phi f$. Then $M_\phi\in\mathcal{B}(H)$ and $\|M_\phi\|=\|\phi\|_\infty$.
\end{proposition}
\begin{proof}
By Holder's inequality, it is clear that $\|\phi f\|_2\leq\|\phi\|_\infty\|f\|_2$, thus $\|M_\phi\|\leq\|\phi\|_\infty$. Now let $\alpha<\|\phi\|_\infty$, then the set $\{x:|\phi(x)|>\alpha\}$ is not locally $\mu$-null, so there exist a set $A\in\mathcal{A}$ such that $\mu(A)<+\infty$ and $E:=A\cap\{x:|\phi(x)|>\alpha\}$ has nonzero measure. If $f=\mu(E)^{-1/2}\chi_E$, then $f\in L^2(\mu)$ and $\|f\|_2=1$. We also note that
\[\|M_\phi f\|^2\geq\|\phi f\|_2^2=\mu(E)^{-1}\int_E|\phi|^2\geq\alpha^2.\]
Since $\alpha<\|M\|_\phi$ is arbitrary, it follows that $\|\phi\|_\infty\leq\|M_\phi\|$, so the claim follows.
\end{proof}
The operator $M_\phi$ is called a \textbf{multiplication operator}. The function $\phi$ is its \textbf{symbol}.
\begin{example}\label{Hilbert space multiplication operator}
Suppose that $E$ is an orthonormal basis in a Hilbert space $H$, $\phi$ is a bounded complex-valued function on $E$, and $k=\|\phi\|_\infty$. For each $x$ in $H$,
\[\sum_{e\in E}|\phi(e)\langle x,e\rangle|^2\leq k^2\sum_{e\in E}|\langle x,e\rangle|^2=k^2\|x\|^2\]
so the equation
\[T_\phi x=\sum_{e\in E}\phi(e)\langle x,e\rangle e\]
defines a vector $Tx$ in $H$, and $\|T_\phi x\|\leq k\|x\|$. It is clear that $T_\phi x$ depends linearly on $x$, so $T$ is a bounded linear operator on $H$, with $\|T_\phi\|\leq k$. By definition, we have $T_\phi e=\phi(e)e$ for all $e\in E$, so it follows that $\|T_\phi\|=k$.
\end{example}
\begin{proposition}[\textbf{Schur's test}]\label{Hilbert space integration operator}
Let $(X,\mathcal{A},\mu)$ and $(Y,\mathcal{B},\nu)$ be $\sigma$-finite measure space and suppose $k:X\times Y\to\R$ is a nonnegative $\mathcal{A}\otimes\mathcal{B}$-measurable function for which there are real functions $p(x)>0$ and $q(y)>0$ and numbers $C_1,C_2>0$ such that
\[\int_Yk(x,y)q(y)\,d\nu(y)\leq C_1p(x),\]
and
\[\int_Xk(x,y)p(x)\,d\mu(x)\leq C_2q(y).\]
Then the integral operator $K:L^2(\nu)\to L^2(\mu)$ defined by
\[Kf(x)=\int_Yk(x,y)f(y)\,d\nu(y)\]
is bounded and $\|K\|\leq\sqrt{C_1C_2}$.
\end{proposition}
\begin{proof}
Using the Cauchyâ€“Schwarz inequality and the first inequality, we get:
\begin{align*}
|Kf(x)|^2&=\Big|\int_Yk(x,y)f(y)\,d\nu(y)\Big|^2\leq\Big(\int_Yk(x,y)q(y)\,d\nu(y)\Big)\Big(\int_Y\frac{k(x,y)f^2(y)}{q(y)}\Big)\\
&\leq C_1p(x)\int_Y\frac{k(x,y)f^2(y)}{q(y)}\,d\nu(y).
\end{align*}
Integrating the above relation in $x$, using Fubini's Theorem, and applying the second inequality, we get:
\begin{align*}
\|Kf\|_2&\leq C_1\int_Xp(x)\int_Y\frac{k(x,y)f^2(y)}{q(y)}\,d\nu(y)d\mu(x)=C_1\int_Y\frac{f^2(y)}{q(y)}\int_Xk(x,y)p(x)\,d\mu(x)d\nu(y)\\
&\leq C_1C_2\int_Yf^2(y)\,d\nu(y)=C_1C_2\|f\|_2^2,
\end{align*}
thus the claim follows.
\end{proof}
\begin{example}
Let $k:[0,1]^2\to\R$ be the characteristic function of $\{(x,y):y<x\}$. The corresponding operator $V:L^2([0,1])\to L^2([0,1])$ defined by $Vf(x)=\int_{0}^{1}k(x,y)f(y)\,dy$ is called the \textbf{Volterra operator}. Note that
\[Vf(x)=\int_0^xf(y)\,dy.\]
\end{example}
\begin{example}
Let $\{H_s\}$ be a collection of Hilbert spaces and let $H=\bigoplus_sH_s$. Let $K$ be a Hilbert space and suppose $A_s\in\mathcal{B}(H_s,K)$ for all $s$. Then we can define an operator $A:H\to K$ by the condition $A|_{H_s}=A_s$. It is clear that $A$ is bounded iff $\sup_s\|A_s\|<+\infty$. The operator $A$ is called the direct sum of the operators $\{A_s\}$ and is denoted by $A=\bigoplus_sA_s$.
\end{example}
Now we define an important class of operators. If $H_1$ and $H_2$ are Hilbert spaces with inner products $\langle\cdot\ ,\cdot\rangle_1$ and $\langle\cdot\ ,\cdot\rangle_2$, a \textbf{unitary} map from $H_1$ to $H_2$ is an invertible linear map $U:H_1\to H_2$ that preserves inner products:
\[\langle Ux,Uy\rangle_2=\langle x,y\rangle_1\]
for any $x,y\in H_1$. By taking $y=x$, we see that every unitary map is an isometry. Conversely, every surjective isometry is unitary, by the polarization identity.
\begin{proposition}\label{Hilbert space unitary iff}
Let $H_1$ and $H_2$ be Hilbert spaces. A linear map from $H_1$ to $H_2$ is unitary if and only if it is isometric and surjective.
\end{proposition}
\begin{proof}
One direction follows by definition. Now assume that $U:H_1\to H_2$ is isometric and surjective. Then
\begin{align*}
\langle Ux,Uy\rangle=\frac{1}{4}\sum_{k=0}^{3}i^k\|Ux+i^k Uy\|^2=\frac{1}{4}\sum_{k=0}^{3}i^k\|x+i^ky\|^2=\langle x,y\rangle.
\end{align*}
Since $U$ is bijective, this implies $U^{-1}$ is also linera and bounded. Therefore $U$ is unitary.
\end{proof}
\begin{example}\label{shift operator on ell^2}
Let $S:\ell^2\to\ell^2$ be the shift operator on $\ell^2$ defined by
\[S(\alpha_1,\alpha_2,\dots)=(0,\alpha_1,\alpha_2,\dots).\]
Then $S$ is an isometry that is not surjective, so is not unitary.
\end{example}
We say two Hilber spaces $H_1$ and $H_2$ are \textbf{isomorphic} if there exists a unitary map from $H_1$ to $H_2$. Unitary maps are the true isomorphisms in the category of Hilbert spaces; they preserve not only the linear structure and the topology but also the norm and the inner product. From the point of view of this abstract structure, every Hilbert space looks like an $\ell^2$ space:
\begin{theorem}[\textbf{Riesz-Fischer}]
Let $\{e_{\alpha}\}_{\alpha\in A}$ be an orthonormal basis for $H$. Then the correspondence $x\mapsto\widehat{x}$ defined by $\widehat{x}(\alpha)=\langle x,e_{\alpha}\rangle$ is a unitary map from $H$ to $\ell^2(A)$. In particular, all infinite-dimensional separable Hilbert spaces are linearly isometric between themselves.
\end{theorem}
\begin{proof}
The map $x\mapsto x$ is clearly linear, and it is an isometry from $H$ to $\ell^2(A)$ by the Parseval identity $\|x\|^2=\sum_{\alpha\in A}|\langle x,e_{\alpha}\rangle|^2$. If $f\in\ell^2(A)$ then $\sum|f(\alpha)|^2<+\infty$, so the Pythagorean theorem shows that the partial sums of the series $\sum f(\alpha)e_{\alpha}$ (of which only countably many terms are nonzero) are Cauchy; hence $x=\sum f(\alpha)e_{\alpha}$ exists in $H$ and $\widehat{x}=f$. By Proposition~\ref{Hilbert space unitary iff}, $x\mapsto\widehat{x}$ is unitary.
\end{proof}
\begin{theorem}\label{Hilbert space isomorphic iff dim}
Two Hilbert spaces are isomorphic if and only if they have the same dimension.
\end{theorem}
\begin{proof}
By Riesz-Fischer theorem, if $H_1$ and $H_2$ have the same dimension, they are isomorphic to the same space. Now let $U:H_1\to H_2$ be a unitary map and $E\sub H_1$ be an orthonormal basis for $H_1$. Then it is easy to see $U(E)$ is an orthonormal basis for $H_2$, thus $\dim H_1=\dim H_2$.
\end{proof}
\begin{corollary}
All separable infinite dimensional Hilbert spaces are isomorphic.
\end{corollary}
\begin{example}
Let $\mathcal{F}:L^2([0,1])\to\ell^2(\Z)$ be the Fourier transform defined by
\[\mathcal{F}(f)(n)=\hat{f}(n)=\int_{0}^{1}f(x)e^{-2\pi inx}dx.\]
Then $\mathcal{F}$ is an isometry by Parseval's identity, so it has a closed image. To see $\mathcal{F}$ is surjective, let $(a_n)\in\ell^2(\Z)$. Then $f_N(x)=\sum_{n=1}^{N}a_ne^{inx}\in L^2([0,1])$ and it is easy to check that
\[\hat{f}_N(n)=\begin{cases}
a_n&n\leq N,\\
0&n>N.
\end{cases}\]
Since $\hat{f}_N\to(a_n)$ in $\ell^2(\Z)$. It follows that $R(\mathcal{F})=\ell^2(\Z)$. Thus $\mathcal{F}$ is surjective and so is a unitary map.
\end{example}
\begin{definition}
If $H$ and $K$ are Hilbert spaces, a function $u:H\times K\to\C$ is a \textbf{sesquilinear form} if
\begin{itemize}
\item[(a)] $u(\alpha x_1+\beta x_2,y)=\alpha u(x_1,y)+\beta u(x_2,y)$.
\item[(b)] $u(x,\alpha y_1+\beta y_2)=\bar{\alpha}u(x,y_1)+\bar{\beta}u(x,y_2)$.
\end{itemize}
A sesquilinear form is bounded if there is a constant $M$ such that $|u(x,y)|\leq M\|x\|\|y\|$. The constant $M$ is called a bound for $B$
\end{definition}
Sesquilinear forms are used to study operators. If $A\in\mathcal{B}(H,K)$, $u(x,y)=\langle Ax,y\rangle$ is a bounded sesquilinear form. Also, if $B\in\mathcal{B}(K,H)$, then $u(x,y)=\langle x,By\rangle$ is a bounded sesquilinear form. Are there any more? Are these two forms related?
\begin{theorem}\label{Hilbert space sesquilinear form char}
If $u:H\times K\to\C$ is a bounded sesquilinear form with bound $M$, then there are unique operators $A$ in $\mathcal{B}(H,K)$ and $B$ in $\mathcal{B}(K,H)$ such that
\[u(x,y)=\langle Ax,y\rangle=\langle x,By\rangle\]
for all $x\in H$ and $y\in K$ and $\|A\|,\|B\|\leq M$.
\end{theorem}
\begin{proof}
For each $x\in H$, define $L_x:K\to\C$ by $L_x(y)=u(x,y)$. Then $L_x$ is linear and $\|L_x\|\leq M$. By the Riesz Representation Theorem there is a unique vector $Ax\in K$ such that $L_x(y)=\langle x,y\rangle$ and $\|Ax\|=\|L_x\|\leq M$. It is easy to see that $A:H\to K$ is linear. Also, $u(x,y)=\langle Ax,y\rangle$. The existence of $B$ can be shown similarly. Uniqueness of $A$ and $B$ is clear.
\end{proof}
\begin{definition}
If $A\in\mathcal{B}(H,K)$, then the unique operator $B\in\mathcal{B}(K,H)$ satisfying $\langle Ax,y\rangle=\langle Bx,y\rangle$ is called the \textbf{adjoint} of $A$ and is denoted by $B=A^*$.
\end{definition}
From now on we will examine and prove results for the adjoint of operators. The following proposition is easy to prove.
\begin{proposition}\label{Hilbert space adjoint prop}
If $A,B\in\mathcal{B}(H)$ and $\alpha,\beta\in\C$, then
\begin{itemize}
\item[(a)] $(\alpha A+\beta B)^*=\bar{\alpha}A^*+\bar{\beta}B^*$.
\item[(b)] $(AB)^*=B^*A^*$.
\item[(c)] $A^{**}=A$.
\item[(d)] If $A$ is bijective, then $A^*$ is invertible and $(A^*)^{-1}=(A^{-1})^*$.
\end{itemize}
\end{proposition}
\begin{proof}
If $A$ is bijective, then we can define its inverse $A^{-1}$. By the open mapping theorem, $A^{-1}$ is continuous, so $A^{-1}\in\mathcal{B}(H)$.
Let $x,y\in H$, then
\[\langle A^*(A^{-1})^*x,y\rangle=\langle(A^{-1}A)^*x,y\rangle=\langle x,y\rangle.\]
This implies $(A^*)^{-1}=(A^{-1})^*$.
\end{proof}
\begin{proposition}\label{Hilbert space norm of adjoint}
If $A\in\mathcal{B}(H)$, then $\|A\|=\|A^*\|=\|A^*A\|^{1/2}$.
\end{proposition}
\begin{proof}
For $x\in H$ with $\|x\|=1$, we have
\[\|Ax\|^2=\langle Ax,Ax\rangle=\langle A^*Ax,x\rangle\leq\|A^*A\|\|x\|^2=\|A^*A\|\leq\|A^*\|\|A\|.\]
Hence $\|A\|^2\leq\|A^*A\|\leq\|A^*\|\|A\|$. Using the two ends of this string of inequalities gives $\|A\|\leq\|A^*\|$ when $\|A\|$ is cancelled. But $A=A^{**}$ and so if $A^*$ is substituted for $A$, we get $\|A\|=\|A^{**}\|$. Thus the string of inequalities becomes a string of equalities and the proof is complete.
\end{proof}
\begin{example}
If an operator on $\C^n$ is presented by a matrix, then its adjoint is represented by the conjuagate transpose of the matrix.
\end{example}
The operation of taking the adjoint of an operator is, as the reader may have seen from the examples above, analogous to taking the conjugate of a complex number. It is good to keep the analogy in mind, but do not become too religious about it.
\begin{definition}
Let $A\in\mathcal{B}(H)$. Then $A$ is \textbf{Hermitian} or \textbf{self-adjoint} if $A^*=A$, and is \textbf{normal} if $AA^*=A^*A$. $A$ is called \textbf{nonnegative} if $\langle Ax,x\rangle\geq 0$ for all $x\in X$, and \textbf{positive} if $\langle Ax,x\rangle>0$ unless $x=0$.
\end{definition}
In the analogy between the adjoint and the complex conjugate, hermitian operators become the analogues of real numbers and unitaries are the analogues of complex numbers of modulus $1$. Normal operators, as we shall see, are the true analogues of complex numbers. Notice that hermitian and unitary operators are normal.
\begin{example}
Let $(X,\mathcal{A},\mu)$ be a measure space and let $M_\phi$ be the multiplication operator with symbol $\phi$ (Proposition~\ref{L^2 space multiplication map}). Then $M_\phi^*=M_{\bar{\phi}}$ is the multiplication operator with symbol $\bar{\phi}$. Thus $M_\phi$ is normal, and is Hermitian if and only if $\phi$ is real-valued. Moreover, $M_\phi$ is unitary if and only if $|\phi|\equiv 1$.
\end{example}
\begin{example}
If $K:L^2(\nu)\to L^2(\mu)$ is the integral operator in Proposition~\ref{Hilbert space integration operator}. Then $K^*:L^2(\mu)\to L^2(\nu)$ is the integral operator given by
\[Kf(y)=\int_X\widebar{k(x,y)}f(x)\,dx.\]
Then $K$ is Hermitian iff $k(x,y)=\widebar{k(y,x)}$.
\end{example}
\begin{example}
Let $T_{\phi}$ be the operator in Example~\ref{L^2 space multiplication map}. By the same process, the complex-valued function $\widebar{\phi}$ gives rise to a bounded linear operator $T_{\widebar{\phi}}$ on $H$. For all $u,v\in H$,
\[\langle T_{\widebar{\phi}}u,v\rangle=\langle\sum_{e\in E}\widebar{\phi(e)}\langle u,e\rangle e,v\rangle=\sum_{e\in E}\widebar{\phi(e)}\langle u,e\rangle\langle e,v\rangle=\langle u,\sum_{e\in E}\phi(e)\langle v,e\rangle e\rangle=\langle u,T_\phi v\rangle.\]
Hence $T_{\widebar{\phi}}=T_\phi$ and we have
\[\|T_\phi x\|^2=\sum_{e\in E}|\phi(e)\langle x,e\rangle|^2=\|T_{\widebar{\phi}}x\|^2.\]
Thus $T$ is normal by Proposition~\ref{Hilbert space normal operator iff}. Also, we see $T$ is self-adjoint iff $\phi=\widebar{\phi}$, and $T$ is unitary iff $|\phi|\equiv 1$. 
\end{example}
\begin{example}
Let $S:\ell^2\to\ell^2$ be the shift operator in Example~\ref{shift operator on ell^2}. Then
\[\langle S(x_n),(y_n)\rangle=\sum_{n=2}^{+\infty}x_{n-1}\bar{y}_n=\sum_{n=1}^{+\infty}x_n\bar{y}_{n+1}.\]
Thus $S^*$ is given by $(x_1,x_2,\dots)\mapsto(x_2,x_3,\dots)$. The operator $S$ is called the \textbf{unilateral shift} and the operator $S^*$ is called the \textbf{backward shift}. Since $S^*S=I$ but $SS^*\neq I$, $S$ is not normal.
\end{example}
\begin{proposition}\label{Hilbert space Hermitian iff}
If $H$ is a Hilbert space and $A\in\mathcal{B}(H)$, then $A$ is Hermitian if and only if $\langle Ax,x\rangle\in\R$ for all $x\in H$.
\end{proposition}
\begin{proof}
If $A=A^*$, then $\langle Ax,x\rangle=\langle x,Ax\rangle=\widebar{\langle Ax,x\rangle}$; hence $\langle Ax,x\rangle\in\R$.\par
For the converse, assume $\langle Ax,x\rangle$ is real for every $x\in H$. If $\alpha\in\C$ and $x,y\in H$, then
\[\langle A(x+\alpha y),x+\alpha y\rangle=\langle Ax,x\rangle+\bar{\alpha}\langle Ax,y\rangle+\alpha\langle Ay,x\rangle+|\alpha|^2\langle Ay,y\rangle\in\R\]
So this expression equals its complex conjugate. Using the fact that $\langle Ax,x\rangle$ and $\langle Ay,y\rangle\in\R$ yields
\[\bar{\alpha}\langle Ax,y\rangle+\alpha\langle Ay,x\rangle=\alpha\langle y,Ax\rangle+\bar{\alpha}\langle x,Ay\rangle=\alpha\langle A^*y,x\rangle+\bar{\alpha}\langle A^*x,y\rangle.\]
By first taking $\alpha=1$ and then $\alpha=i$, we obtain the two equations
\[\langle Ax,y\rangle+\langle Ay,x\rangle=\langle A^*x,y\rangle+\langle A^*y,x\rangle,\]
\[i\langle Ay,x\rangle-i\langle Ax,y\rangle=i\langle A^*y,x\rangle-i\langle A^*x,y\rangle.\]
A little arithmetic implies $\langle Ax,y\rangle=\langle A^*x,y\rangle$, thus $A=A^*$.
\end{proof}
\begin{proposition}\label{Hilbert space Hermitian operator norm by inner product}
If $A\in\mathcal{B}(H)$ is Hermitian then $\|A\|=\sup\{|\langle Ax,x\rangle|:\|x\|=1\}$.
\end{proposition}
\begin{proof}
Put $M=\sup\{|\langle Ax,x\rangle|:\|x\|=1\}$. If $\|x\|=1$ then $\langle Ax,x\rangle\leq\|A\|$. Thus $M\leq\|A\|$. On the other hand, if $\|x\|=\|y\|=1$, then
\[\langle A(x\pm y),x\pm y\rangle=\langle Ax,x\rangle\pm\langle Ax,y\rangle\pm\langle Ay,x\rangle+\langle Ay,y\rangle.\]
Since $A=A^*$, this implies
\[\langle A(x\pm y),x\pm y\rangle=\langle Ax,x\rangle\pm 2\Re\langle Ax,y\rangle+\langle Ay,y\rangle.\]
Subtracting one of these two equations from the other gives
\[4\Re\langle Ax,y\rangle=\langle A(x+y),x+y\rangle-\langle A(x-y),x-y\rangle.\]
Since it is easy to verify that $|\langle Ax,x\rangle|\leq M$ for any $x\in H$, using the parallelogram law we get 
\[4\Re\langle Ax,y\rangle\leq M(\|x+y\|^2-\|x-y\|^2)=2M(\|x\|^2+\|y\|^2)=4M.\]
provided $x$ and $y$ are unit vectors. Now suppose $\langle Ax,y\rangle=re^{i\theta}$. Replacing $x$ in the inequality above with $e^{-i\theta}x$ gives $|\langle Ax,y\rangle|\leq M$. Taking the supremum over all $y$ gives $\|Ax\|\leq M$. Thus $\|A\|\leq M$.
\end{proof}
\begin{corollary}\label{Hilbert space Hermitian zero iff}
If $A=A^*$ and $\langle Ax,x\rangle=0$ for all $x\in H$, then $A=0$.
\end{corollary}
If $H$ is a Hilbert space and $A\in\mathcal{B}(H)$, then $B=(A+A^*)/2$ and $C=(A-A^*)/2i$ are self-adjoint and $A=B+iC$. The operators $B$ and $C$ are called, respectively, the \textbf{real} and \textbf{imaginary parts} of $A$.
\begin{proposition}\label{Hilbert space normal operator iff}
If $A\in\mathcal{B}(H)$, the following statement are equivalent.
\begin{itemize}
\item[(\rmnum{1})] $A$ is normal.
\item[(\rmnum{2})] $\|Ax\|=\|A^*x\|$ for all $x\in H$.
\item[(\rmnum{3})] The real and imaginary parts of $A$ commute.
\end{itemize}
\end{proposition}
\begin{proof}
If $x\in H$, then
\[\|Ax\|^2-\|A^*x\|^2=\langle Ax,Ax\rangle-\langle A^*x,A^*x\rangle=\langle(A^*A-AA^*)x,x\rangle\]
Since $A^*A-AA^*$ is hermitian, the equivalence of (\rmnum{1}) and (\rmnum{2}) follows from Corollary~\ref{Hilbert space Hermitian zero iff}.\par
If $B,C$ are real and imaginary parts of $A$, then a calculation yields
\[BC=\frac{1}{4i}(A^2-AA^*+A^*A-(A^*)^2),\quad CB=\frac{1}{4i}(A^2-A^*A+AA^*-(A^*)^2).\]
Thus $BC=CB$ iff $AA^*=A^*A$ and the claim follows.
\end{proof}
\begin{corollary}
If $A$ is a normal operator in $\mathcal{B}(H)$, then $N(A)=N(A^*)$.
\end{corollary}
\begin{proposition}\label{Hilbert space normal operator invertible iff}
If $A$ is a bounded normal operator on the Hilbert space $H$ and
\[\alpha:=\inf\{\|Ax\|:x\in H,\|x\|=1\}>0\]
then $A$ is invertible and $\|A^{-1}\|=\alpha^{-1}$.
\end{proposition}
\begin{proof}
By assumption we have $\|Ax\|\geq\alpha\|x\|$ for all $x\in H$. Therefore  $A$ is injective and $R(A)$ is closed. Thus $A$ is a bicontinuous linear mapping from $H$ to $R(A)$ and the inverse mapping $A^{-1}:R(A)\to H$ satisfies $\|A^{-1}\|=\alpha^{-1}$. It remains to prove that $R(A)=H$.\par
If $R(A)\neq H$, there is a unit vector $x\in R(A)^\bot$; by Proposition~\ref{Hilbert space normal operator iff},
\[0=\langle x,AA^*x\rangle=\langle A^*x,A^*x\rangle=\|A^*x\|^2=\|Ax\|^2\geq\alpha\|x\|^2.\]
Thus $x=0$. This porves $R(A)=H$, so the claim follows.
\end{proof}
\begin{proposition}\label{Hilbert space isometry iff}
If $A\in\mathcal{B}(H)$, the following statements are equivalent.
\begin{itemize}
\item[(\rmnum{1})] $A$ is an isometry.
\item[(\rmnum{2})] $A^*A=I$.
\item[(\rmnum{3})] $\langle Ax,Ay\rangle=\langle x,y\rangle$ for $x,y\in H$.
\end{itemize}
\end{proposition}
\begin{proof}
The proof that (\rmnum{1}) and (\rmnum{2}) are equivalent was seen in Proposition~\ref{Hilbert space unitary iff}. Note that if $x,y\in H$, then $\langle A^*Ax,y\rangle=\langle Ax,Ay\rangle$. Hence (\rmnum{2}) and (\rmnum{3}) are easily seen to be equivalent.
\end{proof}
\begin{proposition}\label{Hilbert space unitary iff normal isometry}
If $A\in\mathcal{B}(H)$, then the following statements are equivalent.
\begin{itemize}
\item[(a)] $A$ is unitary.
\item[(b)] $AA^*=A^*A=I$.
\item[(c)] $A$ is a normal isometry.
\end{itemize}
\end{proposition}
\begin{proof}
Note that $AA^*=A^*A=I$ implies $A$ is invertible and $\langle Ax,Ay\rangle=\langle x,y\rangle$, which means $A$ is unitary. Conversely, if $A$ is unitary, then $AA^*=I$, so $A^*=A^{-1}$ and $A^*A=I$. The rest is clear.
\end{proof}
We conclude with a very important, though easily proved, result.
\begin{theorem}\label{Hilbert space kernel and adjoint}
If $A\in\mathcal{B}(H)$, then $N(A)=R(A^*)^{\bot}$ and $N(A^*)=R(A)^\bot$.
\end{theorem}
\begin{proof}
If $x\in N(A)$ and $y\in H$, then $\langle x,A^*y\rangle=\langle Ax,y\rangle=0$, so $N(A)\sub R(A^*)^\bot$. On the other hand, if $x\bot R(A^*)$ and $y\in H$, then $\langle Ax,y\rangle=\langle x,A^*y\rangle=0$, so $R(A^*)^\bot\sub N(A)$. The second claim follows similarly, since $A^{**}=A$.
\end{proof}
Note that it is not ture that $N(A)^\bot=R(A^*)$ since $R(A^*)$ may not be closed. All that can be said is that $N(A)^\bot=\widebar{(R(A^*)}$ and $(NA^*)^\bot=\widebar{R(A)}$.
\subsection{Projections and idempotents}
Let $H$ be a Hilbert space and $P\in\mathcal{B}(H)$. Then $P$ is called \textbf{idempotent} if $P^2=P$, and a \textbf{projection} if $P$ is idempotent and $N(P)=R(P)^\bot$. If $M\sub H$ is a closed subspace, then the orthogonal projectin $P_M$ is a projection. It is not difficult to construct an idempotent that is not a projection.
\begin{proposition}
Let $H$ be a Hilbert space and $P\in\mathcal{B}(H)$. Then $P$ is an idempotent if and only if $I-P$ is an idempotent. If $P$ is an idempotent, then the following are ture:
\begin{itemize}
\item[(a)] $I-P$ is a projection on $N(P)$.
\item[(a)] $R(P)=N(I-P)$ and $N(P)=R(I-P)$.
\item[(b)] $N(P)$ and $R(P)$ are closed subspaces of $H$ and $H=N(P)\oplus R(P)$.
\end{itemize}
\end{proposition}
\begin{proof}
Since $(I-P)^2=I^2-I-2E+E^2$, the first claim follows. Now assume that $P^2=P$. The inclusion $N(I-P)\sub R(P)$ is clear. For the converse, if $y=Px$ then $Py=P^2x=y$, so $y\in N(I-P)$. The equality $N(P)=R(I-P)$ can be proved similarly.\par
Now, since $P$ and $I-P$ are continuous, $N(P)$ and $N(I-P)$ are closed. The claim $N(P)\oplus R(P)=H$ follows immediately from $P^2=P$. This completes the proof.
\end{proof}
Now we turn our attention to projections, which are peculiar to Hilbert space.
\begin{proposition}\label{Hilbert space idempotent is projection iff}
If $P\in\mathcal{B}(H)$ is an idempotent on $H$ and $P\neq 0$, the following statements are equivalent.
\begin{itemize}
\item[(\rmnum{1})] $P$ is a projection.
\item[(\rmnum{2})] $P$ is the orthogonal projection of $H$ onto $R(P)$.
\item[(\rmnum{3})] $\|P\|=1$.
\item[(\rmnum{4})] $P$ is Hermitian.
\item[(\rmnum{5})] $P$ is normal.
\item[(\rmnum{6})] $\langle Px,x\rangle\geq 0$ for all $x\in H$.
\end{itemize}
\end{proposition}
\begin{proof}
Let $M=R(P)$. If $P$ is a projection, then $N(P)\bot R(P)$, so $Px$ is the unique vector such that $x-Px\bot M$. It follows that $P=P_M$, by the uniqueness of orthogonal projections. With this, we then have $\|P\|=1$ by Proposition~\ref{Hilbert orthogonal projection prop}.\par
Assume that $\|P\|=1$. Let $x\in(N(P))^\bot$. Now $N(P)=R(I-P)$, hence
\[0=\langle x-Px,x\rangle=\|x\|^2-\langle Px,x\rangle.\]
This implies $\|x\|^2=\langle Px,x\rangle\leq\|Px\|\|x\|=\|x\|^2$, so for $x\in(N(P))^\bot$ we have $\|x\|^2=\|Px\|^2=\langle Px,x\rangle$. But then
\[\|x-Px\|^2=\|x\|^2+\|Px\|^2-2\Re\langle Px,x\rangle=0,\]
which implies $x=Px$, so $(N(P))^\bot\sub R(P)$. On the other hand, if $x=x_1+x_2\in R(P)$ with $x_1\in N(P),x_2\in N(P)^\bot$, then $x=Px=Px_2=x_2$, so $x\in N(P)^\bot$. Therefore $R(P)=N(P)^\bot$ and $P$ is a projection.\par
Now assume that $P=P_M$ is an orthonormal projection. Then for $x=x_1+x_2\in H$ with $x_1\in M,x_2\in M^\bot$, we have
\[\langle Px,x\rangle=\langle x_1,x_1+x_2\rangle=\|x_1\|^2\geq 0\]
thus $P$ is Hermitian by Proposition~\ref{Hilbert space Hermitian iff} and (\rmnum{6}) is satisfieed. In particular, $P$ is normal. If $P$ is normal then $\|Px\|=\|P^*x\|=\|x\|$ by Proposition~\ref{Hilbert space normal operator iff}, hence $N(P)=N(P)^*=R(P)^\bot$ (Theorem~\ref{Hilbert space kernel and adjoint}). Therefore $P$ is a projection and the proof is completed.
\end{proof}
Now we consider some operations on projections.
\begin{proposition}\label{Hilbert space sum of projection}
Let $P$ and $Q$ be projections. Then $P+Q$ is a projection if and only if $R(P)\bot R(Q)$. If this holds, then $R(P+Q)=R(P)+R(Q)$ and $N(P+Q)=N(P)\cap N(Q)$.
\end{proposition}
\begin{proof}
Since $(P+Q)^2=P+Q+PQ+QP$, $P+Q$ is idempotent iff $PQ+QP=0$. Moreover, for $x\in H$ we have
\[\langle(P+Q)x,x\rangle=\langle Px,x\rangle+\langle Qx,x\rangle\geq 0.\]
Thus by Proposition~\ref{Hilbert space idempotent is projection iff}, $(P+Q)$ is a projection iff $PQ+QP$. If $R(P)\bot R(Q)$, then $R(P)\cap R(Q)=\{0\}$, so this is satisfied. Conversely, if $PQ+QP=0$, then write $Q$ with respect to the decomposition $H=N(P)\oplus R(P)$,
\[Q=\begin{bmatrix}
Q_1&Q_2\\
Q_3&Q_4
\end{bmatrix}\]
we have
\[QP=\begin{bmatrix}
Q_1&0\\
Q_3&0
\end{bmatrix}\quad PQ=\begin{bmatrix}
Q_1&Q_2\\
0&0
\end{bmatrix}\]
Thus $Q_1=Q_2=Q_3=0$, and this implies $R(Q)\sub N(P)=R(P)^\bot$. That is, $R(P)\bot R(Q)$.\par
Now assume that $P+Q$ is a projection. Then $R(P+Q)\sub R(P)+R(Q)$. Conversely, if $x+y\in R(P)+R(Q)$, then $(P+Q)(x+y)=Px+Py=x+y$, so $x+y\in R(P+Q)$. This proves $R(P+Q)=R(P)+R(Q)$, the second claim follows by Theorem~\ref{Hilbert space kernel and adjoint}.
\end{proof}
\begin{proposition}\label{Hilbert space composition of projection}
Let $P$ and $Q$ be projections. Then the following are equivalent:
\begin{itemize}
\item[(\rmnum{1})] $PQ$ is a projection.
\item[(\rmnum{2})] $PQ=QP$.
\item[(\rmnum{3})] $P+Q-PQ$ is a projection.
\end{itemize}
If these conditions hold, then
\begin{itemize}
\item[(a)] $R(PQ)=R(P)\cap R(Q)$ and $N(PQ)=N(P)+N(Q)$.
\item[(b)] $R(P+Q-PQ)=R(P)+R(Q)$ and $N(P+Q-PQ)=N(P)\cap N(Q)$. 
\end{itemize}
\end{proposition}
\begin{proof}
If $PQ$ is a projection then $(PQ)^*=QP=PQ$. Conversely, if $PQ=QP$, then $(PQ)^2=PQ$, so $PQ$ is idempotent. Moreover, 
\[(PQ)^*=Q^*P^*=QP=PQ\]
so $PQ$ is Hermitian and it follows from Proposition~\ref{Hilbert space idempotent is projection iff} that $PQ$ is a projection. Similarly, if $P+Q-PQ$ is a projection then $(P+Q-PQ)^*=P+Q-QP=P+Q-PQ$, so $PQ=QP$. Conversely, if $PQ=QP$, then $P+Q-PQ$ is Hermitian and $I-(P+Q-PQ)=(I-P)(I-Q)$, so it is idempotent, hence projection.\par
Now assume the conditions above. Let $y=PQx\in R(PQ)$, then
\[Py=P^2Qx=PQx=y,\quad Qy=QPQx=PQ^2x=PQx=y\]
so $y\in R(P)\cap R(Q)$. Conversely, if $x\in R(P)\cap R(Q)$ then $PQx=Px=x$, so $x\in R(PQ)$. This proves $R(PQ)=R(P)\cap R(Q)$. With this, by Theorem~\ref{Hilbert space kernel and adjoint} and $(PQ)^*=PQ$ we then get
\[N(PQ)=R(PQ)^\bot=(R(P)\cap R(Q))^\bot=R(P)^\bot+R(Q)^\bot=N(P)+N(Q).\]
This proves the first part. Now let $y=(P+Q-PQ)x\in R(P+Q-PQ)$, then
\[Py=Px+PQx-PQx=Px,\quad Qy=QPx+Qx-QPQx=Qx.\]
Thus $y=(P+Q-PQ)y\in R(P)+R(Q)$. Conversely, if $z=Px+Qy\in R(P)+R(Q)$, then
\[(P+Q-PQ)(Px+Qy)=Px+PQy+QPx+Qy-PQPx-PQy=Px+Qy\]
so $z\in R(P+Q-PQ)$. This proves $R(P+Q-PQ)=R(P)+R(Q)$ and we get the second part by Theorem~\ref{Hilbert space kernel and adjoint}.
\end{proof}
Now we consider the lattice of projections on a Hilbert space $H$. For this, the following result is useful.
\begin{proposition}\label{Hilbert space difference of projection}
Let $P$ and $Q$ be projections. Then the following are equivalent:
\begin{itemize}
\item[(\rmnum{1})] $P-Q$ is a projection.
\item[(\rmnum{2})] $R(Q)\sub R(P)$.
\item[(\rmnum{3})] $PQ=Q$.
\item[(\rmnum{4})] $QP=P$. 
\end{itemize}
If these conditions hold, then $R(P-Q)=R(P)\cap N(Q)$ and $N(P-Q)=N(P)+R(Q)$.
\end{proposition}
\begin{proof}
By the definition of orthonormal projection, it is clear that $(\rmnum{2})\Leftrightarrow(\rmnum{3})\Leftrightarrow(\rmnum{4})$. Now we characterize $R(P-Q)$. Let $y=Px-Qx\in R(P-Q)$. Then $Py=Px-PQx=Px-Qx=y$, so $y\in R(P)$. Similarly, $Qy=QPx-Qx=0$, so it follows that $R(P-Q)\sub R(P)\cap N(Q)$. Conversely, if $x\in R(P)\cap N(Q)$, then $(P-Q)x=Px-Qx=Px=x$, so $x\in R(P-Q)$. This proves $R(P-Q)=R(P)\cap N(Q)$, and the second claim follows by Theorem~\ref{Hilbert space kernel and adjoint}.
\end{proof}
Now we define an order on projections on $H$ by $P\leq Q$ iff $Q-P$ is a projection. It is easy to see $P\leq Q$ iff $R(P)\sub R(Q)$. Given any family $\{E_s:s\in S\}$ of closed subspaces of a Hilbert space $H$, there is a greatest closed subspace $\bigwedge_sE_s$ that is contained in each $E_s$ and a smallest closed subspace $\bigvee_sE_s$ that contains each $E_s$. Specially,
\[\bigwedge_sE_s=\bigcap_sE_s,\quad \bigvee_sE_s=\widebar{\langle\{ E_s:s\in S\}\rangle}.\]
From this it follows that each family $\{P_s\}$ of projections acting on $H$ has a greatest lower bound $\bigwedge_sP_s$, and a least upper bound $\bigvee_sP_s$, within the set of projections. Of course, the projections $\bigwedge_sP_s$, and $\bigvee_sP_s$, correspond to the closed subspaces $\bigwedge_sE_s$ and $\bigvee_sE_s$. We write $P\wedge Q$ and $P\vee Q$ for the lower and upper bounds (often called the intersection and union) of two projections $P$ and $Q$.\par
Since the mapping $P\mapsto I-P$ reverses the ordering of projections, we have
\[\bigwedge(I-P_s)=I-\bigvee P_s,\quad\bigvee(I-P_s)=I-\bigwedge P_s\]
for each family $\{P_s\}$ of projections.\par
Our next few results are concerned with commuting sets of projections.
\begin{proposition}\label{Hilbert space union and inters of commuting projection}
If $P$ and $Q$ are commuting projections acting on a Hilbert space $H$, then
\[P\vee Q=P+Q-PQ,\quad P\wedge Q=PQ.\]
In particular, the linear subspace $R(P)+R(Q)$ of $H$ is closed.
\end{proposition}
\begin{proof}
By the given condition, $P+Q-PQ$ and $PQ$ are projection. Moreover, by Proposition~\ref{Hilbert space composition of projection}, we have $R(P)Q=R(P)\wedge R(Q)$, so $PQ=P\wedge Q$. By applying the same result to the commuting projections $I-P$ and $I-Q$, we have
\[I-P\vee Q=(I-P)\wedge(I-Q)=(I-P)(I-Q)=I-P-Q+PQ\]
and thus $P\vee Q=P+Q-PQ$. Since $R(P+Q-PQ)=R(P)+R(Q)$, we see $R(P)+R(Q)=R(P)\vee R(Q)$, so $R(P)+R(Q)$ is closed.
\end{proof}
\begin{corollary}
Suppose that $P$ and $Q$ are the projections. Then $PQ=0$ if and only if $R(P)\bot R(Q)$, and when this is so, $P\vee Q=P+Q$.
\end{corollary}
\begin{proposition}\label{Hilbert space increasing projection}
If $\{P_\alpha\}$ is an increasing net of projections acting on a Hilbert space $H$, and if $P=\bigvee P_\alpha$, then $Px=\lim_\alpha Px$ for each $x\in H$. A similar result holds for decreasing nets.
\end{proposition}
\begin{proof}
Since $\{R(P)_\alpha\}$ is an increasing net of closed subspaces of $H$, $\bigcup_\alpha R(P)_\alpha$ is a linear subspace of $H$ and has norm closure $R(P)$. Suppose $x\in H$ and $\eps>0$. Since $Px\in R(P)$, we can choose an element $y$ in one of the subspaces $R(P)_\alpha$ so that $\|Px-y\|<\eps$. When $\beta\succeq\alpha$, we have $y\in R(P)_\alpha\sub R(P)_\beta\sub R(P)$, and thus
\[\|Px-P_\beta x\|=\|P(Px-y)-P_\beta(Px-y)\|\leq\|P-P_\beta\|\|Px-y\|<\eps.\]
This proves the claim.
\end{proof}
By an \textbf{orthogonal family of projections} we mean a family $\{P_s:s\in S\}$ of projections such that $P_sP_t=0$ whenever $s$ and $t$ are distinct elements of $S$.
\begin{proposition}\label{Hilbert space union of orthogonal projections}
If $\{P_s:s\in S\}$ is an orthogonal family of projections acting on a Hilbert space $H$, $P=\bigvee_sP_s$ and $x\in H$, then $Px=\sum_sP_sx$; the sum converges in the norm topology on $H$.
\end{proposition}
\begin{proof}
When $S$ is a finite set, it follows from Corollary~\ref{Hilbert space union and inters of commuting projection}. When $S$ is an infinite set, let $\mathcal{F}$ denote the class of all finite subsets of $S$; for each $F\in\mathcal{F}$; define $P_F=\sum_{s\in F}P_s$. By the preceding paragraph, $P_F=\bigvee_{s\in F}P_s$, so $(P_F)_{F\in\mathcal{F}}$ is an increasing net of projections, and
\[\bigvee_{F\in\mathcal{F}}P_F=\bigvee_{F\in\mathcal{F}}\bigvee_{s\in F}P_s=\bigvee_{s\in S}P_s=P.\]
By Proposition~\ref{Hilbert space increasing projection}, $Px$ is the limit, in norm, of the net $(P_Fx)_{F\in\mathcal{F}}$; that is, $\sum_{s\in S}P_sx$ converges in norm to $Px$.
\end{proof}
\subsection{Compact operators}
It turns out that most of the statements about linear transformations on finite dimensional spaces have nice generalizations to a certain class of operators on infinite dimensional spaces-namely, to the compact operators.
\begin{theorem}
Let $H$ be a Hilbert space and $T\in\mathcal{B}(H)$. Then $T$ is compact iff there is a sequence $\{T_n\}$ of operators of finite rank such that $\|T_n-T\|\to 0$.
\end{theorem}
\begin{proof}
One dierction follows from Theorem~\ref{Banach space compact operator prop}. Now let $T$ be a compact operator on $H$. Since $\widebar{T(B_H)}$ is compact, it is separable. Therefore $M:=\widebar{T(B_H)}$ is a separable subspace of $H$. Let $\{e_n\}$ be an orthonormal basis for $M$. For each $n$, set $M_n=\bigvee\{e_i:1\leq i\leq n\}$ and let $P_n$ be the orthogonal projection of $H$ onto $M_n$. Put $T_n=P_nT$. Note that each $T_n$ has finite rank since $P_n$ has finite rank. We now show that $\|T_n-T\|\to 0$.\par
We first show that $\|T_nx-Tx\|\to 0$ for all $x\in H$. In fact, $y=Tx\in M$, so $\|P_ny-y\|\to 0$ and $\|T_nx-Tx\|=\|P_nT_nx-Tx\|\to 0$. Since $T$ is compact, if $\eps>0$, there are vectors $x_1,\dots,x_k$ such that $T(B_H)\sub\bigcup_{i=1}^{k}B_{\eps/3}(Tx_i)$. So if $x\in B_H$, choose $x_i$ with $\|Tx-Tx_i\|<\eps/e$. Then for any integer $n$,
\begin{align*}
\|Tx-T_nx\|&\leq\|Tx-Tx_i\|+\|Tx_i-T_nx_i\|+\|P_n(Tx_i-Tx)\|\\
&\leq 2\|Tx-Tx_i\|+\|Tx_i-T_nx_i\|\\
&\leq 2\eps/3+\|Tx_i-T_nx_i\|.
\end{align*}
Using the claim we can find an integer $N$ such that $\|Tx_i-T_nx_i\|<\eps/3$ for $i=1,\dots,k$ and $n>N$. So $\|Tx-T_nx\|<\eps$ uniformly for $x\in B_H$ and the claim follows.
\end{proof}
A fact emerged in the proof of the preceding theorem that is worth recording.
\begin{corollary}\label{Hilbert space compact operator image separable}
If $T\in\mathcal{K}(H,K)$, then $\widebar{R(T)}$ is separable and if $\{e_n\}$ is a basis for $\widebar{R(T)}$ and $P_n$ is the projection of $H$ onto $\bigvee\{e_i:1\leq i\leq n\}$, then $\|P_nT-T\|\to 0$.
\end{corollary}
\begin{proposition}\label{Hilbert space diagonal operator is compact iff}
Let $H$ be a separable Hilbert space with orthonormal basis $\{e_n\}$. Let $(\alpha_n)\in\ell^\infty$. If $Ae_n:=\alpha_ne_n$ for all $n$, then $A$ extends by linearity to a bounded operator on $H$ with $\|A\|=\sup_n|\alpha_n|$. The operator $A$ is compact if and only if $\alpha_n\to 0$.
\end{proposition}
\begin{proof}
It is easy to see $\|A\|=\sup_n|\alpha_n|$. Let $P_n$ be the projection of $H$ onto $\bigvee{e_i:1\leq i\leq n}$. Then $A_n=A-AP_n$ is seen to be diagonalizable with $A_ne_i=\alpha_ie_i$ for $i>n$ and $A_ne_i=0$ for $i\leq n$. So $AP_n\in\mathcal{R}(H)$ and $\|A_n\|=\sup\{|\alpha_j|:j>n\}$. If $\alpha_n\to 0$ then $\|A_n\|\to 0$ and so $\|A-AP_n\|\to 0$, thus $A$ is compact. Conversely, if $A$ is compact, then Corollary~\ref{Hilbert space compact operator image separable} implies $\|A_n\|\to 0$; hence $\alpha_n\to 0$.
\end{proof}
\begin{proposition}\label{Hilbert space integral operator is compact}
If $(X,\mathcal{A},\mu)$ is a $\sigma$-finite measure space and $k\in L^2(\mu\times\mu)$, then
\[Kf(x)=\int_Xk(x,y)f(y)\,d\mu(y)\]
is a compact operator and $\|K\|\leq\|k\|_2$.
\end{proposition}
\begin{proof}
First we show that $K$ defines a bounded operator. In fact, if $f\in L^2(\mu)$, then
\begin{align*}
\|Kf\|^2&=\int\Big|\int k(x,y)f(y)\,d\mu(y)\Big|^2\,d\mu(x)\\
&\leq\int\Big(\int|k(x,y)|^2\,d\mu(y)\Big)\Big(\int|f(y)|^2\,d\mu(y)\Big)d\mu(x)=\|k\|_2^2\|f\|_2^2.
\end{align*}
Hence $K$ is bounded and $\|K\|\leq\|k\|_2$.\par
Now let $\{e_i\}$ be a basis for $L^2(\mu)$ and define $\phi_{ij}$ by
\[\phi_{ij}(x,y)=e_{i}(x)\widebar{e_j(y)}.\]
Then $\{\phi_{ij}\}$ is an orthonormal basis for $L^2(\mu\times\mu)$, so
\[k(x,y)=\sum_{i,j}\alpha_{ij}\phi_{ij}\quad\text{where}\quad \alpha_{ij}=\langle k,\phi_{ij}\rangle.\]
Note that there are at most countably many $i,j$ such that $\alpha_{ij}\neq 0$. After deleting these terms, we get a sequence $\{\alpha_{ij}\}_{i,j=1}^{+\infty}$. Next, let $k_n=\sum_{i,j=1}^{n}\alpha_{ij}\phi_{ij}$ and also $K_n$ be the finite rank operator
\[K_n(x)=\int_Xk_n(x,y)f(y)\,d\mu(y).\]
By Parseval's theorem, we have that
\[\|k-k_n\|_2^2=\sum_{i,j=1}^{\infty}|\alpha_{ij}|^2-\sum_{i,j=1}^{n}|\alpha_{ij}|^2=\sum_{i>n,j>n}|\alpha_{ij}|^2\leq\sum_{j>n}\sum_{i=1}^{n}|\alpha_{ij}|^2+\sum_{i>n}\sum_{i=1}^{n}|\alpha_{ij}|^2.\]
Both terms go to $0$ as $n\to 0$, which implies $\|k-k_n\|_2\to 0$. As we have proved, $\|K-K_n\|\leq\|k-k_n\|_2$, so $\|K-K_n\|\to 0$ and the claim follows.
\end{proof}
\subsection{Constructions with Hilbert spaces}
In this section we consider subspaces, direct sums, and tensor products of Hilbert spaces, together with related operator-theoretic constructions.
\subsubsection{Subspaces}
Suppose that $P$ is the projection from a Hilbert space $H$ onto a closed subspace $M$. By restriction, the inner product on $H$ gives rise to an inner product on $M$, relative to which $M$ itself is a Hilbert space. With $T\in\mathcal{B}(H)$, the restriction $PT|_{E}=PTP|_{E}$ is a bounded linear operator $T_M$ acting on $M$, the \textbf{compression} of $T$ to $M$. For all $y$ and $z$ in $M$,
\[\langle T_My,z\rangle=\langle PTPy,z\rangle=\langle y,PT^*Pz\rangle\]
so the adjoint of $T_M$ is $PT^*P|_{E}$, the compression of $T^*$ to $M$.\par
We say that $M$ is invariant under $T$, or that $T$ leaves $M$ invariant (invariant is sometimes replaced by stable), if $T(M)\sub M$. Since $M=R(P)=N(I-P)$, it is apparent that $T(M)\sub M$ if and only if $TP=PTP$. Since
\[T^*(I-P)-(I-P)T^*(I-P)=PT^*(I-P)=(TP-PTP)^*\]
it follows that the orthogonal complement $M^\bot$ is invariant under $T^*$ if and only if $M$ is invariant under $T$.\par
When $M$ and $M^\bot$ are both invariant under $T$, we say that $M$ reduces $T$; from the preceding paragraph, this occurs if and only if $M$ is invariant under both $T$ and $T^*$. In this case
\[PT=(T^*P)^*=(PT^*P)^*=PTP=TP.\]
Conversely, if $PT=TP$, then $PT^*=T^*P$, so that $PTP=PT=TP$ and $PT^*P=PT^*=T^*P$. Thus $M$ reduces $T$ iff $P$ and $T$ commutes.
\subsubsection{Direct sums}
When $H_1,\dots,H_n$ are Hilbert spaces and $H=\bigoplus_{i=1}^{n}H_i$, there is a Hilbert space structure on $H$ in which the inner product is defined by
\[\langle(x_1,\dots,x_n),(y_1,\dots,y_n)\rangle=\sum_{i=1}^{n}\langle x_i,y_i\rangle.\]
The resulting Hilbert space $H$ is called the \textbf{Hilbert direct sum} of $H_1,\dots,H_n$. For each $i=1,\dots,n$, the set $\widetilde{H}_i$, consisting of those $n$-tuples in which all but the $i$-th entry are zero, is a closed subspace of $H$. The mapping $U_i:H_i\to\widetilde{H}_i$ defined by $U_ix=(0,\dots,x,\dots,0)$ (with $x$ in the $i$-th position) is an isomorphism from $H_i$ onto $\widetilde{H}_i$, so we may identify $H_i$ with a subspace of $H$ and make no distinction between $H_i$ and $\widetilde{H}_i$. The subspaces $\widetilde{H}_1,\dots,\widetilde{H}_n$ are pairwise orthogonal, and $\bigvee_{i=1}^{n}\widetilde{H}_i=H$.\par
Suppose next that $H_1,\dots,H_n$ are mutually orthogonal subspaces of a Hilbert space $H$, and $\bigvee_{i=1}^{n}H_i=H$. By Proposition~\ref{Hilbert space union and inters of commuting projection}, the corresponding pairwise orthogonal projections $P_1,\dots,P_n$ have sum $I$. The linear mapping $U_i:H\to\bigoplus_{i=1}^{n}H_i$ defined by $Ux=(P_1x,\dots,P_nx)$ carries $H_i$ to $\widetilde{H}_i$ and is unitary because
\[\|Ux\|^2=\sum_{i=1}^{n}\|P_ix\|^2=\|\sum_{i=1}^{n}P_ix\|^2=\|x\|^2.\]
Thus $H$ is isomorphic to the direct sum $\bigoplus_{i=1}^{n}H_i$.\par
If $H_i,K_i$ are Hilbert spaces and $T\in\mathcal{B}(H_i,K_i)$ for $i=1,\dots,n$. The equation
\[T(x_1,\dots,x_n)=(T_1x_1,\dots,T_nx_n)\]
defines a linear operator $T$ from $\bigoplus_{i=1}^{n}H_i$ to $\bigoplus_{i=1}^{n}K_i$. With $c=\sup_{i}\|T_i\|$, we have
\[\|T(x_1,\dots,x_n)\|^2=\sum_{i=1}^{n}\|T_ix_i\|^2\leq c^2\sum_{i=1}^{n}\|x_i\|^2=c^2\|(x_1,\dots,x_n)\|^2\]
so $T$ is bounded and $\|T\|\leq c$. However, for each $i=1,\dots,n$ and $x\in H_i$,
\[\|T_ix\|=\|T(0,\dots,x\dots,0)\|\leq\|T\|\|(0,\dots,x,\dots,0)\|=\|T\|\|x\|\]
thus $\|T_i\|\leq\|T\|$ for all $i$, which implies $c\leq \|T\|$, and so $\|T\|=c$. Since
\begin{align*}
\langle T(x_1,\dots,x_n),(y_1,\dots,y_n)\rangle=\sum_{i=1}^{n}\langle Tx_i,y_i\rangle=\sum_{i=1}^{n}\langle x_i,T^*y_i\rangle=\langle(x_1,\dots,x_n),(T_1^*y_1,\dots,T_n^*y_n)\rangle,
\end{align*}
it follows that $T^*=\bigoplus_{i=1}^{n}T_i^*$. We have now proved that
\[\|\bigoplus_{i=1}^{n}T_i\|=\sup_{1\leq i\leq n}\|T_i\|,\quad \Big(\bigoplus_{i=1}^{n}T_i\Big)^*=\bigoplus_{i=1}T_i^*.\]

So far, we have considered direct sums of finite families of Hilbert spaces. With slight modifications, the same ideas apply also to infinite families. Given Hilbert spaces $\{H_s:s\in S\}$, let $\bigoplus_sH_s$ be the subset of $\prod_sH_s$ consists of all $(x_s)$ such that $\sum_s\|x_s\|^2<+\infty$. An inner product on $H$ is defined by
\[\langle(x_s),(y_s)\rangle=\sum_s\langle x_s,y_s\rangle.\]
We assert that $H$ is complete and is therefore a Hilbert space. For this, suppose that $(x^{n})$ is a Cauchy sequence in $\bigoplus_sH_s$. Given any positive real number $\eps$, there is a positive integer $N$ such that $\|x^{(m)}-x^{(n)}\|<\eps$ whenever $n,m\geq N$. From this, $\|x^{(m)}_s-x^{(n)}_s\|<\eps$ for all $s\in S$ and $n,m\geq N$. Therefore $(x^{(m)}_s)$ is a Cauchy sequence in $H_s$, and has a limit $x_s$. It is easy to see $\sum_{a\in F}\|x_s^{(n)}-x_s\|^2<\eps^2$ for all finite subset of $F$ $n\geq N$, and thus $\sum_s\|x_s^{(n)}-x_s\|^2<\eps^2$. This shows $(x_s)\in H$ and $(x^{(n)}_s)\to(x_s)$ in $\bigoplus_sH_s$. Thus $\bigoplus_sH_s$ is complete, so is a Hilbert space. Similar to the finite case, we can identify each $H_s$ as a subspace of $\bigoplus_sH_s$, and $\bigoplus_sH_s=\bigvee_sH_s$.\par
If $\{H_s\}$ is a family of mutually orthogonal subspaces of a Hilbert space $H$ and $H=\bigvee_sH_s$, the corresponding projections form an orthogonal family $\{P_s\}$ with (strong-operator convergent) sum $I$. Just as in the case of finite direct sums, the equation $Ux=(P_sx)$ defines an isomorphism $U$ from $H$ onto $\bigoplus_sH_s$, and we consider $H$ as an "internal" direct sum of the family $\{H_s\}$.\par
Suppose next that $H_s$, $K_s$ are Hilbert spaces, and $T_s\in\mathcal{B}(H_s,K_s)$ for each $s\in S$. If $c=\sup_{s\in S}\|T_s\|<+\infty$, then the equation $T(x_s)=(T_sx_s)$ defines a bounded linear operator $T$ from $\bigoplus_sH_s$ into $\bigoplus_sK_s$. We call $T$ the \textbf{direct sum} $\bigoplus_sT_s$ of the family $\{T_s\}$. Just as in the case of finite direct sums, we have $\|T\|=c$ and $T^*=\bigoplus_sT_s^*$ and
\[\bigoplus{s}(aA_s+bB_s)=a\bigoplus_{s}A_s+b\bigoplus_{s}B_s,\quad \Big(\bigoplus_{s}C_s\Big)\Big(\bigoplus_{s}B_s\Big)=\bigoplus_{s}C_sB_s\]
where $A_s,B_s\in\mathcal{B}(H_s,K_s)$, $C_s\in\mathcal{B}(K_s,L_s)$, and $a,b\in\C$.
\begin{example}\label{L^2 space disjoint union}
Let $\{(X_s,\mathcal{A}_s,\mu_s):s\in S\}$ be a family of measure spaces and define
\[X=\coprod_sX_s,\quad \mathcal{A}=\{\Delta\sub X:\Delta\cap X_s\in\mathcal{A}_s\}.\]
Let $\mu$ be the measure on $X$ defined by
\[\mu(\Delta)=\sum_s\mu(\Delta\cap X_s).\]
Then every function $f$ on $X$ can be written into $f=\sum_sf_s$ where $f_s$ is a function on $X_s$, and $f\in\mathcal{L}^0(X,\mathcal{A},\mu)$ if and only if $f_s\in\mathcal{L}^0(X_s,\mathcal{A}_s,\mu_s)$ for all $s$. From the definition of the measure $\mu$, it is not hard to see that $L^p(X,\mathcal{A},\mu)=\bigoplus_sL^p(X_s,\mathcal{A}_s,\mu_s)$ for $0<p\leq+\infty$, where the norm on $\bigoplus_sL^p(X_s,\mathcal{A}_s,\mu_s)$ is given by
\[\|f\|_p=\Big(\int |f|^p\,d\mu\Big)^{1/p}=\Big(\int \sum_s|f_s|^p\,d\mu\Big)^{1/p}=\Big(\sum_s\int |f|^p\,d\mu\Big)^{1/p}=\Big(\sum_s\|f_s\|_p^p\Big)^{1/p}.\]
In particular, for $p=2$ it is easy to see that $L^2(X,\mathcal{A},\mu)$ is isomorphic to $\bigoplus_sL^2(X_s,\mathcal{A}_s,\mu_s)$ as Hilbert spaces.
\end{example}
\begin{example}
When $H_s$ is the one-dimensional Hilbert space $\C$ for each $s\in S$, the direct sum $\bigoplus_sH_s$ reduces to the Hilbert space $\ell^2(S)$.
\end{example}
\subsubsection{Tensor products}
Suppose that $H_1,\dots,H_n$ are Hilbert spaces and $\varphi$ is a mapping from the cartesian product $H_1\times\cdots\times H_n$ into the scalar field $\C$. We say $\varphi$ is a \textbf{bounded multilinear functional} on $H_1\times\cdots\times H_n$ if $\varphi$ is linear in each of its variables (while the other variables remain fixed), and there is a real number $c$ such that
\[|\varphi(x_1,\dots,x_n)|\leq c\|x_1\|\cdots\|x_n\|.\]
When this is so, the least such constant $c$ is denoted by $\|\varphi\|$. Then $\varphi$ is a continuous mapping from $H_1\times\cdots\times H_n$ into $\C$, relative to the product of the norm topologies on the Hilbert spaces.
\begin{proposition}\label{Hilbert-Schmidt functional def}
Suppose that $H_1,\dots,H_n$ are Hilbert spaces and $\varphi$ is a bounded multilinear functional on $H_1\times\cdots\times H_n$.
\begin{itemize}
\item[(a)] The sum
\[\sum_{e_i\in E_i}|\varphi(e_1,\dots,e_n)|^2\]
has the same (finite or infinite) value for orthonormal bases $E_i$ of $H_i$.
\item[(b)] If $K_1,\dots,K_n$ are Hilbert spaces, $A_i\in\mathcal{B}(H_i,K_i)$, $\psi$ is a bounded multilinear functional on $H_1,\dots,H_n$ and $\varphi$ is defined by
\[\varphi(x_1,\dots,x_n)=\psi(A_1x_1,\dots,A_nx_n)\]
then 
\[\sum_{e_i\in E_i}|\varphi(e_1,\dots,e_n)|^2\leq\|A_1\|^2\cdots\|A_n\|^2\sum_{s_i\in S_i}|\psi(s_1,\dots,s_n)|^2\]
when $E_i$ and $S_i$ are orthonormal bases of $H_i$ and $K_i$, respectively.
\end{itemize}
\end{proposition}
\begin{proof}
Clearly (b) implies (a) by taking $K_i=H_i$ and $A_i=I$, so we only prove (b). For this, suppose that $1\leq j\leq n$ and fix vectors $e_i\in E_i$, $s_i\in S_i$. The map
\[\Lambda_j:K_j\to\C,\quad y\mapsto\psi(A_1e_1,\dots,A_{j-1}e_{j-1},y,s_{j+1},\dots,s_n)\]
is a bounded linear functional on $K_j$, so there exists $w\in K_j$ such that $\Lambda_j(y)=\langle y,w\rangle$. From Parseval's equation, we then get
\begin{align*}
\sum_{e_j\in E_j}|\Lambda_j(A_je_j)|^2&=\sum_{e_j\in E_j}|\langle A_je_j,w\rangle|^2=\sum_{e_j\in E_j}|\langle e_j,A_j^*w\rangle|^2=\|A_j^*w\|^2\leq\|A_j\|^2\|w\|^2\\
&=\|A_j\|^2\sum_{s_j\in S_j}|\langle s_j,w\rangle|^2=\|A_j\|^2\sum_{s_j\in S_j}|\Lambda_j(s_j)|^2.
\end{align*}
The claim now follows by an inductional argument.
\end{proof}
A map $\varphi;H_1\times\cdots\times H_n\to\C$ is called a \textbf{Hilbert-Schmidt functional} on $H_1\times\cdots\times H_n$ if it is a bounded multilinear functional and the sum in Proposition~\ref{Hilbert-Schmidt functional def} is finite for one (and hence each) choice of the orthonormal bases $E_i$ in $H_i$.
\begin{proposition}\label{Hilbert-Schmidt functional is Hilbert space}
If $H_1,\dots,H_n$ are Hilbert spaces, then the set $\mathcal{HS}(H_1\times\cdots\times H_n)$ of all Hilbert-Schmidt functionals on $H_1\times\cdots\times H_n$ is itself a Hilbert space when the inner product is defined by
\[\langle\varphi,\psi\rangle=\sum_{e_i\in E_i}\varphi(e_1,\dots,e_n)\widebar{\psi(e_1,\dots,e_n)}\]
where $E_i$ is an orthonormal basis for $H_i$.
\end{proposition}
\begin{proof}
It is easy to see $\mathcal{HS}(H_1\times\cdots\times H_n)$ is a vector space, and the sum in Proposition~\ref{Hilbert-Schmidt functional def} defines a norm which is induced by the prescribed inner product. The completeness of $\mathcal{HS}(H_1\times\cdots\times H_n)$ is a routine verification.
\end{proof}
\begin{proposition}\label{Hilbert-Schmidt functional orthonormal basis}
Let $H_1,\dots,H_n$ be Hilbert spaces. For each $v_1\in H_1,\dots,v_n\in H_n$, the equation
\[\varphi_{v_1,\dots,v_n}(x_1,\dots,x_n)=\langle x_1,v_1\rangle\cdots\langle x_n,v_n\rangle\]
defines an element of $\mathcal{HS}(H_1\times\cdots\times H_n)$ and
\[\langle\varphi_{v_1,\dots,v_n},\varphi_{w_1,\dots,w_n}\rangle=\langle w_1,v_1\rangle\cdots\langle w_n,v_n\rangle.\]
If $E_i$ is an orthonormal basis for $H_i$, then the set $\{\varphi_{e_1,\dots,e_n}:e_i\in E_i\}$ is an orthonormal basis for $\mathcal{HS}(H_1\times\cdots\times H_n)$. Therefore, there is a unitary map
\[U:\mathcal{HS}(H_1\times\cdots\times H_n)\to\ell^2(E_1\times\cdots\times E_n),\quad\varphi\mapsto\varphi|_{E_1\times\cdots\times E_n}.\]
\end{proposition}
\begin{proof}
The first claim follows from the Cauchy-Schwarz inequality. We now prove that $\{\varphi_{e_1,\dots,e_n}:e_i\in E_i\}$ is an orthonormal basis. First, let $\psi\in\mathcal{HS}(H_1\times\cdots\times H_n)$, then for any $w_1\in e_1,\dots,w_n\in E_n$, we have
\[\langle\psi,\varphi_{w_1,\dots,w_n}\rangle=\sum_{e_i\in E_i}\psi(e_1,\dots,e_n)\widebar{\varphi_{w_1,\dots,w_n}(e_1,\dots,e_n)}=\psi(w_1,\dots,w_n).\]
and therefore
\[\sum_{e\in E_1\times\cdots\times E_n}\langle\psi,\varphi_{e_1,\dots,e_n}\rangle\varphi_{e_1,\dots,e_n}=\sum_{e_i\in E_i}\psi(e_1,\dots,e_n)\varphi_{e_1,\dots,e_n}=\psi|_{E_1\times\cdots\times E_n}.\]
Since for each $i$, the set $E_i$ is an orthonormal basis for $H_i$, $\varphi=0$ if and only if $\varphi|_{E_1\times\cdots\times E_n}=0$, if and only if $\langle\psi,\varphi_{e_1,\dots,e_n}\rangle=0$. The maximality now follows from Proposition~\ref{Hilbert space orthonormal basis iff} and Riesz-Finsher theorem.\par
Finally, let $v_i,w_i\in H_i$. Then by Parseval's equation and absolute convergence,
\begin{equation*}
\begin{aligned}
\langle\varphi_{v_1,\dots,v_n},\varphi_{w_1,\dots,w_n}\rangle&=\sum_{e_i\in E_i}\varphi_{v_1,\dots,v_n}(e_1,\dots,e_n)\widebar{\varphi_{w_1,\dots,w_n}(e_1,\dots,e_n)}\\
&=\sum_{e_i\in E_i}\langle e_1,v_1\rangle\cdots\langle e_n,v_n\rangle\widebar{\langle e_1,w_1\rangle\cdots\langle e_n,w_n\rangle}\\
&=\Big(\sum_{e_1\in E_1}\langle e_1,v_1\rangle\widebar{\langle e_1,w_1\rangle}\Big)\cdots\Big(\sum_{e_n\in E_n}\langle e_n,v_n\rangle\widebar{\langle e_n,w_n\rangle}\Big)\\
&=\langle w_1,v_1\rangle\cdots\langle w_n,v_n\rangle.
\end{aligned}
\end{equation*}
Thus the orthonormality of $E_1,\dots,E_n$ implies that of $\{\varphi_{v_1,\dots,e_n}:e_i\in E_i\}$.
\end{proof}
In order to simplify the treatment of conjugate-linear mappings, we introduce the notion of the "conjugate" of a Hilbert space. The conjugate Hilbert space $\widebar{H}$ is the same abelian group $H$, with the scalar multiplication and inner product given by
\[(a,x)\mapsto\bar{a}x,\quad (x,y)\mapsto\widebar{\langle x,y\rangle}=\langle y,x\rangle.\]
Of course, the conjugate Hilbert space of $\widebar{H}$ is $H$. A subset of a Hilbert space is linearly independent, or orthogonal, or orthonormal, or an orthonormal basis of that space, if and only if it has the same property relative to the conjugate Hilbert space. If $H_1$ and $H_2$ are Hilbert spaces and $T$ is a mapping from the set $H_1$ into the set $H_2$, linearity of $T:H_1\to H_2$ is equivalent to linearity of $T:\widebar{H}_1\to\widebar{H}_2$, and corresponds to conjugate-linearity of $T:\widebar{H}_1\to H_2$ and of $T:H_1\to\widebar{H}_2$.\par
Now let $H_1,\dots,H_n$ and $K$ be Hilbert spaces and suppose $L$ is a mapping from $H_1\times\cdots\times H_n$ into $K$. We say $L$ is a \textbf{bounded multilinear mapping} if it is linear in each of its variables (while the other variables remain fixed), and there is a real number $c$ such that
\[\|L(x_1,\dots,x_n)\|\leq c\|x_1\|\cdots\|x_n\|.\]
In these circumstances, the least such constant $c$ is denoted by $\|L\|$. We say $L$ is a \textbf{weak Hilbert-Schmidt map} if it is a bounded multilinear mapping such that for each $u\in K$, the mapping $L_u$ defined by
\begin{align}\label{weak Hilbert-Schmidt map def}
L_u(x_1,\dots,x_n)=\langle L(x_1,\dots,x_n),u\rangle
\end{align}
is a Hilbert-Schmidt functional on $H_1\times\cdots\times H_n$. Note that in this case, by an application of the closed graph theorem to the mapping \[L:\widebar{K}\to\mathcal{HS}(H_1\times\cdots\times H_n),\quad u\mapsto L_u\]
we see the map $L$ is continous. We use $\|L\|_2$ to denote its operator norm.
\begin{theorem}\label{Hilbert space tensor product exist and unique}
Suppose that $H_1,\dots,H_n$ are Hilbert spaces.
\begin{itemize}
\item[(a)] There is a Hilbert space $H$ and a weak Hilbert-Schmidt map $p:H_1\times\cdots\times H_n\to H$ with $\|p\|_2=1$ satisfying the following property: given any weak Hilbert-Schmidt map $L:H_1\times\cdots\times H_n\to K$, there is a unique bounded linear mapping $T:H\to K$ such that $L=Tp$ and $\|L\|_2=\|T\|$.
\[\begin{tikzcd}
H_1\times\cdots\times H_n\ar[r,"p"]\ar[rd,swap,"L"]&H\ar[d,dashed,"\exists!"]\\\
&K
\end{tikzcd}\]
Moreover, if $(H_1,p_1)$ and $(H_2,p_2)$ has the attributed property, then there is a unitary transformation $U$ from $H_1$ onto $H_2$ such that $p_2=Up_1$.
\item[(b)] If $E_i$ is an orthonormal basis of $H_i$, then $\{p(e_1,\dots,e_n):e_i\in E_i\}$ is an orthonormal basis of $H$ and for $v_i,w_i\in H_i$, we have
\[\langle p(v_1,\dots,v_n),p(w_1,\dots,w_n)\rangle=\langle v_1,w_1\rangle\cdots\langle v_n,w_n\rangle.\] 
\end{itemize}
\end{theorem}
\begin{proof}
Let $H=\mathcal{HS}(\widebar{H}_1\times\cdots\times\widebar{H}_n)$. Then $H$ is a Hilbert space. With $v_1\in H_1,\dots,v_n\in H_n$, let $p(v_1,\dots,v_n)\in H$ be the Hilbert-Schmidt functional defined by
\[p(v_1,\dots,v_n)(x_1,\dots,x_n)=\widebar{\langle x_1,v_1\rangle}\cdots\widebar{\langle x_n,v_n\rangle}.\]
Since $E_i$ is an orthonormal basis of $H_i$, by Proposition~\ref{Hilbert-Schmidt functional orthonormal basis} the set $\{p(e_1,\dots,e_n):e_i\in E_i\}$ is an orthonormal basis of $H$, and that
\[\langle p(v_1,\dots,v_n),p(w_1,\dots,w_n)\rangle=\widebar{\langle w_1,v_1\rangle\cdots\langle w_n,v_n\rangle}=\langle v_1,w_1\rangle\cdots\langle v_n,w_n\rangle.\]
Thus $p$ is a bounded multilinear map. We prove next that $p$ is a weak Hilbert-Schmidt map. For this, suppose that $\varphi\in H$, and consider the bounded multilinear functional $p_\varphi$ as in $(\ref{weak Hilbert-Schmidt map def})$. With $w_1\in E_1,\dots,w_n\in E_n$, we have
\begin{align*}
p_\varphi(w_1,\dots,w_n)=\sum_{e_i\in E_i}p(w_1,\dots,w_n)(e_1,\dots,e_n)\widebar{\varphi(e_1,\dots,e_n)}=\widebar{\varphi(w_1,\dots,w_n)}.
\end{align*}
This implies $p_\varphi=\widebar{\varphi}$, so $p$ is a weak Hilbert-Schmidt map and $\|p\|_2=1$.\par
Suppose next that $L$ is a weak Hilbert-Schmidt map from $H_1\times\cdots\times H_n$ into another Hilbert space $K$. For $u\in K$, let $L_u$ be defined by $(\ref{weak Hilbert-Schmidt map def})$. Then for any $\varphi\in H$ we have
\begin{align*}
|\langle\sum_{e_i\in E_i}\varphi(e_1,\dots,e_n)L(e_1,\dots,e_n),u\rangle|&\leq\sum_{e_i\in E_i}|\varphi(e_1,\dots,e_n)||L_u(e_1,\dots,e_n)|\leq\|u\|\|L\|_2\|\varphi\|.
\end{align*}
It follows from the Cauchy criterion that the (unordered) sum
\[\sum_{e_i\in E_i}\varphi(e_1,\dots,e_n)L(e_1,\dots,e_n)\]
converges to an element $T\varphi$ of $K$, and $\|T\varphi\|\leq\|L\|_2\|\varphi\|$. Thus $T$ is a bounded linear operator from $H$ into $K$, and $\|T\|\leq\|L\|_2$. When $w_1\in E_1,\dots,w_n\in E_n$, we have
\begin{align*}
Tp(w_1,\dots,w_n)=\sum_{e_i\in E_i}p(w_1,\dots,w_n)(e_1,\dots,e_n)L(e_1,\dots,e_n)=L(w_1,\dots,w_n).
\end{align*}
Since $L$ and $Tp$ are both bounded and multilinear and $E_i$ has closed linear span $H_i$, it follows that $L=Tp$.\par
The condition $Tp=L$ uniquely determines the bounded linear operator $T$, because the range of $p$ contains the orthonormal basis $p(E_1\times\cdots\times E_n)$ of $H$. For each $u\in K$, Parseval's equation gives
\begin{align*}
\|L_u\|^2&=\sum_{e_i\in E_i}|\langle L(e_1,\dots,e_n),u\rangle|^2=\sum_{e_i\in E_i}|\langle Tp(e_1,\dots,e_n),u\rangle|^2\\
&=\sum_{e_i\in E_i}|\langle p(e_1,\dots,e_n),T^*u\rangle|^2=\|T^*u\|^2\leq\|T\|^2\|u\|^2.
\end{align*}
so $\|L\|_2\leq\|T\|$ and we get $\|L\|_2=\|T\|$.\par
Finally, we prove the uniqueness part. If $(H,p)$ and $(\widetilde{H},\widetilde{p})$ both has the property in (a), then there exists unique weak Hilbert-Schmidt maps $U:H\to\widetilde{H}$ and $V:\widetilde{H}\to H$ such that $\|U\|=\|\widetilde{p}\|=1$, $\|V\|=\|p\|=1$, and the following diagram commutes
\[\begin{tikzcd}
&\widetilde{H}\ar[d,dashed,"V"]\\
H_1\times\cdots\times H_n\ar[r,"p"]\ar[rd,swap,"\widetilde{p}"]\ar[ru,"\widetilde{p}"]&H\ar[d,dashed,"U"]\\\
&\widetilde{H}
\end{tikzcd}\]
Since $UV$ and $VU$ are both weak Hilbert-Schmidt maps, it follows from the uniqueness part of (a) that $UV=VU=I$. Thus $U$ and $V$ are bijective isometris, hence unitary maps by Proposition~\ref{Hilbert space unitary iff}.
\end{proof}
The Hilbert space $H$ together with the multilinear mapping $p:H_1\times\cdots\times H_n\to H$ is uniquely determined (up to isomorphism) by the "universal" property set out in Theorem~\ref{Hilbert space tensor product exist and unique}. We call $H$ the \textbf{Hilbert tensor product} of $H_1,\dots,H_n$, denoted by $H_1\otimes\cdots\otimes H_n$, and refer to $p$ as the canonical (product) mapping from $H_1\times\cdots\times H_n$ into $H_1\otimes\cdots\otimes H_n$. The vector $p(x_1,\dots,x_n)$ is usually denoted by $x_1\otimes\cdots\otimes x_n$. Finite linear combinations of these "simple tensors" form a dense subspace of $H_1\otimes\cdots\otimes H_n$, as shown in part (b). In particular, we see
\[\langle x_1\otimes\cdots\otimes x_n,y_1\otimes\cdots\otimes y_n\rangle=\langle x_1,y_1\rangle\cdots\langle x_n,y_n\rangle.\]
We now consider the associativity of tensor products.
\begin{proposition}\label{Hilbert space tensor product associativity}
If $H_1,\dots,H_{m+n}$ are Hilbert spaces, there is a unique unitary transformation 
\[U:H_1\otimes\cdots\otimes H_{m+n}\to(H_1\otimes\cdots\otimes H_{m})\otimes(H_{m+1}\otimes\cdots\otimes H_{m+n})\]
such that
\[U(x_1\otimes\cdots\otimes x_{m+n})=(x_1\otimes\cdots\otimes x_{m})\otimes(x_{m+1}\otimes\cdots\otimes x_{m+n})\]
whenever $x_i\in H_i$.
\end{proposition}
\begin{proof}
Since the set of all simple tensors has dense linear span, there is at most one unitary operator $U$ with the stated property; so it suffices to prove the existence of such an isomorphism. For this, let $p_1$ and $p_2$ denote the canonical maps
\[p_1:H_1\times\cdots\times H_{m+n}\to K_1:=H_1\otimes\cdots\otimes H_{m+n}\]
and
\[p_2:H_1\times\cdots\times H_{m+n}\to K_2:=(H_1\otimes\cdots\otimes H_m)\otimes(H_{m+1}\otimes\cdots\otimes H_{m+n}).\]
The ranges of $p_1$ and $p_2$ contain orthonormal bases of $K_1$ and $K_2$, respectively, and so generate dense subspaces $M_1$ and $M_2$. If $x_i,y_i\in H_i$, it is easy to see
\begin{align*}
\langle p_1(x_1,\dots,x_{m+n}),p_1(x_1,\dots,x_{m+n})\rangle=\langle p_2(x_1,\dots,x_{m+n}),p_2(x_1,\dots,x_{m+n})\rangle.
\end{align*}
and therefore the $U$ prescribed in the proposition is a norm-preserving map from $M_1$ to $M_2$. By continuity, $U$ extends to an isomorphism from $K_1$ onto $K_2$, and has the same expression on $H_1\times\cdots\times H_n$. This proves the claim.
\end{proof}
By use of the associativity established in the preceding proposition,
questions concerning the $n$-fold tensor product of Hilbert spaces can usually be reduced to the particular case $n=2$. Our next few results are directed toward this case. We consider first the question oflinear dependence of simple tensors.
\begin{proposition}\label{Hilbert space tensor product is algebraic}
Suppose that $H_1$ and $H_2$ are Hilbert spaces, $H=H_1\otimes H_2$, and $H_0$ is the dense subspace of $H$ generated by the simple tensors.
\begin{itemize}
\item[(a)] If $x_1,\dots,x_n\in H_1$ and $y_1,\dots,y_n\in H_2$, then $\sum_ix_i\otimes y_i=0$ if and only if there is an $n\times n$ complex matrix $A$ such that
\[A^T\bm{x}=0,\quad A\bm{y}=\bm{y},\]
where $\bm{x}=(x_1,\dots,x_n)^T$ and $\bm{y}=(y_1,\dots,y_n)^T$.
\item[(b)] If $L$ is a bilinear mapping from $H_1\times H_2$ into a complex vector space $K$, there is a (unique) linear mapping $T$ from $H_0$ into $K$ such that $T(x\otimes y)=L(x,y)$ for each $x\in H_1$, $y\in H_2$.
\end{itemize}
\end{proposition}
\begin{proof}
Let $\varphi$ be a bilinear map on $H_1\times H_2$. For $x_1,\dots,x_n\in H_1$ and $y_1,\dots,y_n\in H_2$, define
\[\varphi(\bm{x},\bm{y}):=\sum_i\varphi(x_i,y_i).\]
It is easy to see for any matrix $A=(a_{ij})$, we have
\[\varphi(\bm{x},A\bm{y})=\sum_{j}\varphi(x_j,\sum_ka_{jk}y_k)=\sum_{k}\varphi(\sum_ja_{jk}x_j,y_k)=\varphi(A^T\bm{x},\bm{y}).\]
If there is a matrix $A$ with the stated properties, then bilinearity of the mapping $(x,y)\mapsto x\cdot y=x\otimes y$ implies that
\[\otimes(\bm{x},\bm{y})=\otimes(\bm{x},A\bm{y})=\otimes(A^T\bm{x},\bm{y})=0.\]
Conversely, suppose that $\otimes(\bm{x},\bm{y})=0$. If $v_1,\dots,v_r$ is an orthonormal basis of the linear subspace of $H_2$ generated by $y_1,\dots,y_n$, we can choose an $n\times r$ matrix $B$ and an $r\times n$ matrix $C$ such that
\[\bm{y}=B\bm{v},\quad \bm{v}=C\bm{y}\]
where $\bm{v}=(v_1,\dots,v_r)^T$. With $A=BC$, we then have $\bm{y}=A\bm{y}$, and so
\[0=\otimes(\bm{x},\bm{y})=\otimes(\bm{x},B\bm{v})=\otimes(B^T\bm{x},\bm{v}).\]
Write $B^T\bm{x}=(u_1,\dots,u_r)^T$. Then since $v_1,\dots,v_r$ are orthonormal, we have
\[0=\langle\otimes(B^T\bm{x},\bm{v}),\otimes(B^T\bm{x},\bm{v})\rangle=\sum_{i,j}\langle u_i\otimes v_i,u_j\otimes v_j\rangle=\sum_{i,j}\langle u_i,u_j\rangle\langle v_i,v_j\rangle=\sum_{i=1}^{r}\|u_i\|^2.\]
Thus $u_1=\cdots=u_r=0$, and $A^T\bm{x}=C^TB^T\bm{x}=0$.\par
Suppose that $L$ is a bilinear mapping from $H_1\times H_2$ into $K$. If $x_1,\dots,x_n\in H_1$, $y_1,\dots,y_n\in H_2$, and $\sum_ix_i\otimes y_i=0$, we can choose a matrix $A$ as in (a), and so
\[\sum_iL(x_i,y_i)=L(\bm{x},\bm{y})=L(\bm{x},A\bm{y})=L(A^T\bm{x},\bm{y})=0.\]
Therefore for $x_i,u_i\in H_1$, $y_i,v_i\in H_2$ such that $\sum_ix_i\otimes y_i=\sum_iu_i\otimes v_i$, we have
\[\sum_iL(x_i,y_i)=\sum_iL(u_i,v_i).\]
From this, the equation
\[T(\sum_ix_i\otimes y_i):=\sum_iL(x_i,y_i)\]
then defined (unambiguously) a linear operator $T$ from $H_0$ into $K$.
\end{proof}
\begin{remark}
The first part of Proposition~\ref{Hilbert space tensor product is algebraic} asserts, in effect, that the only finite families of simple tensors that have sum zero are those that are "forced" to have zero sum by the bilinearity of the mapping $(x,y)\mapsto x\otimes y$. From this, $H_0$ can be identified with the algebraic tensor product of $H_1$ and $H_2$. The second part of the proposition shows that $H_0$ has the "universal" property that characterizes the algebraic tensor product.\par
We can identify $H$ with the completion of its dense subspace $H_0$. Accordingly, the Hilbert tensor product $H_1\otimes H_2$ can be viewed as the completion of the algebraic tensor product $H_0$, relative to the unique inner product on $H_0$ that satisfies
\[\langle x_1\otimes y_1,x_2\otimes y_2\rangle=\langle x_1,x_2\rangle\langle y_1,y_2\rangle.\]
\end{remark}
We show next that the tensor product of Hilbert spaces $H$ and $K$ can be represented as a certain linear space of operators from the conjugate Hilbert space $\widebar{H}$ into $K$. For this, note first that the equation
\[b_T(x,y)=\langle Tx,y\rangle,\quad x\in H,y\in K\]
defines a injective linear mapping $T\mapsto b_T$ from $\mathcal{B}(H,K)$ onto the set o f all bounded bilinear functionals on $H\times\widebar{K}$ (since these are, precisely, the bounded conjugate-bilinear functionals on $H\times K$). With $T\in\mathcal{B}(H,K)$, it follows by applying Proposition~\ref{Hilbert-Schmidt functional def} to $b$, that the (finite or infinite) sum
\[\sum_{x\in E,y\in S}|\langle Tx,y\rangle|^2=\sum_{x\in E,y\in S}|\langle x,T^*y\rangle|^2\]
has the same value, for all orthonormal bases $E$ of $H$ and $S$ of $K$. From Parseval's equation, this sum can be written also in the alternative forms
\[\sum_{x\in E}\|Tx\|^2=\sum_{y\in S}\|T^*y\|^2.\]
We say $T$ is a \textbf{Hilbert-Schmidt operator} if the value of the sums is finite; equivalently, $T$ is a Hilbert-Schmidt operator if and only if $b_T$ is a Hilbert-Schmidt functional on $H\times\widebar{K}$.\par
With $\mathcal{HS}(H\times\widebar{K})$ the linear space of all Hilbert-Schmidt functionals on $H\times\widebar{K}$, the Hilbert-Schmidt operators from $H$ into $K$ form a linear subspace $\mathcal{HS}(H,K)$ of $\mathcal{B}(H,K)$. By means of the mapping $b$, the Hilbert space structure on $\mathcal{HS}(H\times\widebar{K})$ can be transferred to $\mathcal{HS}(H,K)$. Accordingly, $\mathcal{HS}(H,K)$ is a Hilbert space, when the inner product defined by
\[\langle T,S\rangle=\sum_{x\in E,y\in S}\langle Tx,y\rangle\langle y,Sx\rangle=\sum_{x\in E}\langle Tx,Sx\rangle=\sum_{y\in S}\langle S^*x,T^*y\rangle.\]
An important fact is that the Hilbert-Schmidt norm does not coincide with the operator norm. However, the following property is ture.
\begin{proposition}\label{Hilbert-Schmidt operator ideal prop}
Let $A\in\mathcal{B}(H,K)$, $T\in\mathcal{HS}(K,L)$, and $B\in\mathcal{B}(L,M)$. Then $BTA$ is a Hilbert-Schmidt operator with $\|BTA\|_2\leq\|B\|\|T\|_2\|A\|$.
\end{proposition}
\begin{proof}
Let $E$ be an orthonormal basis for $H$ and $S$ be an orthonormal basis for $L$, then we have the inequality
\begin{align*}
\sum_{x\in E}\|BTAx\|^2&\leq\|B\|^2\sum_{x\in E}\|TAx\|^2=\|B\|^2\sum_{y\in S}\|A^*T^*y\|^2\\
&\leq\|B\|^2\|A\|^2\sum_{y\in S}\|T^*y\|^2=\|B\|^2\|T\|_2^2\|A\|^2
\end{align*}
and so the claim follows.
\end{proof}
The identification of $H\otimes K$ with the Hilbert space of all Hilbert-Schmidt operators from $\widebar{H}$ into $K$ is described in the proposition that follows.
\begin{proposition}\label{Hilbert space tensor product is HS-operator}
If $H$ and $K$ are Hilbert spaces, then for each $x\in H$ and $y\in K$, the equation
\[T_{x,y}u=\widebar{\langle u,x\rangle}y=\langle x,u\rangle y\]
defines a Hilbert-Schmidt operator $T_{x,y}$ from $\widebar{H}$ into $K$ and induces a unitary map
\[U:H\otimes K\to\mathcal{HS}(\widebar{H},K),\quad x\otimes y\mapsto T_{x,y}.\]
\end{proposition}
\begin{proof}
We know that $H\otimes K=\mathcal{HS}(\widebar{H}\times\widebar{K})$. Moreover, when $x\in H$ and $y\in K$, $x\otimes y=p(x,y)$ is the bilinear functional $\varphi_{x,y}$ defined by
\[\varphi_{x,y}(u,v)=\langle x,u\rangle\langle y,v\rangle.\]
Also, we have an isomorphism from $\mathcal{HS}(\widebar{H},K)$ to $\mathcal{HS}(\widebar{H}\times\widebar{K})$, which is given by $T\mapsto b_T$. It is apparent that $T_{x,y}$, as defined in the proposition, is the bounded linear operator from $\widebar{H}$ into $K$ that corresponds to the bilinear functional $\varphi_{x,y}$. Since $\varphi_{X,y}\in\mathcal{HS}(\widebar{H}\times\widebar{K})$, it follows that $T_{x,y}\in\mathcal{HS}(\widebar{H},K)$, and $U(x\otimes y)=U\varphi_{x,y}=T_{x,y}$.
\end{proof}
We now give some examples of tensor products of Hilbert spaces.
\begin{example}
With $X$ and $Y$ arbitrary sets, we can associate with each $f\in\ell^2(X)$ and $g\in\ell^2(Y)$ a complex-valued function $p_{f,g}$ defined on $X\times Y$ by
\[p_{f,g}(x,y)=f(x)g(y).\]
We shall show that there is a (unique) unitary transformation $U$ from $\ell^2(X)\otimes\ell^2(Y)$ onto $\ell^2(X\times Y)$ such that
\[U(f\otimes g)=p_{f,g}.\]
For this, note that $p_{f,g}\in\ell^2$ since
\begin{align*}
\sum_{(x,y)\in X\times Y}|p_{f,g}(X,y)|^2=\sum_{x\in X}\sum_{y\in Y}|f(x)|^2|g(y)|^2=\|f\|_2^2\|g\|_2^2<+\infty
\end{align*}
so the map $U$ is an isometry. Since its image contains the orthonormal basis of $\ell^2(X\times Y)$ and is closed, it follows that $U$ is surjective, hence a unitary map.
\end{example}
\begin{example}
We now consider the tensor product of the $L^2$ spaces associated with $\sigma$-finite measure spaces $(X,\mathcal{A},\mu)$ and $(Y,\mathcal{B},\nu)$. We show that this can be identified with the $L^2$ space of the product measure space $(X\times Y,\mathcal{A}\otimes\mathcal{B},\mu\times\nu)$, in such a way that $f\otimes g$ corresponds to the function $p_{f,g}$ defined by
\[p_{f,g}(x,y)=f(x)g(y).\]
Note that $p_{f,g}\in L^2(\mu\times\nu)$ since
\[\iint_{X\times Y}|p_{f,g}|^2=\int_X|f|^2\int_Y|g|^2.\]
With a similar argument, we see the map $U$ defined by $U(f\otimes g)=p_{f,g}$ is a unitary map.
\end{example}
We now introduce tensor products of bounded linear operators.
\begin{proposition}\label{Hilbert space operator tensor product}
If $H_1,\dots,H_n$, $K_1,\dots,K_n$ are Hilbert spaces and $A_i\in\mathcal{B}(H_i,K_i)$, then there is a unique bounded linear operator $A$ from $H_1\otimes\cdots\otimes H_n$ into $K_1\otimes\cdots\otimes K_n$ such that
\[A(x_1\otimes\cdots\otimes x_n)=A_1x_1\otimes\cdots\otimes A_nx_n.\]
\end{proposition}
\begin{proof}
The canonical mapping $p:K_1\times\cdots\times K_n\to K:=K_1\otimes\cdots\otimes K_n$ is a weak Hilbert-Schmidt mapping with $\|p\|_2=1$. With $u\in K$ and $p_u$ defined by
\[p_u(z_1,\dots,z_n)=\langle p(z_1,\dots,z_n),u\rangle,\]
$p_u$ is a Hilbert-Schmidt functional on $K$ and $\|p_u\|\leq\|u\|$. The equation
\[\varphi(x_1,\dots,x_n)=p(A_1x_1,\dots,A_nx_n)\]
defines a bounded multilinear mapping $\varphi:H_1\times\cdots\times H_n\to K$ and
\[\varphi_u(x_1,\dots,x_n)=\langle\varphi(x_1,\dots,x_n),u\rangle=\langle p(A_1x_1,\dots,A_nx_n),u\rangle=p_u(A_1x_1,\dots,A_nx_n).\]
It now follows from Proposition~\ref{Hilbert-Schmidt functional def} that $\varphi_u$ is a Hilbert-Schmidt functional on $H_1\times\cdots\times H_n$ with
\[\|\varphi_u\|\leq\|A_1\|\cdots\|A_n\|\|p_u\|\leq\|A_1\|\cdots\|A_n\|\|u\|.\]
Accordingly, $\varphi:H_1\times\cdots\times H_n\to K$ is a weak Hilbert-Schmidt mapping, with $\|\varphi\|_2\leq\|A_1\|\cdots\|A_n\|$. By the universal property of the tensor product, there is a unique bounded linear operator $A$ from $H_1\otimes\cdots\otimes H_n$ into $K$, such that $\varphi=Ap'$, where $p'$ is the canonical mapping from $H_1\times\cdots\times H_n$ into $H_1\otimes\cdots\otimes H_n$. Moreover, $\|A\|=\|\varphi_2\|\leq\|A_1\|\cdots\|A_n\|$. Also,
\[A(x_1\otimes\cdots\otimes x_n)=Ap'(x_1,\dots,x_n)=\varphi(x_1,\dots,x_n)=p(A_1x_1,\dots,A_nx_n)=A_1x_1\otimes\cdots\otimes A_nx_n.\]
This proves the claim.
\end{proof}
The operator $A$ described in Proposition~\ref{Hilbert space operator tensor product} is called the tensor product of $A_1,\dots,A_n$, and denoted by $A_1\otimes\cdots\otimes A_n$. It is apparent that $A_1\otimes\cdots\otimes A_n$ depends linearly on each $A_i$ and that
\[(A_1\otimes\cdots\otimes A_n)(B_1\otimes\cdots\otimes B_n)=(A_1B_1\otimes\cdots\otimes A_nB_n).\]
Also, since
\begin{align*}
\langle(A_1\otimes\cdots\otimes A_n)(x_1\otimes\cdots\otimes x_n),y_1\otimes\cdots\otimes y_n\rangle&=\langle A_1x_1,y_1\rangle\cdots\langle A_nx_n,y_n\rangle
\end{align*}
it follows by linearity and continuity that
\[\langle(A_1\otimes\cdots\otimes A_n)u,v\rangle=\langle u,(A_1^*\otimes\cdots\otimes A_n^*)v\rangle\]
and therefore $(A_1\otimes\cdots\otimes A_n)^*=(A_1^*\otimes\cdots\otimes A_n^*)$. We assert also that $\|A_1\otimes\cdots\otimes A_n\|=\|A_1\|\cdots\|A_n\|$. Indeed, given by any unit vectors $x_i\in H_i$, we have
\begin{align*}
\|A_1\otimes\cdots\otimes A_n\|&=\|A_1\otimes\cdots\otimes A_n\|\|x_1\otimes\cdots\otimes x_n\|\geq\|(A_1\otimes\cdots\otimes A_n)(x_1\otimes\cdots\otimes x_n)\|\\
&=\|A_1x_1\otimes\cdots\otimes A_nx_n\|=\|A_1x_1\|\cdots\|A_nx_n\|.
\end{align*}
Upon taking the supremum of the right-hand side, we obtain $\|A_1\otimes\cdots\otimes A_n\|\geq\|A_1\|\cdots\|A_n\|$; the reverse inequality was noted during the proof of Proposition~\ref{Hilbert space operator tensor product}.\par
Now let $H_1,\dots,H_{m+n}$, $K_1,\dots,K_{m+n}$ be Hilbert spaces and $A_i\in\mathcal{B}(H_i,K_i)$. We can construct isomorphisms
\[U:H_1\otimes\cdots\otimes H_{m+n}\to(H_1\otimes\cdots\otimes H_{m})\otimes(H_{m+1}\otimes\cdots\otimes H_{m+n})\]
\[V:K_1\otimes\cdots\otimes K_{m+n}\to(K_1\otimes\cdots\otimes K_{m})\otimes(K_{m+1}\otimes\cdots\otimes K_{m+n})\]
and it is at once verified that
\[U(A_1\otimes\cdots\otimes A_n)V^{-1}=(A_1\otimes\cdots\otimes A_m)\otimes(A_{m+1}\otimes\cdots\otimes A_{m+n}).\]
This proves the "associativity" of the tensor product of bounded linear operators on Hilbert spaces.\par
With $H$ and $K$ Hilbert spaces, the linear mapping
\[\mathcal{B}(H)\to\mathcal{B}(H\otimes K),\quad A\mapsto A\otimes I\]
preserves operator products, adjoints, and norms; from this last, it is norm continuous. We consider next its continuity properties relative to the strong operator topology. With a simple tensor $v=x\otimes y\in H\otimes K$,
\[\|(A\otimes I)v-(A_0\otimes I)v\|=\|(A-A_0)x\otimes y\|=\|(A-A_0)x\|\|y\|\]
for each $A$ and $A_0$ in $\mathcal{B}(H)$. From this, it follows that, if $v_1,\dots,v_k$ are simple tensors in $H\otimes K$ and $\eps>0$, then the set
\[\{A\in\mathcal{B}(H):\|(A\otimes I)v_i-(A_0\otimes I)v_i\|<\eps\text{ for $i=1,\dots,k$}\}\]
is a strong-operator neighborhood of $A_0$ in $\mathcal{B}(H)$. Since the simple tensors have closed linear span $H\otimes K$, they suffice to determine the strong-operator topology on bounded subsets of $H\otimes K$; so the preceding sentence implies that the mapping $A\mapsto A\otimes I$ is strong-operator continuous on bounded subsets of $\mathcal{B}(H)$.
\section{Normed spaces and Banach spaces}
\subsection{Schauder fixed point theorem}
\begin{theorem}[\textbf{Brouwer's Fixed Point Theorem}]
If $f:\B^n\to\B^n$ is a continuous map, then $f$ has a fixed point.
\end{theorem}
\begin{corollary}\label{NVS finite dim fix point thm}
If $K$ is a nonempty compact convex subset of a finite dimensional normed space $X$ and $f:K\to K$ is a continuous function, then there is a point $x\in K$ such that $f(x)=x$.
\end{corollary}
\begin{proof}
Since $X$ is isomorphic to either $\C^n$ or $\R^n$, it is homeomorphic to either $\R^{2n}$ or $\R^n$. So it suffices to assume that $X=\R^n$. If $K=rB_{X}$, then the result is immediate from Brouwer's Theorem. If $K$ is any compact convex subset of $\R^n$, let $r>0$ such that $K\sub B:=rB_X$. Let $\phi:B\to K$ be the map defined by $\phi(x)=$ the unique point $y$ in $K$ such that $\|x-y\|=d(x,K)$ (since $K$ is compact, such a point exists). Then $\phi$ is continuous and $\phi(x)=x$ for each $x$ in $K$. (In topological parlance, $K$ is a retract of $B$.) Hence $f\circ\phi:B\to K\sub B$ is continuous. By Brouwer's Theorem, there is an $x$ in $B$ such that $f(\phi(x))=x$. Since $f\circ\phi$ has image in $K$, we have $x\in K$. Hence $\phi(x)=x$ and $f(x)=x$.
\end{proof}
Schauder's Fixed Point Theorem is a generalization of the preceding corollary to infinite dimensional spaces.
\begin{definition}
If $X$ is a normed space and $E\sub X$, a function $f:E\to X$ is said to be \textbf{compact} if $f$ is continuous and $\widebar{f(A)}$ is compact whenever $A$ is a bounded subset of $E$.
\end{definition}
If $E$ is itself a compact subset of $X$, then every continuous function from $E$ into $X$ is compact. The following lemma will be needed in the proof of Schauder's Theorem.
\begin{lemma}\label{NVS convex hull of compact lemma}
If $K$ is a compact subset of the normed space $X$, $\eps>0$, and $A$ is a finite subset of $K$ such that $K\sub\bigcup_{a\in A}B_\eps(a)$, define $\phi_A:K\to X$ by
\[\phi_A(x)=\frac{\sum_{a\in A}m_a(x)a}{\sum_{a\in A}m_a(x)}\]
where $m_a(x)=\min\{0,\eps-\|x-a\|\}$. Then $\phi_A$ is continuous and $\|\phi_A(x)-x\|<\eps$ for $x\in K$.
\end{lemma}
\begin{proof}
Note that for each $a$ in $A$, $m_a(x)\geq 0$ and $\sum_{a\in A}m_a(x)>0$ for all $x\in K$. So $\phi_A$ is well defined on $K$. The continuity of $\phi_A$ follows from that of $m_a$. If $x\in K$, then
\[\phi(x)-x=\frac{\sum_{a\in A}m_a(x)(a-x)}{\sum_{a\in A}m_a(x)}.\]
If $m_a(x)>0$, then $\|x-a\|<\eps$. Hence $\|\phi(x)-x\|<\eps$.
\end{proof}
\begin{theorem}[\textbf{Schauder Fixed Point Theorem}]\label{Schauder fixed point theorem}
Let $E$ be a closed bounded convex subset of a normed space $X$. If $f:E\to X$ is a compact map such that $f(E)\sub E$, then there is an $x$ in $E$ such that $f(x)=x$.
\end{theorem}
\begin{proof}
Let $K=\widebar{f(E)}$, so $K\sub E$ is compact. For each positive integer $n$ let $A_n$ be a finite subset of $K$ such that $K\sub\bigcup_{a\in A_n}B_{1/n}(a)$. For each $n$ let $\phi_n=\phi_{A_n}$ as in the preceding lemma. Now the definition of $\phi_n$ clearly implies that $\phi_n(E)\sub\widebar{\conv}(K)\sub E$ since $E$ is closed and convex; thus $f_n:=\phi_n\circ f$ maps $E$ into $E$. Also, Lemma~\ref{NVS convex hull of compact lemma} implies
\[\|f_n(x)-f(x)\|<1/n\for x\in E.\]
Let $X_n$ be the linear span of the set $A_n$ and put $E_n=E\cap X_n$. So $X_n$ is a finite dimensional normed space, $E_n$ is a compact convex subset of $X_n$. By the definition of $\phi_n$, $f_n(E_n)\sub E_n$ and the map $f_N:E_n\to E_n$ is continuous. By Corollary~\ref{NVS finite dim fix point thm}, there is a point $x_n$ in $E_n$ such that $f_n(x_n)=x_n$. Now $\{f(x_n)\}$ is a sequence in the compact set $K$, so there is a point $x_0$ and a subsequence $\{f(x_{n_k})\}$ such that $f(x_{n_k})\to x_0$. Since $f_{n_k}(x_{n_k})=x_{n_k}$, this implies
\[\|x_{n_k}-x_0\|\leq\|f_{n_k}(x_{n_k})-f(x_{n_k})\|+\|f(x_{n_k})-x_0\|\leq 1/n_{k}+\|f(x_{n_k})-x_0\|.\]
Thus $x_{n_k}\to x_0$. Since $f$ is continuous, $f(x_0)=\lim f(x_{n_k})=x_0$.
\end{proof}
\subsection{Adjoint of a linear map}
The adjoint of a linear map is already discussed in duality theory. Now we introduce it for Banach spaces and prove some special results for Banach spaces.
\begin{proposition}\label{Banach space map invertible iff adjoint invertible}
Let $X$ and $Y$ be Banach spaces. If $A\in\mathcal{B}(X,Y)$, then $A$ is invertible iff $A^*$ is invertible.
\end{proposition}
\begin{proof}
If $A$ is bijective then $A$ is invertible, so $A^*$ is invertible by Proposition~\ref{TVS adjoint prop}(b). Conversely, if $A^*$ is invertible, then by the open mapping theorem, there exist $c>0$ such that $A^*(B_{Y^*})\sub cB_{X^*}$. Then
\begin{align*}
\|Ax\|&=\sup\{|\langle Ax,y^*\rangle|:y^*\in B_{Y^*}\}=\sup\{|\langle x,A^*y^*\rangle|:y^*\in B_{Y^*}\}\\
&\geq\sup\{|\langle x,x^*\rangle|:x^*\in cB_{X^*}\}=c^{-1}\|x\|.
\end{align*}
Thus $N(A)=\{0\}$ and $R(A)$ is closed. On the other hand, $R(A)^\bot=N(A^*)=\{0\}$ so $R(A)$ is also dense. This implies that $A$ is surjective and thus invertible.
\end{proof}
\begin{theorem}[\textbf{Closed Image Theorem}]
If $X$ and $Y$ are Banach spaces and $A\in\mathcal{B}(X,Y)$. Then the following are equivalent.
\begin{itemize}
\item[(\rmnum{1})] $R(A)=(N(A^*))^\bot$.
\item[(\rmnum{2})] $R(A)$ is closed.
\item[(\rmnum{3})] There exists a constant $c>0$ such that every $x\in X$ satisfies $\|x+N(A)\|\leq c\|Ax\|$. 
\item[(\rmnum{4})] $R(A^*)=N(A)^\bot$.
\item[(\rmnum{5})] $R(A^*)$ is weak$^*$ closed.
\item[(\rmnum{6})] $R(A^*)$ is norm closed.
\item[(\rmnum{7})] There exists a constant $c>0$ such that every $y^*\in Y^*$ satisfies $\|y^*+N(A^*)\|\leq c\|A^*y^*\|$.  
\end{itemize}
\end{theorem}
\begin{proof}
First we prove that $(\rmnum{1})\Leftrightarrow(\rmnum{3})$. Let $Z=\widebar{R(A)}$. The map $A$ induces a continuous linear map $\bar{A}:X/N(A)\to Z$. It is easy to see that $\bar{A}$ is injective and that has dense range. Since $R(A)=R(\bar{A})$, $R(A)$ is closed if and only if $R(\bar{A})$ is closed, iff $\bar{A}$ is surjective. Note that $\bar{A}$ is surjective iff it is invertible, iff there exists $c>0$ such that $\|\bar{A}(x+N(A))\|\geq c\|x+N(A)\|$. This proves the first claim. The equivalent of (\rmnum{5}) and (\rmnum{7}) can be proved similarly.\par
Now let's examine $\bar{A}^*:Z^*\to (X/N(A))^*$. By Proposition~\ref{polar and adjoint} and \ref{dual of subspace and quotient}, we have
\[(X/N(A))^*=N(A)^\bot=\mathrm{cl}_{\sigma(X^*,X)}R(A^*),\quad Z^*=Y^*/Z^\bot=Y^*/R(A)^\bot=Y^*/N(A^*).\]
Thus $\bar{A}^*:Y^*/N(A^*)\to N(A)^\bot$. We claim that $\bar{A}^*(y^*+N(A^*))=A^*y^*$ for all $y^*\in Y^*$. To see this, let $x\in X$ and $y^*\in Y^*$. Making the appropriate identifications gives
\[\langle x+N(A),\bar{A}^*(y^*+N(A^*))\rangle=\langle\bar{A}(x+N(A)),y^*+N(A^*)\rangle=\langle Ax,y^*\rangle=\langle x,A^*y^*\rangle.\]
Since $x$ was arbitrary, the claim is established. In particular, this implies $R(\bar{A}^*)=R(A^*)$, so $R(A^*)$ is weak$^*$ closed iff $R(\bar{A}^*)$ is.\par
This discussion shows that the theorem is equivalent to the analogous theorem in which there is the additional hypothesis that $A$ is injective and has dense range. It is assumed, therefore, that $N(A)=\{0\}$ and $\widebar{R(A)}=Y$. With the additional hypothesis, it is clear that $R(A)$ is closed iff $A$ is bijective, and $R(A^*)$ is weak$^*$ closed iff $A^*$ is bijective. By the open mapping theorem, bijectivity is equivalent to invertibility, so the calim follows from Proposition~\ref{Banach space map invertible iff adjoint invertible}.
\end{proof}
\begin{corollary}
Let $X$ and $Y$ be Banach spaces and let $A\in\mathcal{B}(X,Y)$. Then the following hold.
\begin{itemize}
\item[(a)] The operator $A$ is surjective if and only if $A^*$ is injective and has a closed image. Equivalently, there exists a constant $c>0$ such that $\|A^*y^*\|\geq c\|y^*\|$ for all $y^*\in Y^*$.
\item[(b)] The operator $A$ is surjective if and only if $A$ is injective and has a closed image. Equivalently, there exists a constant $c>0$ such that $\|Ax\|\geq c\|x\|$ for all $x\in X$.
\end{itemize}
\end{corollary}
\begin{proof}
The operator $A$ has a dense image if and only if $A^*$ is injective by Proposition~\ref{polar and adjoint}. Hence $A$ is surjective if and only if it has a closed image and $A^*$ is injective. The second part is proved simialrly.
\end{proof}
\subsection{Compact operators}
One of the most important concepts in the study of bounded linear operators is that of a compact operator. The notion of a compact operator can be defined in several equivalent ways. The equivalence of these conditions is the content of the following lemma.
\begin{lemma}\label{Banach space compact operator iff}
Let $X$ and $Y$ be Banach spaces and let $K:X\to Y$ be a bounded linear operator. Then the following are equivalent.
\begin{itemize}
\item[(\rmnum{1})] If $\{x_n\}$ is a bounded sequence in X, then the sequence $\{Kx_n\}$ has a Cauchy subsequence.
\item[(\rmnum{2})] If $B\sub X$ is a bounded set, then the set $K(B)$ is precompact.
\item[(\rmnum{3})] The set $K(B_X)$ is relatively compact in $Y$.
\end{itemize}
\end{lemma}
\begin{proof}
Assume $K$ satisfies (\rmnum{1}) and let $B\sub X$ be a bounded set. Then every sequence in $K(B)$ has a Cauchy subsequence by (\rmnum{1}). Hence $K(B)$ is totally bounded and so is a compact subset of $Y$, because $Y$ is complete.\par
We prove that (\rmnum{3}) implies (\rmnum{1}). Let $\{x_n\}$ be a bounded sequence and choose $c>0$ such that $\|x_n\|\leq c$ for all $n$. Then $\{c^{-1}Kx_n\}$ has a convergent subsequence  by (\rmnum{3}). This is the required Cauchy subsequence.
\end{proof}
\begin{definition}
Let $X$ and $Y$ be Banach spaces. A bounded linear operator $K:X\to Y$ is said to be
\begin{itemize}
\item \textbf{compact} if it satisfies the equivalent conditions of Lemma~\ref{Banach space compact operator iff},
\item \textbf{of finite rank} if its image is a finite-dimensional subspace of $Y$,
\item \textbf{completely continuous} if the image of every weakly convergent sequence in $X$ under $A$ converges in the norm topology on $Y$.
\end{itemize}
We use $\mathcal{K}(X,Y)$ to denote compact operators from $X$ to $Y$, and $\mathcal{R}(X,Y)$ for finite rank operators.
\end{definition}
\begin{lemma}\label{Banach space compact and completely continuous}
Let $X$ and $Y$ be Banach spaces. Then the following hold.
\begin{itemize}
\item[(a)] Every compact operator $K:X\to Y$ is completely continuous.
\item[(b)] Assume that $X$ is reflexive. Then a bounded linear operator $K:X\to Y$ is compact if and only if it is completely continuous.
\end{itemize}
\end{lemma}
\begin{proof}
Assume $K$ is compact and let $\{x_n\}$ be a sequence in $X$ that converges weakly to $x\in X$. Suppose, by contradiction, that the sequence $\{Kx_n\}$ does not converge to $Kx$ in the norm topology. Then there exist an $\eps>0$ and a subsequence $\{x_{n_i}\}$ such that $\|Kx-Kx_{n_i}\|\geq\eps$. Since the sequence $\{x_{n_i}\}$ converges weakly, it is weakly bounded, hence bounded in $X$. Since $K$ is compact, there exists a further subsequence $\{x_{n_{i_k}}\}$ such that the sequence $\{Kx_{n_{i_k}}\}$ converges strongly to some element $y\in Y$. This implies
\[\langle y,y^*\rangle=\lim_k\langle Kx_{n_{i_k}},y^*\rangle=\lim\langle x_{n_{i_k}},K^*y^*\rangle=\langle x,K^*y^*\rangle=\langle Kx,y^*\rangle.\]
Thus $y=Kx$ and so $\|Kx_{n_{i_k}}-Kx\|\to 0$, which is a contradiction.\par
Assume $X$ is reflexive and $K$ is completely continuous. Let $\{x_n\}$ be a bounded sequence in $X$. Since $X$ is reflexive, there exists a weakly convergent subsequence $\{x_{n_i}\}$ (Theorem~\ref{Banach space reflexive iff closed unit ball weakly compact}). Let $x\in X$ be the limit of that subsequence. Since $K$ is completely continuous, the sequence $\{x_{n_i}\}$ converges strongly to $Kx$. Thus $K$ is compact by Lemma~\ref{Banach space compact operator iff}.
\end{proof}
\begin{proposition}
Every finite-rank operator $K$ is compact.
\end{proposition}
\begin{proof}
The range of $K$ is finite dimensional, so every bounded subset of the range is precompact. Since $K$ is continous, $K(B_X)$ is bounded in $K(X)$. Thus $K(B_X)$ is precompact in $K(X)$, hence in $Y$.
\end{proof}
\begin{example}
Let $X=C^1([0,1])$, $Y=C([0,1])$ and let $K:X\to Y$ be the obvious inclusion. Then the image of the closed unit ball is a bounded equi-continuous subset of $C([0,1])$ and hence has a compact closure by the Arzel\'aâ€“Ascoli Theorem. In this example the image of the closed unit ball in $X$ under $K$ is not a closed subset of $Y$ (Example~\ref{C([0,1]) closed subspace}).
\end{example}
\begin{example}
If $X$ is reflexive and $K:X\to Y$ is a compact operator, then the closed unit ball $B_X$ is weakly compact in $X$, so $K(B_X)$ is weakly compact in $Y$, hence weakly closed. Then $K(B_X)$ is also closed in $Y$.
\end{example}
\begin{example}
If $K:X\to Y$ is a bounded linear operator between Banach spaces whose image is a closed infinite-dimensional subspace of $Y$, then $K$ is not compact. Namely, the image of the closed unit ball in $X$ under $K$ contains an open ball in $R(K)$ by the closed image theorem, and hence does not have a compact closure.
\end{example}
\begin{example}
Fix a number $1\leq p\leq+\infty$ and a bounded sequence $\lambda=(\lambda_i)$. For $i\in\N$ let $e_i=(\delta_{ij})_{j\in\N}\in\ell^p$. Define the bounded linear operator $K_\lambda:\ell^p\to\ell^p$ by
\[K_\lambda x=(\lambda_ix_i)_{i\in\N}\for x=(x_i)_{i\in\N}\in\ell^p.\]
Then $K_\lambda$ is compact iff $\lim_i\lambda_i\to 0$. This condition is necessary for compactness because, if there exist a constant $\delta>0$ and a sequence $\{\lambda_{i_k}\}$ such that $|\lambda_{i_k}|\geq\delta$ for all $k\in\N$, then the sequence $\{Ke_{i_k}\}=\{\lambda_{i_k}e_{i_k}\}$ in $\ell^p$ has no convergent subsequence. The condition is sufficient because then $K$ can be approximated by a sequence of finite rank operators in the norm topology (Theorem~\ref{Banach space compact operator prop}).
\end{example}
The following theorem shows that the set of compact operators between two Banach spaces is closed with respect to the norm topology.
\begin{theorem}\label{Banach space compact operator prop}
Let $X$, $Y$, and $Z$ be Banach spaces. Then the following hold.
\begin{itemize}
\item[(a)] $\mathcal{K}(X,Y)$ and $\mathcal{R}(X,Y)$ are subspaces of $\mathcal{B}(X,Y)$.
\item[(a)] Let $A:X\to Y$ and $B:Y\to Z$ be bounded linear operators and assume that $A$ or $B$ is compact. Then $BA:X\to Z$ is compact.
\item[(b)] Let $K_n:X\to Y$ be a sequence of compact operators that converges to a bounded linear operator $K:X\to Y$ in the norm topology. Then $K$ is compact.
\item[(c)] Let $K:X\to Y$ be a bounded linear operator and let $K^*:Y^*\to X^*$ be its dual operator. Then $K$ is compact if and only if $K^*$ is compact. 
\end{itemize}
\end{theorem}
\begin{proof}
The first part is clear by definition. Let $\{x_n\}$ be a bounded sequence in $X$. If $A$ is compact, then there exists a subsequence $\{x_{n_k}\}$ such that the sequence $\{Ax_{n_k}\}$ converges, and so does the subsequence $\{BAx_{n_k}\}$. If $B$ is compact, then, since the sequence $\{Ax_n\}$ is bounded, there exists a subsequence $\{Ax_{n_k}\}$ such that the sequence $\{BAx_{n_k}\}$ converges. This proves (b).\par
We prove part (c) by showing that $K(B_X)$ is totally bounded. Let $\eps>0$ and choose $n$ such that $\|K_n-K\|<\eps/3$. Since $K_n$ is compact, there are $x_1,\dots,x_k\in B_X$ such that $K_n(B_X)\sub\bigcup_{i=1}^{k}B_{\eps/3}(K_nx_i)$. So if $\|x\|\leq 1$, there is an $x_i$ with $\|K_nx-K_nx_i\|<\eps/3$. Thus
\[\|Kx-Kx_i\|\leq\|Kx-K_nx\|+\|K_nx-K_nx_i\|+\|K_nx_i-Kx_i\|\leq 2\|K-K_n\|+\eps/3<\eps.\]
This implies $K(B_X)\sub\bigcup_{i=1}^{k}B_{\eps}(x_i)$, so $K(B_X)$ is totally bounded.\par
We prove part (c). Assume first that $K:X\to Y$ is a compact operator.
Then the set $M:=\widebar{K(B_X)}$ is a compact metric space with the distance function determined by the norm on $Y$. Consider the subset $H\sub C(M)$ given by
\[H=\{f_{y^*}:=y^*|_{M}:y^*\in B_{Y^*}\}.\]
For each $y^*\in B_{Y^*}$ the supremum norm of $y^*|_{M}$ is given by
\begin{align}\label{Banach space compact prop-1}
\|f_{y^*}\|_\infty=\sup_{y\in M}|\langle y,y^*\rangle|=\sup_{\|x\|\leq 1}|\langle Kx,y^*\rangle|=\|K^*y^*\|_{X^*}\leq\|K^*\|.
\end{align}
Thus $\mathscr{F}$ is a bounded subset of $C(M)$. Moreover, the set $\mathscr{F}$ is equi-continuous because
\[|f_{y^*}(y_1)-f_{y^*}(y_2)|=|\langle y_1-y_2,y^*\rangle|\leq\|y^*\|\|y_1-y_2\|\leq\|K^*\|\|y_1-y_2\|\]
for all $y^*\in B_{Y^*}$ and $y_1,y_2\in M$. Since $M$ is a compact metric space, it follows from the Arzel\'aâ€“Ascoli Theorem that $\mathscr{F}$ has a compact closure. Now let $\{y^*_n\}$ be a sequence in $B_{Y^*}$. Then the sequence $\{f_{y^*}\}$ in $\mathscr{F}$ has a uniformly convergent subsequence $\{f_{y^*_{n_k}}\}$. Hence it follows from $(\ref{Banach space compact prop-1})$ that $\{K^*y^*_{n_k}\}$ is a Cauchy sequence in $X^*$ and hence converges. This shows that $K^*$ is a compact operator.\par
Conversely, suppose that $K^*$ is compact. Then, by what we have just proved, the bidual operator $K^{**}:X^{**}\to Y^{**}$ is compact. This implies that $K$ is compact. To see this, let $\{x_n\}$ be a bounded sequence in $X$. Then $\{J_X(x_n)\}$ is a bounded sequence in $X^{**}$. Since $K^{**}$ is a compact operator, there exists a subsequence $\{J_X(x_{n_k})\}$ such that the sequence $K^{**}J_X(x_{n_k})=J_Y(Kx_{n_k})$ converges in $Y^{**}$. Hence $\{Kx_{n_k}\}$ is a Cauchy sequence in $Y$, so $K$ is compact.
\end{proof}
\begin{corollary}
If $X$ is a Banach space, then $\mathcal{K}(X)$ is a closed two-sided ideal in the algebra $\mathcal{B}(X)$.
\end{corollary}
\begin{corollary}\label{Banach space compact operator invertible iff}
If $A\in\mathcal{K}(X)$ and $A$ is invertible, then $\dim X<+\infty$.
\end{corollary}
\begin{proof}
If $A$ is invertible then $I$ is in $\mathcal{K}(X)$. Thus $\dim X<+\infty$.
\end{proof}
\begin{theorem}
If $X$ is a compact Hausdorff space, then $\mathcal{R}(C(X))$ is dense in $\mathcal{K}(C(X))$.
\end{theorem}
\begin{proof}
Let $T\in\mathcal{K}(C(X))$. Thus $T(B_{C(X)})$ is precompact, so is bounded and equicontinuous by the Arzel\'a-Ascoli Theorem. If $\eps>0$ and $x\in X$, let $U_x$ be an open neighborhood of $x$ such that $|(Tf)(x)-(Tf)(y)|<\eps$ for all $f\in B_{C(X)}$ and $y\in U_x$. Let $\{x_1,\dots,x_n\}\sub X$ such that $X=\bigcup_{i=1}^{n}U_{x_i}$. Let $\{\psi_1,\dots,\psi_n\}$ be a partition of unity subordinate to $\{U_{x_1},\dots,U_{x_n}\}$. Define $T_\eps:C(X)\to C(X)$ by
\[T_\eps f=\sum_{i=1}^{n}(Tf)(x_i)\psi_i.\]
Since $R(T_\eps)\sub\bigvee\{\psi_1,\dots,\psi_n\}$, we have $T_\eps\in\mathcal{R}(C(X))$. If $f\in B_{C(X)}$ and $x\in X$, then
\begin{align*}
|(T_\eps f)(x)-(Tf)(x)|&=\Big|\sum_{i=1}^{n}(Tf)(x)\psi_i(x)-\sum_{i=1}^{n}(Tf)(x_i)\psi_i(x)\Big|\\
&\leq \sum_{i=1}^{n}|(Tf)(x_i)-(Tf)(x)|\psi_i(x)<\eps\sum_{i=1}^{n}\psi_i(x)=\eps.
\end{align*}
Thus the claim follows.
\end{proof}
\subsection{Invariant subspaces}
\begin{definition}
If $X$ is a Banach space and $T\in\mathcal{B}(X)$, an \textbf{invariant subspace} for $T$ is a closed linear subspace $M$ of $X$ such that $T(M)\sub M$. $M$ is nontrivial if $M\neq\{0\}$ or $X$. We use $\Lat(T)$ to denote the collection of all invariant subspaces for $T$. If $\mathcal{A}\sub\mathcal{B}(X)$, then $\Lat(\mathcal{A})=\bigcap_{T\in\mathcal{A}}\Lat(T)$.
\end{definition}
If $\{M_s:s\in S\}\sub\Lat(T)$, we define $\bigvee\{M_s\}:=\widebar{\langle\{M_s\}\rangle}$ and $\bigwedge\{M_s\}:=\bigcap_sM_s$. The following result is immediate. 
\begin{proposition}\label{Banach space invariant subspace prop}
Let $X$ be a Banach space and $T\in\mathcal{B}(X)$. If $\{M_s:s\in S\}\sub\Lat(T)$, then $\bigvee\{M_s:s\in S\}$ and $\bigwedge\{M_s:s\in S\}$ belong to $\Lat(T)$.
\end{proposition}
This results justifies the use of the symbol "Lat" to denote the collection of invariant subspaces. With the operations $\vee$ and $\wedge$, $\Lat(T)$ is a complete lattice and has a largest element, $X$, and a smallest element, $\{0\}$.
\begin{example}
If $X$ is a finite dimensional space over $\C$ and $T\in\mathcal{B}(X)$, then $\Lat(T)$ is not trivial. In fact, any eigenspace of $T$ is invariant.
\end{example}
\begin{example}
Let $T$ be the matrix
\[T=\begin{bmatrix}
0&-1\\
1&0
\end{bmatrix}\]
on $\R^2$. Then $\Lat(T)$ is trivial. Indeed, if $\Lat(T)$ is not trivial, there is a one-dimensional space $M$ in $\Lat(T)$. Let $M=\R x$, then $x$ is an eigenvector of $T$. But $T$ does not has any eigenvector, because it hsa no real eigenvalues.
\end{example}
\begin{example}
If $V:L^2([0,1])\to L^2([0,1])$ is the Volterra operator $Vf(x)=\int_0^xf(y)\,dy$ and $\alpha\in[0,1]$, put $M_\alpha=\{f\in L^2([0,1]):f(x)=0\text{ for $x\in[0,\alpha]$}\}$. Then $M_\alpha$ is invariant under $V$. Moreover, it can be shown $\Lat(V)=\{M_\alpha:0\leq\alpha\leq 1\}$.
\end{example}
\begin{example}
Let $(X,\mathcal{A},\mu)$ be a $\sigma$-finite measure space and for $\phi\in L^\infty(\mu)$, let $M_\phi$ denote the multiplication operator on $L^p(\mu)$, $1\leq p\leq+\infty$. If $x\in X$, let $M_x=\{f\in L^p(\mu):f(x)=0\}$. Then $M_x\in\Lat(M_\phi)$ for every $\phi\in L^\infty(\mu)$.
\end{example}
\begin{lemma}[\textbf{Lomonosov's Lemma}]
If $\mathcal{A}$ is a subalgebra of $\mathcal{B}(X)$ such that $1\in\mathcal{A}$ and $\Lat(\mathcal{A})$ is trivial and if $K$ is a nonzero compact operator on $X$, then there is an $A\in\mathcal{A}$ such that $N(AK-I)\neq\{0\}$.
\end{lemma}
\begin{proof}
We may assume that $\|K\|=1$. Fix $x_0\in X$ such that $\|x_0\|\geq \|Kx_0\|>1$ and put $S=\{x\in X:\|x-x_0\|\leq 1\}$. It is easy to check that $0\notin S$ and $0\notin\widebar{K(S)}$. Now if $0\neq x\in X$ then $\widebar{\{Tx:T\in\mathcal{A}\}}$ is an invariant subspace for $\mathcal{A}$ (because $\mathcal{A}$ is an algebra) that contains the nonzero vector $x$ (because $I\in\mathcal{A}$), so it equals $X$ by hypothesis. Then for every $y\in\widebar{K(S)}$ (hence $y\neq 0$) there exists $T\in\mathcal{A}$ with $\|Ty-x_0\|<1$. Equivalently,
\[\widebar{K(S)}\sub\bigcup_{T\in\mathcal{A}}\{y:\|Ty-x_0\|<1\}.\]
Because $\widebar{K(S)}$ is compact, there are $T_1,\dots,T_n\in\mathcal{A}$ such that the sets cover $\widebar{K(S)}$. For $y\in\widebar{K(S)}$, define $a_i(y)=\max\{0,1-\|T_iy-x_0\|\}$. Then $\sum_{i=1}^{n}a_i(y)>0$ for all $y\in\widebar{K(S)}$. Define
\[b_i:\widebar{K(S)}\to\R,\quad b_i(y)=\frac{a_i(y)}{\sum_{i=1}^{n}a_i(y)}\]
and
\[\psi:S\to X,\quad \psi(x)=\sum_{i=1}^{n}b_i(Kx)T_iKx.\]
It is easy to see that $a_i$ is a continuous function. Hence $b_i$ and $\psi$ are continuous.\par
By the definition of $a_i(Kx)$'s, $T_iKx\in S$ whenever $a_i(Kx)>0$. Since $S$ is a convex set, we then have $\psi(S)\sub S$. Note that $T_iK\in\mathcal{K}(X)$ for each $i$ by Theorem~\ref{Banach space compact operator prop} so that $\bigcup_{i=1}^{n}T_iK(S)$ has compact closure. By Proposition~\ref{TVS convex hull of finite union of compact}, $\widebar{\conv}(\bigcup_{i=1}^{n}T_iK(S))$ is compact, so $\widebar{\psi(S)}$ is also compact. This is, $\psi$ is a compact map. By the Schauder Fixed-Point Theorem, there is a vector $x_1$ in $S$ such that $\psi(x_1)=x_1$. Let $A=\sum_ib_i(Kx_1)T_i$. Then $A\in\mathcal{A}$ and $AKx_1=\psi(x_1)=x_1$. Since $0\notin S$, $x_1\neq 0$, and so $N(AK-I)\neq\{0\}$.
\end{proof}
\begin{definition}
If $T\in\mathcal{B}(X)$, then a \textbf{hyperinvariant subspace} for $T$ is a subspace $M$ of $X$ such that $A(M)\sub M$ for every operator $A$ in the commutator of $T$; that is, $A(M)\sub M$ whenever $AT=TA$.
\end{definition}
\begin{theorem}[\textbf{Lomonosov's Theorem}]
If $X$ is a Banach space over $\C$, $T\in\mathcal{B}(X)$ is not a multiple of the identity, and $TK=KT$ for some nonzero compact operator $K$, then $T$ has a nontrivial hyperinvariant subspace.
\end{theorem}
\begin{proof}
Let $\mathcal{A}$ be the commutator of $T$. We want to show that $\Lat(\mathcal{A})$ is nontrivial. If this is not the case, then Lomonosov's Lemma implies that there is an operator $A\in\mathcal{A}$ such that $N:=N(AK-I)\neq\{0\}$. Then $N\in\Lat(AK)$ and $AK|_N$ is the identity operator. Since $AK-I\in\mathcal{K}(X)$, by Proposition~\ref{Hilbert space compact operator eigenspace finite dim} we have $\dim N<+\infty$. Since $AK-I\in\mathcal{A}$, $N$ is also an invariant subspace for $T$. But $\dim N<+\infty$ so that $T|_N$ must have an eigenvalue $\lambda$, thus $M:=N(T-\lambda I)\neq\{0\}$. But $M\neq X$ since $T$ is not a multiple of the identity. It is easy to check that $M$ is hyperinvariant for $T$.
\end{proof}
\begin{corollary}[\textbf{Aronszajn-Smith}]
If $K\in\mathcal{K}(X)$, then $\Lat(K)$ is nontrivial.
\end{corollary}
\begin{corollary}
If $K_1,K_2\in\mathcal{K}(X)$ and $K_1K_2=K_2K_1$ then $K_1$ and $K_2$ have a common nontrivial invariant subspace.
\end{corollary}
\begin{corollary}
If $X$ is infinite dimensional, $A\in\mathcal{B}(X)$, and there is a polynomial $p(x)$ such that $p(A)\in\mathcal{K}(X)$, then $\Lat(A)$ is nontrivial.
\end{corollary}
\begin{proof}
If $p(A)\neq 0$, then Lomonosov's Theorem applies. If $p(A)=0$, then $a_0+a_1A+\cdots+a_nA^n=0$. For $x\neq 0$, let $M=\bigvee\{x,Ax,\cdots,A^{n-1}x\}$. Then by the equation on $A$ we see $M$ is invariant under $A$. Since $x\in M$, $M\neq\{0\}$. Since $\dim M<+\infty$, $M\neq X$.
\end{proof}
\subsection{Weakly compact operators}
\begin{definition}
If $X$ and $Y$ are Banach spaces, an operator $T\in\mathcal{B}(X,Y)$ is weakly compact if the closure of $T(B_X)$ is weakly compact.
\end{definition}
Weakly compact operators are generalizations of compact operators, but the hypothesis is not sufficiently strong to yield good information about their structure.
\begin{proposition}\label{Banach space weakly compact operator prop}
Let $X$, $Y$, and $Z$ be Banach spaces.
\begin{itemize}
\item[(a)] If either $X$ or $Y$ is reflexive, then every operator in $\mathcal{B}(X,Y)$ is weakly.
compact.
\item[(b)] If $A:X\to Y$ and $B:Y\to Z$ be bounded operators and assume that $A$ or $B$ is weakly compact. Then $BA$ is weakly compact.
\end{itemize}
\end{proposition}
\begin{proof}
If $X$ is reflexive then $B_X$ is weakly compact, so $T(B_X)$ is also weakly compact. If $Y$ is reflexive then $\sigma(Y,Y^*)$ has Henie-Borel property. Since $T$ is continuous, $T(B_X)$ is bounded, so it is precompact in $Y$.\par
A continuous map is weakly continuous by Proposition~\ref{LCHS weak continuous is continuous iff}, so part (b) follows from Theorem~\ref{Banach space compact operator prop}. 
\end{proof}
This proposition shows that assuming that an operator is weakly compact
is not that strong an assumption. For example, if $X$ is reflexive, every operator in $\mathcal{B}(X)$ is weakly compact. In particular, every operator on a Hilbert space is weakly compact. So any theorem about weakly compact operators is a theorem about all operators on a reflexive space.\par
In fact, there is a degree of validity for the converse of this statement. In a certain sense, theorems about operators on reflexive spaces are also theorems about weakly compact operators. The precise meaning of this statement is the content of the theorem below. But before we begin to prove this, a lemma is needed.\par
Let $Y$ be a Banach space and let $W$ be a bounded convex balanced subset of $Y$. For $n\geq 1$, put $U_n=2^{n}W+2^{-n}B_Y$. Let $p_n$ be the gauge of $U_n$. Since $U_n$ is a bounded disk, each $p_n$ is a norm on $Y$ by Proposition~\ref{TVS Banach disk if}. In fact, $p_n$ and $\|\cdot\|$ are equivalent. To see this note that if $\|y\|\leq 1$, then $2^{-n}y\in U_n$ so that $p_n(y)\leq 2^n$. Hence $p_n(y)\leq 2^n\|y\|$. Also, because $U_n$ is bounded, if $U_n\sub cB_Y$ then $p_n(y)\geq c^{-1}\|y\|$.
\begin{lemma}\label{Banach space weakly compact operator lemma}
For a Banach space $Y$ let $W$, $U_n$ and $p_n$ be as above. Let 
\[R=\{y\in Y:p(y):=\Big(\sum_{n=1}^{\infty}p_n(y)^2\Big)^{1/2}<+\infty\}\]
Then we have
\begin{itemize}
\item[(a)] $W\sub B_R$.
\item[(b)] $(R,p)$ is a Banach space and the inclusion map $I:R\to Y$ is continuous;
\item[(c)] $I^{**}:R^{**}\to Y^{**}$ is injective and $(I^{**})^{-1}(Y)=R$.
\item[(d)] $R$ is reflexive if and only if $\widebar{W}$ is weakly compact. 
\end{itemize}
\end{lemma}
\begin{proof}
If $w\in W$, then $2^nw\in U_n$. Hence $p_n(w)\leq 2^{-n}$. Thus $\|w\|^2_R\leq\sum_n(2^{-n})^2<1$. Let $Y_n=(Y,p_n)$ and put $X=\bigoplus Y_n$ with norm $p$. Define $\Phi:R\to X$ by $\Phi(y)=(y)_{n\in\N}$. It is easy to see that $\Phi$ is an isometry though it is clearly not surjective. Thus $R$ is a Banach space. Let $\pi_1$ be the projection of $X$ onto the first coordinate. Then $I=\pi_1\circ\Phi$ and hence $I$ is continuous.\par
With the notation from the proof of (b), it follows that $X^{**}=\bigoplus_nY_n^{**}$ and $\Phi^{**}:R^{**}\to X^{**}$ is given by $\Phi^{**}(y^{**})=(y^{**})_{n\in\N}$. Now the fact that $\Phi$ is an isometry implies that $R(\Phi)$ is closed and $\Phi^*$ is surjective. Hence $N(\Phi^{**})=R(\Phi^*)^\bot=\{0\}$; that is, $\Phi^{**}$ is injective. Therefore $I^{**}$ is injective.\par
Now let $y^{**}\in (I^{**})^{-1}(Y)$. It follows that $x:=\Phi^{**}(y^{**})\in X$. Since $R$ is weakly dense in $R^{**}$, let $(y_\alpha)$ be a net in $R$ such that $y_\alpha\to y$ weakly. Then $\Phi^{**}(y_\alpha)\to\Phi^{**}(y^{**})$. But $\Phi^{**}(y_\alpha)=\Phi(y_\alpha)\in X$ and $\Phi^{**}(y^{**})=x$, so $\Phi(y_\alpha)\to x$ weakly in $X$. Since $R(\Phi)$ is closed, $x\in R(\Phi)$; let $x=\Phi(y)$. Then $\Phi^{**}(y^{**})=\Phi(y)$, which implies $y^{**}=y$ since $\Phi^{**}$ is injective.\par
Assume that $\widebar{W}$ is weakly compact. For each $n$, we have $I(B_{R})\sub 2^n\widebar{W}+2^{-n}B_{Y^{**}}$, which is weakly compact. Since $B_{R^{**}}$ is weakly compact, $I^{**}(B_{R^{**}})$ is closed in $Y^{**}$. Thus
\begin{align*}
I^{**}(B_{R^{**}})&=I^{**}(B_{R^{**}})^{\bot\bot}=N(I^*)^\bot=\mathrm{cl}_{\sigma(Y,Y^*)}I(B_R)\\
&\sub \bigcap_{n=1}^{\infty}[2^n\widebar{W}+2^{-n}B_{Y^{**}}]\sub\bigcap_{n=1}^{\infty}[Y+2^{-n}B_{Y^{**}}]=Y.
\end{align*}
By part (c), this implies $R^{**}=R$, so $R$ is reflexive.\par
If $R$ is reflexive then $B_{R}$ is weakly compact. Therefore $I(B_R)$ is weakly compact in $Y$ and by (a), $\widebar{W}$ is weakly compact.
\end{proof}
\begin{theorem}\label{Banach space weakly compact operator iff composition}
If $X,Y$ are Banach spaces and $T\in\mathcal{B}(X,Y)$, then $T$ is weakly compact if and only if there is a reflexive space $R$ and operators $A\in\mathcal{B}(X,R)$ and $B\in\mathcal{B}(R,Y)$ such that $T=BA$.
\end{theorem}
\begin{proof}
If $T=BA$, where $A,B$ have the described form, then $T$ is weakly
compact by Proposition~\ref{Banach space weakly compact operator prop}. Now assume that $T$ is weakly compact and put $W=T(B_X)$. Define $R$ as in Lemma~\ref{Banach space weakly compact operator lemma}. Then $R$ is reflexive. Let $B:R\to Y$ be the inclusion map. Note that if $x\in B_X$ then $Tx\in W$. By Lemma~\ref{Banach space weakly compact operator lemma}, $p(Tx)<1$ whenever $\|x\|\leq 1$. So $A:X\to R$ defined by $Ax=Tx$ is a bounded operator. Clearly $BA=T$.
\end{proof}
\begin{proposition}
If $X$, $Y$ are Banach spaces and $T\in\mathcal{B}(X,Y)$, the following statements are equivalent.
\begin{itemize}
\item[(\rmnum{1})] $T$ is weakly compact.
\item[(\rmnum{2})] $T^{**}(X^{**})\sub Y$.
\item[(\rmnum{3})] $T^*$ is weakly compact.  
\end{itemize}
\end{proposition}
\begin{proof}
If $T$ is weakly compact, let $R$ be a reflexive space, $A\in\mathcal{B}(X,R)$, $B\in\mathcal{B}(R,Y)$ such that $T=BA$. So $T^{**}=B^{**}A^{**}$. Since $R$ is reflexive, $B^{**}=B$. Thus $T^{**}=BA^{**}$ and $T^{**}(X^{**})\sub B(R)\sub Y$.
Moreover, since $T^*=A^*B^*$ and $R^*$ is also reflexive, we see $T^*$ is weakly compact.
\par
Conversely, assume that $T^{**}(X^{**})\sub Y$. Then $T^{**}(B_{X^{**}})\sub Y$ is weakly compact in $Y$. Hence $T(B_X)\sub T^{**}(B_{X^{**}})$ has weakly compact closure.\par
Finally, assume that $T^*$ is reflexive. Let $S$ be a reflexive space, $C\in\mathcal{B}(Y^*,S)$, $D\in\mathcal{B}(S,X^*)$ such that $T^*=DC$. Then $T^{**}=C^*D^*$. Put $R=\widebar{D^*(X)}$ and $A=D^*|_X$. Then $A\in\mathcal{B}(X,R)$ and $R$ is reflexive by Proposition~\ref{Banach space reflexive subspace quotient}. Let $B=C^*|_R$, so $B\in\mathcal{B}(R,Y^{**})$. If $x\in X$, then
\[BAx=C^*D^*x=T^{**}x=Tx\in Y.\]
Thus $B\in\mathcal{B}(R,Y)$ and $T=BA$. By Theorem~\ref{Banach space weakly compact operator iff composition}, $T$ is weakly compact.
\end{proof}
\section{Banach algebras}
\subsection{Basic properties}
Let $\mathfrak{A}$ be a Banach space and, at the same time, an algebra with identity $I$, in which multiplication is separately continuous. Let $L_A$ and $R_B$ denote the left and right multiplication on $\mathfrak{A}$, respectively. From the continuity assumption, $L_A$ and $R_B$ are in $\mathcal{B}(\mathfrak{A})$. Thus 
\[\{\|L_A(B):\|A\|\leq 1\}\]
is a bounded set for each $B$ in $\mathfrak{A}$. From the uniform-boundedness principle, $\{\|L_A\|:\|A\|\leq 1\}$ is bounded. Similarly $\{\|R_B\|:\|B\|\leq 1\}$ is bounded. It follows that the mappings $L:A\mapsto L_A$ and $R:b\mapsto R_B$, which are linear isomorphisms of $\mathfrak{A}$ into $\mathcal{B}(\mathfrak{A})$, are continuous (bounded). The mapping $L$ is an algebraic isomorphism, while $R$ is an algebraic anti-isomorphism. Now,
\[\|A\|=\|L_A(I)\|\leq\|L_A\|\|I\|.\]
Thus
\[\|I\|^{-1}\|A\|\leq\|L_A\|\leq\|L\|\|A\|.\]
Hence $L(\mathfrak{A})$ is a norm-closed subalgebra of $\mathcal{B}(\mathfrak{A})$ and $L$ is an algebraic isomorphism and homeomorphism of $\mathfrak{A}$ onto $\mathcal{B}(\mathfrak{A})$. As far as the (combined) algebraical and topological properties of $\mathfrak{A}$ and $\mathcal{B}(\mathfrak{A})$ are concerned, they are indistinguishable when identified by the isomorphism $L$.\par
The norm on $\mathcal{B}(\mathfrak{A})$ enjoys some special properties: $\|I\|=1$, where $I$ is the identity mapping on $\mathfrak{A}$; and $\|AB\|\leq\|A\|\|B\|$. Thus the norm induced on $\mathcal{B}(\mathfrak{A})$ by that on $L(\mathfrak{A})$ has these special properties.\par
Note that if the norm on an algebra $\mathfrak{A}$ satisfies $\|AB\|\leq\|A\|\|B\|$, then since
\[\|AB-A_0B_0\|\leq\|A\|\|B-B_0\|+\|B_0\|\|A-A_0\|\leq(\|A_0\|+1)\|B-B_0\|+\|B_0\|\|A-A_0\|\]
when $\|A-A_0\|\leq 1$, the multiplication is jointly continuous on $\mathfrak{A}$. In particular, the multiplication is jointly continuous on $L(\mathfrak{A})$, and since $L$ is an algebraic isomorphism and homeomorphism, multiplication is jointly continuous on $\mathfrak{A}$---independent of the norm assumption. (The uniform-boundedness principle did the work in getting us joint from separate continuity of multiplication.) From the joint continuity, it follows at once that the closure of a subalgebra (ideal) is, again, a subalgebra (ideal).\par
If we assume, now, that the norm on $\mathfrak{A}$ satisfies $\|I\|=1$ as well as $\|AB\|\leq\|A\|\|B\|$, then
\[\|A\|=\|L_A(I)\|\leq\|L_A\|\leq\|A\|\]
so that $L$ is an isometry as well as an algebraic isomorphism. While the natural structural assumption on $\mathfrak{A}$ is that of continuity of multiplication (either joint or separate), the preceding discussion assures us that nothing is lost if we make the convenient normalization assumptions on the norm.
\begin{definition}
An algebra $\mathfrak{A}$ (over $\R$ or $\C$) is said to be a \textbf{normed algebra} when $\mathfrak{A}$ is a normed space such that for all $a,b\in\mathfrak{A}$, $\|AB\|\leq\|A\|\|B\|$. If $\mathfrak{A}$ has an identity $I$, then it is assumed that $\|I\|=1$. If $\mathfrak{A}$ is a Banach space relative to this norm, $\mathfrak{A}$ is said to be a \textbf{Banach algebra}.
\end{definition}
From the discussion above, we see that a normed algebra $\mathfrak{A}$ is isometrically, algebraically isomorphic to a subalgebra of $\mathcal{B}(\mathfrak{A})$, view that map $L$. Completing $\mathfrak{A}$ to a Banach space $\widehat{\mathfrak{A}}$ allows us to view each $L_A$ as a bounded linear transformation from $\mathfrak{A}$ to $\widehat{\mathfrak{A}}$ and extend it (uniquely) in a norm-preserving fashion to an operator $\hat{L}_A$ on $\widehat{\mathfrak{A}}$. The resulting mapping $\hat{L}:A\mapsto\hat{L}_A$ is then an isometric algebraic isomorphism of $\mathfrak{A}$ into the Banach algebra $\mathcal{B}(\widehat{\mathfrak{A}})$. Moreover, $\hat{L}$ extends to an isometric isomorphism of $\widehat{\mathfrak{A}}$ onto the norm closure of $\hat{L}(\mathfrak{A})$ in $\mathcal{B}(\widehat{\mathfrak{A}})$. Thus $\widehat{\mathfrak{A}}$ becomes a Banach algebra. We may say, briefly, that the completion of a normed algebra is a Banach algebra.\par
Note that the assumption that $\mathfrak{A}$ has an identity is not an essential restriction. If $\mathfrak{A}$ does not have an identity, we can employ the standard process for adjoining an identity to an algebra.
\begin{proposition}\label{norm algebra adjoining identity}
If $\mathfrak{A}$ is a normed algebra without identity, let $\mathfrak{A}_1=\mathfrak{A}\times\K$ and define algebraic operations on $\mathfrak{A}_1$ by
\begin{itemize}
\item[(\rmnum{1})] $(A,\alpha)+(B,\beta)=(A+B,\alpha+\beta)$;
\item[(\rmnum{2})] $\beta(A,\alpha)=(\beta A,\beta\alpha)$;
\item[(\rmnum{3})] $(A,\alpha)\cdot(B,\beta)=(A\beta+\alpha B+AB,\alpha\beta)$.
\end{itemize}
Define $\|(A,\alpha)\|=\|A\|+|\alpha|$. Then $\mathfrak{A}_1$ with this norm and the algebraic operations defined above is a normed algebra with identity $(0,1)$ and $A\mapsto(A,0)$ is an isometric isomorphism of $\mathfrak{A}$ into $\mathfrak{A}_1$. If $\mathfrak{A}$ is a Banach space, then $\mathfrak{A}_1$ is a Banach algebra. Moreover, if $\mathfrak{B}$ is a normed algebra and $\varphi:\mathfrak{A}\to\mathfrak{B}$ is an algebra homomorphism, then the map $\varphi_1:\mathfrak{A}_1\to\mathfrak{B}$ defined by $\varphi_1(A,\alpha)=\varphi(A)+\alpha$ is an algebra homomorphism, with $\|\varphi\|\leq\|\varphi_1\|$.
\end{proposition}
\begin{proof}
If $(a,\alpha),(b,\beta)\in\mathfrak{A}_1$, then
\begin{align*}
\|(a,\alpha)(b,\beta)\|&=\|a\beta+\alpha b+ab\|+|\alpha\beta|\leq|\beta|\|A\|+|\alpha|\|B\|+\|A\|\|B\|+|\alpha||\beta|\\
&=(\|A\|+|\alpha|)(\|B\|+|\beta|)=\|(a,\alpha)\|\|(b,\beta)\|.
\end{align*}
The completeness of $\mathfrak{A}_1$ clearly follows from that of $\mathfrak{A}$, so the first claim follows.\par
Now let $\mathfrak{B}$ be a normed algebra and $\varphi:\mathfrak{A}\to\mathfrak{B}$ be a homomorphism. Then
\begin{align*}
\varphi_1((A,\alpha)(B,\beta))&=\varphi(A\beta+\alpha B+AB,\alpha\beta)=\beta\varphi(A)+\alpha\varphi(B)+\varphi(A)\varphi(B)+\alpha\beta\\
&=(\varphi(A)+\alpha)(\varphi(B)+\beta)=\varphi_1(A,\alpha)\varphi_1(B,\beta).
\end{align*}
Thus $\varphi_1$ is an algebra homomorphism. Note that since $\mathfrak{A}$ is isometrically isomorphic to $\mathfrak{A}\times\{0\}$, we have
\[|\varphi(A)|=|\varphi_1(A,0)|\leq\|\varphi_1\|\|A\|,\]
so $\|\varphi\|\leq\|\varphi_1\|$. This finishes the proof.
\end{proof}
Despite the possibility of adjoining an identity to a Banach algebra, it is sometimes artificial and inconvenient to do so. In these cases, one develops the appropriate techniques for dealing with the algebras without identity. For our purposes, this assumption will cause us no difficulty and is a considerable convenience.
\begin{example}
An important class of Banach algebras is made up of the algebras of (complexor real-valued) continuous functions on compact Hausdorff spaces. The algebraic operations are the usual pointwise addition and multiplication of functions. If $X$ is a compact Hausdorff space, we shall denote this algebra of continuous functions by $C(X)$. The norm on $C(X)$ is the supremum norm. Of course the identity of $C(X)$ is the constant function $1$, and it is easy to see $\|fg\|\leq\|f\|\|g\|$. From this and the fact that $C(X)$, in the given norm, is a Banach space, we see that $C(X)$ is a Banach algebra. While we could have used the fact that each $f$ in $C(X)$ attains its norm at some point of $X$ in our norm considerations, by avoiding its use, the discussion applies without change with the assumption that $X$ is compact omitted and $C(X)$ denoting the bounded continuous functions on $X$.
\end{example}
\begin{example}
If $X$ is a locally compact space, then $\mathfrak{A}=C_0(X)$ is a Banach algebra when the multiplication is defined pointwise as in the preceding example. $\mathfrak{A}$ is abelian, but if $X$ is not compact, $\mathfrak{A}$ does not have an identity. If $X$ is the one-point compactification of $X$, then $C(X^*)\sups C_0(X)$ and $C(X^*)$ is a Banach algebra with identity. Note that in this case $C(X^*)=C_0(X)\times\C$ (Proposition~\ref{LCH one-point compactification continuous function}), and the product on $C(X^*)$ is defined exactly as in Proposition~\ref{norm algebra adjoining identity}.
\end{example}
\begin{example}
If $(X,\mathcal{A},\mu)$ is measure space and $\mathfrak{A}=L^\infty(\mu)$, then $\mathfrak{A}$ is an abelian Banach algebra with identity if the operations are defined pointwise.
\end{example}
\begin{example}
If $X$ is a Banach space and $\mathfrak{A}=\mathcal{B}(X)$, then $\mathfrak{A}$ is a Banach algebra with identity. Also, $\mathcal{K}(X)$ is an ideal of $\mathfrak{A}$.
\end{example}
\begin{example}
Let $G$ be a locally compact group and $\mu$ a left Haar measure on $G$. Then $L^1(G)$ and $M(G)$ is a Banach algebra with the convolution operation. Note that $M(G)$ has an identity $\delta_e$, but $L^1(G)$ has no identity, unless the topology on $G$ is discrete (Proposition~\ref{LCH group L^1(G) has identity iff discrete topo}).
\end{example}
\begin{lemma}\label{Banach algebra invertible lemma}
If $\mathfrak{A}$ is a Banach algebra with identity and $A\in\mathfrak{A}$ such that $\|A-I\|<1$, then $A$ is invertible.
\end{lemma}
\begin{proof}
Let $B=I-A$, then $\|B\|=r<1$, so the series $\sum_{n=0}^{\infty}B^n$ converges absolutely to an element $S\in\mathfrak{A}$. If $S_n$ is the partial sum, then
\[S_n(I-B)=(I+B+\cdots+B^n)-(B+B^2+\cdots+B^{n+1})=I-B^{n+1}.\]
Since $\|B^{n+1}\|\leq r^{n+1}\to 0$, we see $I-B^{n+1}\to I$, therefore $S(I-B)=(I-B)S=I$. This implies $I-B$ is invertible and $(I-B)^{-1}=\sum_{n=0}^{\infty}B^n$. But $I-B=A$, so the claim follows.
\end{proof}
\begin{proposition}\label{Banach algebran abelian homomorphism to C}
If $\mathfrak{A}$ is Banach algebra and $\phi:\mathfrak{A}\to\C$ is a non-zero homomorphism, then $\|\phi\|\leq 1$. If $\mathfrak{A}$ has an identity, then $\|\phi\|=1$.
\end{proposition}
\begin{proof}
Let $A\in\mathfrak{A}$ and put $\lambda=\phi(A)$. If $|\lambda|>\|A\|$ then $\|\lambda^{-1}A\|<1$. Hence $I-\lambda^{-1}A$ is invertible. Let $B=(I-\lambda^{-1}A)^{-1}$, so $I=B(I-\lambda^{-1}A)=B-\lambda^{-1}BA$. Since $\phi(I)=1$, 
\[1=\phi(I)=\phi(B)-\phi(\lambda^{-1}BA)=\phi(B)-\lambda^{-1}\phi(B)\phi(A)=\phi(B)-\phi(B)=0\]
a contradiction. Hence $|\phi(A)|\leq\|A\|$ for all $A\in\mathfrak{A}$. Since $|\phi(I)|=1$, it follows that $\|\phi\|=1$.
\end{proof}
\begin{theorem}\label{Banach algebra invertible is open set}
Let $\mathfrak{A}$ be a Banach algebra with identity, and set
\[\mathscr{N}_l=\{A\in\mathfrak{A}:\text{$A$ is left-invertible}\},\quad \mathscr{N}_r=\{A\in\mathfrak{A}:\text{$A$ is right-invertible}\},\]
and $\mathscr{N}=\{A\in\mathfrak{A}:\text{$A$ is invertible}\}=\mathscr{N}_l\cap\mathscr{N}_r$. Then $\mathscr{N}_l$, $\mathscr{N}_r$, and $\mathscr{N}$ are open subsets of $\mathfrak{A}$. Also, the inversion map $\inv$ is continuous on $\mathscr{N}$.
\end{theorem}
\begin{proof}
Let $A_0\in\mathscr{N}_l$ and let $B_0\in\mathfrak{A}$ such that $B_0A_0=1$. If $\|A-A_0\|<\|B_0\|^{-1}$, then $\|B_0A-1\|=\|B_0(A-A_0)\|<1$. By the preceding lemma, $B_0A$ is invertible. If $B=(B_0A)^{-1}B_0$, then $BA=1$. Hence $B_{\|B_0\|^{-1}}(A_0)\sub\mathscr{N}_l$ and $\mathscr{N}_l$ must be open. Similarly, $\mathscr{N}_r$ is open. Since $\mathscr{N}=\mathscr{N}_l\cap\mathscr{N}_r$, $\mathscr{N}$ is open.\par
If $A\in\mathscr{N}$ with $\|I-A\|<1$, then
\begin{align*}
\|A^{-1}-I^{-1}\|=\Big\|\sum_{n=1}^{\infty}(I-A)^n-1\Big\|\leq\sum_{n=1}^{\infty}\|I-A\|^n=\|I-A\|(1-\|I-A\|)^{-1},
\end{align*}
so the map $\inv$ is continuous at $I$. For each $a\in\mathscr{N}$, we see
\[\inv=R_{A^{-1}}\circ\inv\circ L_{A^{-1}}\]
and $L_{A^{-1}}$ maps $A$ onto $I$, $\inv$ maps $I$ onto $I$, $R_{A^{-1}}$ maps $I$ onto $A^{-1}$, each mapping continuous at the specified element. Thus $\inv$ is continuous at $A$ and hence on $\mathscr{N}$.
\end{proof}
The elements that are not invertible in $\mathfrak{A}$ are said to be \textbf{singular}. From Theorem~\ref{Banach algebra invertible is open set}, the singular elements form a closed subset of $\mathfrak{A}$. We refer to the invertible elements as \textbf{regular} and \textbf{non-singular} elements as well.\par
Two facts surfaced in the preceding proofs that are worth recording for the future.
\begin{corollary}\label{Banach algebra invertibility}
Let $\mathfrak{A}$ be a Banach algebra with identity.
\begin{itemize}
\item[(a)] If $\|A-I\|<1$ then $A^{-1}=\sum_{n=0}^{\infty}(I-A)^{-1}$.
\item[(b)] If $B_0A_0=1$ and $\|A-A_0\|<\|B_0\|^{-1}$, then $A$ is left invertible.
\end{itemize}
\end{corollary}
\begin{corollary}\label{Banach algebra closure of ideal}
If $\mathfrak{A}$ is a Banach algebra with identity, then
\begin{itemize}
\item[(a)] the closure of a proper left, right, or ideal is a proper left, right, or ideal;
\item[(b)] a maximal left, right, or ideal is closed.
\end{itemize}
\end{corollary}
\begin{proof}
Let $\mathscr{M}$ be a proper left ideal and let $\mathscr{N}_l$ be the set of left-invertible elements in $\mathfrak{A}$. It follows that $\mathscr{M}\cap\mathscr{N}_l=\emp$. Thus $\mathscr{M}\sub\mathfrak{A}\setminus\mathscr{N}_l$. By the preceding theorem, $\mathfrak{A}\setminus\mathscr{N}_l$ is closed. Hence $\widebar{\mathscr{M}}\sub\mathfrak{A}\setminus\mathscr{N}_l$; in particular $\widebar{\mathscr{M}}\neq\mathfrak{A}$. It is easy to check that $\widebar{\mathscr{M}}$ is a left ideal. The proof of the remainder of (a) is similar, and part (b) follows from (a).
\end{proof}
If $\mathfrak{A}$ does not have an identity, then $\mathfrak{A}$ may contain some proper, dense ideals. For example, let $\mathfrak{A}=C_0(\R)$. Then $C_c(\R)$, the continuous functions with compact support, is a dense ideal in $C_0(\R)$. This can not happen if $\mathfrak{A}$ has an identity, however, by the following algebraic result.
\begin{proposition}
If $\mathfrak{A}$ is a Banach algebra with identity, then every proper left, right, or ideal is contained in a maximal ideal of the same type.
\end{proposition}
Let $\mathfrak{A}$ be a Banach algebra and let $\mathscr{M}$ be a proper ideal. Then $\mathfrak{A}/\mathscr{M}$ becomes an algebra. Indeed, $(A+\mathscr{M})(B+\mathscr{M})=AB+\mathscr{M}$ is a well-defined multiplication on $\mathfrak{A}/\mathscr{M}$.
\begin{theorem}
If $\mathfrak{A}$ is a Banach algebra and $\mathscr{M}$ is a proper closed ideal in $\mathfrak{A}$, then $\mathfrak{A}/\mathscr{M}$ is a Banach algebra. If $\mathfrak{A}$ has an identity, so does $\mathfrak{A}/\mathscr{M}$.
\end{theorem}
\begin{proof}
We have already seen that $\mathfrak{A}/\mathscr{M}$ is a Banach space and, as was mentioned prior to the statement of the theorem, it is an algebra. By the definition of norm on $\mathfrak{A}/\mathscr{M}$, it is easy to see that
\[\|AB+\mathscr{M}\|=\|(A+\mathscr{M})(B+\mathscr{M})\|\leq\|(A+\mathscr{M})\|\|(B+\mathscr{M})\|.\]
Thus $\mathfrak{A}/\mathscr{M}$ is a Banach algebra. If $I$ is the identity of $\mathfrak{A}$, then $I+\mathscr{M}$ is an identity of $\mathfrak{A}/\mathscr{M}$.
\end{proof}
It may be that $\mathfrak{A}/\mathscr{M}$ has an identity even if $\mathfrak{A}$ does not. For example, let $\mathfrak{A}=C_0(\R)$ and $\mathscr{M}=\{f\in C_0(\R):f([-1,1])=\{0\}\}$. Then $f+\mathscr{M}=g+\mathscr{M}$ if and only if $f\equiv g$ on $[-1,1]$. Therefore if $f_0\in C_0(\R)$ is such that $f_0\equiv 1$ on $[-1,1]$, then $f_0+\mathscr{M}$ is an identity on $\mathfrak{A}/\mathscr{M}$.
\subsection{Spectrum}
Our Banach algebras are intended to provide the general framework for the study of algebras of (linear) operators on a Hilbert space. In the case of a finite-dimensional space (and when they are present in the infinite-dimensional case), the eigenvectors and their associated eigenvalues play an important role in the analysis of the individual operator. The concept of spectrum, which we study in this part, is devised as the replacement, in the general setting of Banach algebras, for the set of eigenvalues in the finite-dimensional case.
\begin{definition}
If $\mathfrak{A}$ is a Banach algebra with identity and $A\in\mathfrak{A}$, the \textbf{spectrum} of $A$ is defined by
\[\sigma(A)=\{\lambda\in\K:\text{$A-\lambda I$ is not invertible}\}\]
The \textbf{left spectrum} $\sigma_l(A)$ and the \textbf{right spectrum} $\sigma_r(a)$ are defined similarly, so that $\sigma(A)=\sigma_l(A)\cup\sigma_r(A)$. The \textbf{resolvent set} of $A$ is defined by $\rho(A)=\K\setminus\sigma(A)$, and \textbf{left and right resolvents} of $A$ are defined similarly.
\end{definition}
Before beginning the general study of the spectrum, let us note that it serves the purpose for which it is designed. If $X$ is a finite-dimensional (Banach) space and $A$ is a linear transformation of $X$ into itself, then $A-\lambda I$ will fail to have an inverse if and only if it annihilates some (unit) vector $x_0$ in $X$; that is, if and only if $A$ has some unit eigenvector $x_0$ corresponding to the eigenvalue $A$. At the same time, let us note that while an eigenvalue is always in the spectrum, the reverse need not, in general, be the case.
\begin{example}\label{Banach space operator spectrum char}
If $X$ is a Banach space and $A\in\mathcal{B}(X)$, then it follows from the inverse mapping theorem that $\sigma(A)=\{\lambda\in\K:\text{$A-\lambda I$ is not bijective}\}$.
\end{example}
\begin{example}\label{Hilbert space operator left-spectrum char}
If $H$ is a Hilbert space and $A\in\mathcal{B}(H)$, then we claim that
\[\sigma_l(A)=\{\lambda\in\K:\inf\{\|(A-\lambda I)x\|:\|x\|=1\}=0\}.\]
In fact, if $B\in\mathcal{B}(H)$ is a left inverse of $A-\lambda I$, then
\[\|x\|=\|B(A-\lambda I)x\|\leq\|B\|\|(A-\lambda I)x\|\]
so $\|(A-\lambda I)x\|\geq\|B\|^{-1}>0$ for $\|x\|=1$.\par
Conversely, suppose that $\|(A-\lambda I)x\|\geq\delta>0$ for $\|x\|=1$. Then $\|(A-\lambda I)x\|\geq\delta\|x\|$ for all $x\in H$, so $K:=R(A-\lambda I)$ is closed. The map $A-\lambda I:H\to K$ is a bijection, so $(A-\lambda I)^{-1}:K\to H$ is bounded. Define $B:H\to H$ by letting $B=(A-\lambda I)^{-1}P_K$. Then $B$ is a left inverse of $A-\lambda I$.
\end{example}
\begin{example}\label{L^2([0,1]) multiplication by identity spectrum}
Let $H=L^2([0,1])$ and let $A$ be the operator defined by $(Af)(x)=xf(x)$. Then $A$ has no eigenvalues; for if $Af=\lambda f$, $f$ must be $0$ at all points of $[0,1]$ other than $\lambda$. Hence $f$ is $0$ almost everywhere, and $f$ is the element $0$ in $H$.\par
Nonetheless, $\sigma(A)=[0,1]$. To see this, by Example~\ref{Hilbert space operator left-spectrum char} we have
\[\sigma_l(A)=\{\lambda\in\K:\inf\{\|(A-\lambda I)f\|:\|f\|_2=1\}=0\}\]
so it is easy to see $[0,1]\sub\sigma_l(A)\sub\sigma(A)$, by constructing a bump function concentrated near $\lambda\in[0,1]$. If $\lambda\notin[0,1]$, then $f(x):=\chi_{[0,1]}(x)(x-\lambda)^{-1}$ is continous and so in $H$. Let $B=M_f$ be the multiplication by $f$. Then it is easy to see $B=(A-\lambda I)^{-1}$, so $\lambda\notin\sigma(A)$.
\end{example}
\begin{example}
Let $\{e_n\}$ be an orthonormal basis for a separable Hilbert space $H$. Recalling Proposition~\ref{Hilbert space diagonal operator is compact iff}, we have a bounded operator $A$ on $H$ such that $Ae_n=\lambda_ne_n$, where $\{\lambda_n\}$ is an arbitrary bounded (denumerable) subset of $\C$. We saw that $\|A\|=\sup_n|\lambda_n|$, that $A$ is normal, in general, and selfadjoint exactly when all $\lambda_n$ are real, unitary when all $\lambda_n$, have modulus $1$, and positive when all $\lambda_n$ are real and non-negative. Since each $\lambda_n$ is an eigenvalue (with eigenvector $e_n$), $\{\lambda_n\}\sub\sigma(A)$. From Theorem~\ref{Banach algebra complex spectrum nonempty}, $\sigma(A)$ is closed, so that $\widebar{\{\lambda_n\}}$, the closure of $\{\lambda_n\}$, is contained in $\sigma(A)$. If $\lambda$ is not in this closure, then $\inf_n|\lambda-\lambda_n|>0$, and $\{(\lambda_n-\lambda)^{-1}\}$ is a bounded subset of $\C$. Thus there is a bounded operator $B$ on $H$ such that $Be_n=(\lambda_n-\lambda)^{-1}e_n$. It is easy to see $B=(A-\lambda I)^{-1}$, so $\lambda\notin\sigma(A)$. Hence $\widebar{\{\lambda_n\}}=\sigma(A)$.\par
If $\{\lambda_n\}$ is an enumeration of the rationals in $[0,1]$, then $\sigma(A)=[0,1]$. In Example~\ref{L^2([0,1]) multiplication by identity spectrum} we considered an operator with spectrum $[0,1]$ but no eigenvectors. Although the present example and Example~\ref{L^2([0,1]) multiplication by identity spectrum} exhibit self-adjoint operators with the same spectrum, and, in a sense still to be made precise, both of these operators have spectra without "multiplicity" ; these operators are quite different structurally. One has an orthonormal basis of eigenvectors, while the other has not a single eigenvector. In the finite-dimensional case, self-adjoint operators having the same spectrum, each without multiplicity, have identical structure (are "unitarily equivalent").
\end{example}
\begin{example}\label{spectrum in C(X)}
Let $X$ be a compact Hausdorff space. If $f\in C(X)$, then $\sigma(f)=f(X)$. In fact, $f\in C(X)$ is invertible iff $f(x)\neq 0$ for all $x\in X$. 
\end{example}
\begin{example}
If $\mathfrak{A}=\mathcal{M}_2(\R)$ and $A=(\begin{smallmatrix}0&1\\-1&0\end{smallmatrix})$. Then $\sigma(A)=\emp$. In fact, $A$ has no eigenvalue in $\R$.
\end{example}
The phenomenon of the last example does not occur if $\mathfrak{A}$ is a Banach algebra over $\C$.
\begin{theorem}\label{Banach algebra complex spectrum nonempty}
If $\mathfrak{A}$ is a Banach algebra over $\C$ with an identity, then for each $A\in\mathfrak{A}$, $\sigma(A)$ is a non-empty closed subset of the closed disk in $\C$ with center $0$ and radius $\|A\|$. Moreover, the map $f(z)=(A-zI)^{-1}$ is an $\mathfrak{A}$-valued analytic function defined on $\rho(A)$.
\end{theorem}
\begin{proof}
If $|\lambda|>\|A\|$ then $\|\lambda^{-1}A\|<1$, so $A-\lambda I=\lambda(\lambda^{-1}A-I)$ is invertible. Thus $\lambda\notin\sigma(A)$ and $\sigma(A)$ is bounded. Let $\mathscr{N}$ be the set of invertible elements of $\mathfrak{A}$. The map $z\mapsto(A-zI)$ is a continuous function from $\C$ to $\mathfrak{A}$. Since $\mathscr{N}$ is open and $\rho(A)$ is the inverse image of $\mathscr{N}$ under this map, $\rho(A)$ is open. Thus $\sigma(A)=\C\setminus\rho(A)$ is compact.\par
Define $f:\rho(A)\to\mathfrak{A}$ by $f(z)=(A-zI)^{-1}$. Then for $z\in\rho(A)$ and $h\in\C$ such that $z+h\in\rho(A)$, we have
\begin{align*}
\frac{f(z+h)-f(z)}{h}=\frac{(A-zI-hI)^{-1}-(A-zI)^{-1}}{h}=(A-zI-hI)^{-1}(A-zI)^{-1},
\end{align*}
so $f'(z)=(A-zI)^{-2}$. This implies $f$ is analytic on $\rho(A)$.\par
From the first paragraph of the proof, if $|z|>\|A\|$ then $f(z)=z^{-1}(z^{-1}A-I)^{-1}$. But as $z\to\infty$, we see $z^{-1}A\to 0$, and so $f(z)\to 0$. Therefore if $\rho(A)=\C$, then $f$ is an entire function that vanishes at $+\infty$. By Liouville's Theorem $f\equiv 0$. Since $f(z)$ is invertible, this is a contradiction. Thus $\rho(A)\neq\C$ and $\sigma(A)\neq\emp$.
\end{proof}
Because the spectrum of an element of a complex Banach algebra is not empty, we now assume that all Banach spaces and all Banach algebras are over $\C$.\par
We saw that $\sigma(A)$ is contained in the disk in $\C$ with center $0$ and radius $\|A\|$. The radius of the "smallest" disk containing the spectrum will appear in our considerations.
\begin{definition}
If $\mathfrak{A}$ is a Banach algebra with identity and $A\in\mathfrak{A}$, the \textbf{spectral radius} of $A$ is defined by
\[r(A)=\sup\{|\lambda|:\lambda\in\sigma(A)\}.\]
Because $\sigma(A)\neq\emp$ and is bounded, $r(A)$ is well defined and finite; because $\sigma(A)$ is compact, this supremum is attained.
\end{definition}
Now we prove some properties of the spectrums.
\begin{proposition}
Let $\mathfrak{A}$ be a Banach algebra with identity and let $A\in\mathfrak{A}$.
\begin{itemize}
\item[(a)] If $\alpha\in\rho(A)$, then $d(\alpha,\sigma(A))\geq\|(\alpha I-A)^{-1}\|^{-1}$. 
\item[(b)] If $\alpha,\beta\in\rho(A)$ then
\[(A-\alpha I)^{-1}-(A-\beta I)^{-1}=(\beta-\alpha)(A-\alpha I)^{-1}(A-\beta I)^{-1}\] 
\end{itemize}
\end{proposition}
\begin{proof}
By Corollary~\ref{Banach algebra invertibility}, if $\|B-(\alpha I-A)\|<\|(\alpha I-A)^{-1}\|^{-1}$, then $B$ is invertible. So if $\beta\in\C$ and $|\beta|<\|(\alpha I-A)^{-1}\|^{-1}$ then $(\beta+\alpha)I-A$ is invertible; that is, $\alpha+\beta\in\rho(A)$. Thus $d(\alpha,\sigma(A))\geq\|(\alpha I-A)^{-1}\|^{-1}$. Part (b) is easy to verify.
\end{proof}
The identity in part (b) of the preceding proposition is called the \textbf{resolvent identity} and the function
\[R(\cdot,A):\rho(A)\to\mathfrak{A},\quad R(\alpha,A)=(\alpha I-A)^{-1}\] is called the \textbf{resolvent} of $A$.
\begin{proposition}\label{Banach algebra spectrum prop}
Let $\mathfrak{A}$ be a Banach algebra with identity and $A,B\in\mathfrak{A}$.
\begin{itemize}
\item[(a)] If $p$ is a polynomial in a single variable, then $\sigma(p(A))=p(\sigma(A))$.
\item[(b)] If $A$ is invertible, then $\sigma(A^{-1})=\sigma(A)^{-1}$.
\item[(c)] $\sigma(AB)\cup\{0\}=\sigma(BA)\cup\{0\}$.
\item[(d)] If $\mathfrak{A}$ is abelian, then $\sigma(AB)\sub\sigma(A)\sigma(B)$ and $\sigma(A+B)\sub\sigma(A)+\sigma(B)$.
\end{itemize}
\end{proposition}
\begin{proof}
If $\lambda\in\sigma(A)$, then $A-\lambda I$ does not have a two-sided inverse in $\mathfrak{A}$. Thus one of $(A-\lambda I)\mathfrak{A}$ or $\mathfrak{A}(A-\lambda I)$ is a proper ideal $\mathscr{I}$ in $\mathfrak{A}$. If $p(x)=a_nx^n+\cdots+a_0$, then
\[p(A)-p(\lambda I)=a_n(A^n-\lambda^nI)+\cdots+a_1(A-\lambda I).\]
Note that for each $k\geq 1$, we have
\[A^k-\lambda^kI=(A-\lambda I)(A^{k-1}+\cdots+\lambda^{k-1}I)=(A^{k-1}+\cdots+\lambda^{k-1}I)(A-\lambda I)\]
so we conclude that $p(A)-p(\lambda)I\in\mathscr{I}$, so that $p(A)-p(\lambda)I$ does not have a twosided inverse in $\mathfrak{A}$ and $p(\lambda)\in\sigma(p(A))$.\par
If $\gamma\in\sigma(p(A))$ and $\lambda_1,\dots,\lambda_n$ are the $n$ roots of $p(\lambda)-\gamma$, then
\[p(A)-\gamma I=a(A-\lambda_1 I)\cdots(A-\lambda_n I)\]
so that at least one of $A-\lambda_1 I,\dots,A-\lambda_nI$ is not invertible. If $A-\lambda_iI$ is not invertible, then $\lambda_i\in\sigma(A)$ and $y=p(\lambda_i)\in p(\sigma(A))$. Thus $\sigma(p(A))=p(\sigma(A))$.\par
Suppose $A$ is invertible in $\mathfrak{A}$ (equivalently, $0\notin\sigma(A)$). If $\lambda\neq 0$, then
\[A^{-1}-\lambda^{-1}I=(\lambda I-A)\lambda^{-1}A^{-1},\]
so that $\lambda^{-1}\in\sigma(A^{-1})$ if and only if $\lambda\in\sigma(A)$. Thus $\sigma(A^{-1})=\sigma(A)^{-1}$.\par
Suppose now that $A,B\in\mathfrak{A}$. If $\lambda\neq 0$ and $\lambda\in\sigma(AB)$, then $AB-\lambda I$ and, hence, $\lambda^{-1}AB-I$ are not invertible. On the other hand, if $\lambda\notin(BA)$, then $BA-\lambda I$ and, hence, $\lambda^{-1}BA-I$ are invertible. Our task, then, is to show that $I-AB$ is invertible in $\mathfrak{A}$ if and only if $I-BA$ is invertible in $\mathfrak{A}$, for arbitrary elements $A$ and $B$ of $\mathfrak{A}$. Arguing formally, for the moment,
\[B(I-AB)^{-1}A=B\sum_{n=0}^{\infty}(AB)^nA=BA+BABA+\cdots=(I-BA)^{-1}-I\]
Thus if $I-AB$ has an inverse, we may hope that $B(I-AB)^{-1}A+I$ is an inverse to $I-BA$. It is easy to see this is in fact the case.\par
Now assume that $\mathfrak{A}$ is abelian. If $\lambda\in\sigma(AB)$, then $AB-\lambda I$ lies in a proper ideal $\mathscr{I}$ of $\mathfrak{A}$. Since $\mathfrak{A}$ has an identity, $\mathscr{I}$ is contained in a maximal ideal $\mathscr{M}$ of $\mathfrak{A}$. From Proposition~\ref{Banach algebran abelian maximal ideal}, it is the kernel of a homomorphism $\phi:\mathfrak{A}\to\C$. Thus $\lambda=\phi(AB)=\phi(A)\phi(B)$. Since $A-\phi(A)I$ and $B-\phi(B)I$ are in the kernel $\mathscr{M}$ of $\phi$, $\phi(A)\in\sigma(A)$ and $\phi(B)\in\sigma(B)$. Thus $\lambda\in\sigma(A)\sigma(B)$ and $\sigma(AB)\sub\sigma(A)\sigma(B)$. The claim about $\sigma(A+B)$ can be proved similarly.
\end{proof}
\begin{remark}
We make special note of the fact established at the end of the proof of Proposition~\ref{Banach algebra spectrum prop}. If $A$ is an element of an abelian Banach algebra $\mathfrak{A}$ and $\lambda\in\sigma(A)$, then there is a multiplicative linear functional $\phi$ on $\mathfrak{A}$ such that $\phi(A)=\lambda$. Conversely, if $\phi$ is a (non-zero) multiplicative linear functional on $\mathfrak{A}$ (not necessarily abelian), then $\phi(A)\in\sigma(A)$ for each $A$ in $\mathfrak{A}$.
\end{remark}
\subsection{The Riesz function calculus}
We need some concept of line integral of a Banach-space-valued function for this program. The integration we use will be Bochner integral. With $X$ a Banach space and $\Omega$ a domain of $\C$, a function $f:\Omega\to X$ is called \textbf{holomorphic} if it is differentiable at each point of $\Omega$, in the sense that the limit of the usual difference exists in the norm topology of $X$. In this case, we write the derivative of $f$ by $f'$. If $f$ is holomorphic on $\Omega$ and $\varphi$ is a continuous linear functional on $X$, then it is clear that $\varphi\circ f$ is a holomorphic function on $\Omega$ in the usual sense. This fact, together with the Hahn-Banach theorem, provides a way to proving results in the Banach-space-valued holomorphic function theory. Applying this method to a function $f$ holomorphic in a domain $\Omega$ containing a curve $C$ for which the classical Cauchy theorem and formula are valid, we have,
\[0=\int\varphi(f(z))\,dz=\varphi\Big(\int_C f(z)\,dz\Big)\And\varphi(f(z_0))=\frac{1}{2\pi i}\int_C\frac{\varphi(f(z))}{z-z_0}\,dz.\]
for every bounded linear functional $\varphi$ on $X$. Thus we get the corresponding Cauchy theorem and formula for $f$, namely
\[\int_Cf(z)\,dz=0\And f(z_0)=\frac{1}{2\pi i}\int_C\frac{f(z)}{z-z_0}\,dz.\]
for each $z_0$ in the interior of $C$. For the purposes of application in this subject, the curves presented here are all assumed to be piecewise smooth.\par
The method of applying bounded functionals combined with an application of the Hahn-Banach theorem yields the fact that if a power series $\sum_nA_n(z-z_0)^n$, with coefficients $A_n\in X$, converges to $0$ in norm throughout some open disk containing $z_0$, then each $A_n$ is $0$. Repetition of the classical argument establishes the following theorems.
\begin{theorem}
Each function $f$ holomorphic on an open set $\Omega$ in $\C$ and taking values in a Banach space $X$ can be represented as a power series with coefficients in $X$, throughout the largest open disk with center $z_0$ contained in $\Omega$, for each $z_0$ in $\Omega$.
\end{theorem}
\begin{theorem}
The convergence radius $R$ of the power series $\sum_nA_n(z-z_0)^n$ is given by
\[R^{-1}=\varlimsup_n\sqrt[n]{\|A_n\|^n}.\]
\end{theorem}
We use these considerations to establish the spectral radius formula.
\begin{proposition}[\textbf{Spectral Radius Formula}]\label{spectral radius formula}
If $\mathfrak{A}$ is a Banach algebra with identity and $A\in\mathfrak{A}$, then
\[r(A)=\lim_n\sqrt[n]{\|A^n\|}.\]
\end{proposition}
\begin{proof}
Let $D=\{z\in\C:z^{-1}\in\rho(A)\}\cup\{0\}$ and define $f:D\to\mathfrak{A}$ by $f(z)=z(I-zA)^{-1}$. Then $f$ is analytic on $D$ and for $|z|<\|A\|^{-1}$ we have
\[f(z)=z\sum_{n=0}^{\infty}(zA)^n.\]
It is clear that this power series converge in the disk of radius $d(0,\partial D)=r(A)^{-1}$. Also, from the theory of power series, the convergence radius of this series is given by $(\varlimsup_n\sqrt[n]{\|A^n\|})^{-1}$, so we get $r(A)\geq \varlimsup_n\sqrt[n]{\|A^n\|}$.\par
Now if $z\in\C$ and $n\geq 1$, we have
\[z^nI-A^n=(zI-A)(z^{n-1}I+z^{n-2}A+\cdots+A^{n-1}),\]
so if $z^nI-A^n$ is invertible then $zI-A$ is also invertible. In orther words, $\sigma(A)^n\sub\sigma(A^n)$. By Theorem~\ref{Banach algebra complex spectrum nonempty} we have $|\lambda|\leq\|A^n\|$ for each $\lambda\in\sigma(A^n)$, so this implies $r(A)\leq\varliminf_n\sqrt[n]{\|A^n\|}$. Combine this with the previous result, we get the claim.
\end{proof}
Turning now to the case where $\mathfrak{A}$ is a Banach algebra, we note that
\begin{align}\label{Banach algebra A^n=integral}
A^n=\frac{1}{2\pi i}\int_Cz^n(zI-A)^{-1}\,dz.
\end{align}
where $n$ is a positive integer, $A\in\mathfrak{A}$, and $C$ is a smooth closed curve whose interior contains $\sigma(A)$. To see this, observe that $f(z)=(zI-A)^{-1}$ is holomorphic on $\rho(A)$. Employing the Cauchy theorem in the case of the $\mathfrak{A}$-valued function $f(z)$, we may replace $C$ by the (circular) perimeter of a disk with center $0$ and large radius. Assuming $C$ is this circle and $z$ is on $C$,
\[z^n(zI-A)^{-1}=z^{n-1}(I-Az)^{-1}=z^{n-1}\sum_{k=0}^{\infty}A^kz^{-k}=\sum_{k=0}^{\infty}A^kz^{n-k-1}.\]
where convergence is in the norm topology (and uniform on $C$), and
\[\int_CA^kz^{n-k-1}\,dz=A^k\int_Cz^{n-k-1}\,dz=\begin{cases}
0&k\neq n,\\
2\pi iA^n&k=n.
\end{cases}\]
This proves $(\ref{Banach algebra A^n=integral})$. It then follows that
\begin{align}\label{Banach algebra f(A) def}
f(A)=\frac{1}{2\pi i}\int_C f(z)(zI-A)^{-1}\,dz
\end{align}
for each polynomial $f$, when $C$ is as in $(\ref{Banach algebra A^n=integral})$.\par
With the foregoing in mind, we take $(\ref{Banach algebra f(A) def})$ as the definition of $f(A)$ for holomorphic functions $f$. More precisely, when $f$ is holomorphic in an open set containing $\sigma(A)$, we can choose a smaller open set $\Omega$ containing $\sigma(A)$ whose boundary is a closed piecewise smooth curve $C$ and defines $f(A)$ by $(\ref{Banach algebra f(A) def})$. To find the smaller open set with boundary as described, an argument involving a square grid in the plane (with squares of diameter less than the distance from $\sigma(A)$ to the boundary of the initial open set) will suffice. Since the integral in $(\ref{Banach algebra f(A) def})$ converges in norm, from our discussion of line integrals, it represents an element $f(A)$ in $X$. From Cauchy's theorem, $f(A)$ is independent of the curve $C$ constituting the boundary of an open set in which $f$ is holomorphic.\par
Let $\mathcal{H}(A)$ be the set of functions holomorphic in some open set containing $\sigma(A)$ (the open set may vary with the function). The following two results constitute a "calculus" of such functions---the Riesz function calculus.
\begin{theorem}[\textbf{The Riesz Functional Calculus}]
Let $\mathfrak{A}$ be a Banach algebra with identity and $A\in\mathfrak{A}$.
\begin{itemize}
\item[(a)] The mapping $f\mapsto f(A)$ is a homomorphism from $\mathcal{H}(A)$ into $\mathfrak{A}$.
\item[(b)] If $f$ is represented by the power series $\sum_na_nz^n$ on an open set containing $\sigma(A)$, then $f(A)=\sum_na_nA^n$.
\item[(c)] If $\{f_n\}$ are holomorphic on on an open set $\Omega$ containing $\sigma(A)$, and $f_n\to f$ locally uniformly. Then $f_n(A)\to f(A)$.
\end{itemize}
\end{theorem}
\begin{proof}
It is easy to see $f\mapsto f(A)$ is linear. The proof that $f(A)g(A)=(fg)(A)$ requires more effort. Let $\Omega$ be an open set, containing $\sigma(A)$, on which both $f$ and $g$ are holomorphic. We can choose open sets $\Omega_1$ and $\Omega_2$ such that $\sigma(A)\sub\Omega_1$, $\widebar{\Omega}_1\sub\Omega_2$, $\widebar{\Omega}_2\sub\Omega$ and $C_i=\partial\Omega_i$ are piecewise smooth. Then
\begin{align*}
f(A)g(A)&=\Big(\frac{1}{2\pi i}\int_{C_1}f(z)(zI-A)^{-1}\,dz\Big)\Big(\frac{1}{2\pi i}\int_{C_2}f(z)(zI-A)^{-1}\,dz\Big)\\
&=\Big(\frac{1}{2\pi i}\Big)^2\int_{C_1}\int_{C_2}f(z)g(w)\frac{(zI-A)^{-1}-(wI-A)^{-1}}{w-z}\,dzdw\\
&=\frac{1}{2\pi i}\int_{C_1}f(z)(zI-A)^{-1}\Big(\frac{1}{2\pi i}\int_{C_2}\frac{g(w)}{w-z}\,dw\Big)\,dz\\
&\ -\frac{1}{2\pi i}\int_{C_2}g(w)(wI-A)^{-1}\Big(\frac{1}{2\pi i}\int_{C_1}\frac{f(z)}{w-z}\,dz\Big)\,dw.
\end{align*}
But note that $C_2\sub\Ext C_1$, so the second integral gives zero. This then proves $f(A)g(A)=(fg)(A)$, so $f\mapsto f(A)$ is an algebra homomorphism.\par
To prove (b), we may assume that $f$ is defined on the disk of convergence of the series. Let $C$ be a circle with center at $0$ containing $\sigma(A)$ in its interior and contained in an open set on which $f$ is holomorphic and represented by $\sum_na_nz^n$. Then this series converges uniformly on $C$, so that
\[f(A)=\frac{1}{2\pi i}\int_Cf(z)(zI-A)^{-1}\,dz=\frac{1}{2\pi i}\sum_{n=0}^{\infty}\int_Ca_nz^n(zI-A)^{-1}\,dz=\sum_{n=0}^{\infty}a_nA^n.\]
Part (c) can be proved similarly, using Cauchy's formula and uniform convergence on any closed curve.
\end{proof}
The Riesz functional calculus is used in the study of Banach algebras and is especially useful in the study of linear operators on a Banach space. Now our attention must focus on the basic properties of this functional calculus. The first such property is its uniqueness.
\begin{proposition}\label{Reisz function calculus uniqueness}
Let $\mathfrak{A}$ be a Banach algebra with identity and let $A\in\mathfrak{A}$. Let $\tau:\mathcal{H}(A)\to\mathfrak{A}$ be a homomorphism such that
\begin{itemize}
\item[(a)] $\tau(1)=I$.
\item[(b)] $\tau(z)=A$.
\item[(c)] If $\{f_n\}$ is a sequence of holomorphic functions on an open set $\Omega$ containing $\sigma(A)$ converges locally uniformly to $f$, then $\tau(f_n)\to\tau(f)$.
\end{itemize}
Then $\tau(f)=f(A)$ for every $f$ in $\mathcal{H}(A)$.
\end{proposition}
\begin{proof}
The proof uses Runge's Theorem, but first it must be shown that $\tau(f)=f(A)$ whenever $f$ is a rational function. For $n\geq 1$, $\tau(z^n)=\tau(z)^n=A^n$, so $\tau(p)=p(A)$ for polynomials $p$. Let $q$ be a polynomial such that $q$ never vanishes on $\sigma(A)$, so $1/q\in\mathcal{H}(A)$. Then
\[I=\tau(1)=\tau(qq^{-1})=\tau(q)\tau(q^{-1})=\tau(q)\tau(q)^{-1}=q(A)\tau(q)^{-1}.\]
Hence $q(A)$ is invertible and $(q^{-1})(A)=q(A)^{-1}=\tau(q^{-1})$. Therefore $\tau(f)=f(A)$ for rational functions in $\mathcal{H}(A)$.\par
Now let $f\in\mathcal{H}(A)$ and suppose $f$ is analytic on an open set $\Omega$ containing $\sigma(A)$. By Runge's theorem there are rational functions $\{f_n\}$ in $\mathcal{H}(A)$ such that $f_n\to f$ locally uniformly. By (c) of the hypothesis, $\tau(f_n)\to\tau(f)$. By what we have proved, we get $\tau(f)=f(A)$, so the claim follows.
\end{proof}
A fact that has been implicit in the manipulations involving the functional
calculus is that $f(A)$ and $g(A)$ commute for all $f$ and $g$ in $\mathcal{H}(A)$. Still more can be said.
\begin{proposition}
If $A,B\in\mathfrak{A}$ are such that $AB=BA$ and  $f\in\mathcal{H}(A)$, then $f(A)B=Bf(A)$.
\end{proposition}
\begin{proof}
It is easy to see $f(A)B=Bf(A)$ for rational functions $f$, and the general case follows by Runge's theorem.
\end{proof}
In our next result, we identify the spectrum of $f(A)$. The special case where $f$ is a polynomial has been treated in Proposition~\ref{Banach algebra spectrum prop}.
\begin{theorem}[\textbf{Spectral Mapping Theorem}]
If $A$ is an element of a Banach algebra $\mathfrak{A}$ with identity and $f$ is holomorphic on an open neighborhood of $\sigma(A)$, then $\sigma(f(A))=f(\sigma(A))$.
\end{theorem}
\begin{proof}
If $\lambda\in\sigma(A)$, then the function $g$ defined by $f(z)-f(\lambda)=(z-\lambda)g(z)$ is in $\mathcal{H}(A)$. If $f(\lambda)\notin\sigma(f(A))$ then $f(A)-f(\lambda)I$ is invertible and so is $A-\lambda I$ with inverse $g(A)[f(A)-f(\lambda)I]^{-1}$. This contradiction means $f(\lambda)\in\sigma(f(A))$, so $f(\sigma(A))\sub\sigma(f(A))$.\par
Conversely, if $\lambda\notin\sigma(A)$, then $g(z)=[f(z)-f(\lambda)]^{-1}\in\mathcal{H}(A)$ and so $g(A)[f(A)-f(\lambda)I]=I$. Thus $\lambda\notin\sigma(f(A))$; that is, $\sigma(f(A))\sub f(\sigma(A))$.
\end{proof}
An interesting and simple corollary of the holomorphic function calculus and the spectral mapping theorem is the following result.
\begin{proposition}\label{Banach algebra nonconnected spectrum}
Let $\mathfrak{A}$ be a Banach algebra with identity. Suppose that $A\in\mathfrak{A}$ and $\sigma(A)=F_1\cup F_2$, where $F_1$ and $F_2$ are disjoint nonempty closed sets. Then there is a nontrivial idempotent $E\in\mathfrak{A}$ such that
\begin{itemize}
\item[(a)] if $AB=BA$ then $EB=BE$.
\item[(b)] if $A_1=AE$ and $A_2=A(I-E)$, then $A=A_1+A_2$ and $A_1A_2=A_2A_1=0$;
\item[(c)] $\sigma(A_1)=F_1\cup\{0\}$ and $\sigma(A_2)=F_2\cup\{0\}$.
\end{itemize}
\end{proposition}
\begin{proof}
Let $\Omega_1,\Omega_2$ be disjoint open subsets of $\C$ such that $F_i\sub\Omega_i$. Let $C$ be a piecewise smooth closed curve such that $F_1\sub\Int C$ and $F_2\sub\Ext C$. If $f$ is the characteristic function of $\Omega_1$, then $f\in\mathcal{H}(A)$. Let $E=f(A)$, then it is easy to verify that $E^2=E$. Since $\sigma(E)=f(\sigma(A))=\{0,1\}$, we see $E$ is nontrivial. Part (a) and (b) follows immediately.\par
Note that $A_1=AE=(zf)(A)$ and $A_2=A(I-E)=(z(1-f))(A)$. Thus (c) follows from the spectral mapping theorem.
\end{proof}
The composite-function result is an important addition to the function calculus.
\begin{proposition}\label{Banach algebra function calculus composition}
If $A$ is an element of the Banach algebra $\mathfrak{A}$ with identity, $g\in\mathcal{H}(A)$, and $f\in\mathcal{H}(g(A))$, then $f\circ g\in\mathcal{H}(A)$ and $(f\circ g)(A)=f(g(A))$.
\end{proposition}
\begin{proof}
By assumption, $f$ is holomorphic on an open set $\Omega_1$ containing $\sigma(g(A))=g(\sigma(A))$ and $g$ is holomorphic on an open set $\Omega_2$ containing $\sigma(A)$. Thus $f\circ g\in\mathcal{H}(A)$. Let $h_w(z)=[w-g(z)]^{-1}$. For appropriate curves $C_1$ and $C_2$, we have
\begin{align*}
f(g(A))&=\frac{1}{2\pi i}\int_{C_1}f(w)[wI-g(A)]^{-1}\,dw=\frac{1}{2\pi i}\int_{C_1}f(w)h_w(A)\,dw\\
&=\frac{1}{2\pi i}\int_{C_1}f(w)\Big(\frac{1}{2\pi i}\int_{C_2}h_w(z)(zI-A)^{-1}\,dz\Big)\,dw\\
&=\frac{1}{2\pi i}\int_{C_2}(zI-A)^{-1}\Big(\frac{1}{2\pi i}\int_{C_2}f(w)[w-g(z)]^{-1}\,dw\Big)\,dz\\
&=\frac{1}{2\pi i}\int_{C_2}(f\circ g)(z)(zI-A)^{-1}\,dz=(f\circ g)(A).
\end{align*}
This proves the claim.
\end{proof}
\subsection{Dependence of the spectrum on the algebra}
If $\partial\D=\{z\in\C:|z|=1\}$, let $\mathfrak{B}$ be the uniform closure of the polynomials in $C(\partial\D)$. If $\mathfrak{A}=C(\partial\D)$, then the spectrum of $z$ as an element of $\mathfrak{A}$ is $\partial\D$ (Example~\ref{spectrum in C(X)}). That is, $\sigma_{\mathfrak{A}}(z)=\partial\D$.\par
Note that $\mathfrak{B}\subsetneq\mathfrak{A}$, for example, the function $\bar{z}$ is not in $\mathfrak{B}$. Since $z\in\mathfrak{B}$, it has a spectrum as an element of this algebra; denote this spectrum by $\sigma_{\mathfrak{B}}(z)$. There is no reason to believe that $\sigma_{\mathfrak{A}}(z)=\sigma_{\mathfrak{B}}(z)$. In fact, they are not equal.
\begin{proposition}\label{spectrum of z in closure of polynomials in z}
If $\mathfrak{B}$ is the closure in $C(\partial\D)$ of the polynomials in $z$, then $\sigma_{\mathfrak{B}}(z)=\widebar{\D}$.
\end{proposition}
\begin{proof}
To see this first note that $\|z\|_\infty=1$, so that $\sigma_{\mathfrak{B}}(z)\sub\widebar{\D}$ by Proposition~\ref{Banach algebra complex spectrum nonempty}. If $|\lambda|\leq 1$ and $\lambda\notin\sigma_{\mathfrak{B}}(z)$, then there exists $f\in\mathfrak{B}$ such that $f(z-\lambda)=1$. Note that this implies $|\lambda|=1$, since $f$ is continuous on $\partial\D$. Because $f\in\mathfrak{B}$, there is a sequence of polynomials $\{p_n\}$ such that $p_n\to f$ uniformly on $\partial\D$. Thus for every $\eps>0$ there is a $N$ such that for $m,n\geq N$, $\|p_n-p_m\|_{\partial\D}\leq\eps$. By the maximum modulus principle, $\|p_n-p_m\|_{\widebar{\D}}<\eps$. Thus $g(z)=\lim_np_n(z)$ is analytic on $\D$ and continuous on $\widebar{\D}$; also, $g|_{\partial\D}=f$. By the same argument, since $p_n(z)(z-\lambda)\to 1$ uniformly on $\partial\D$, $p_n(z-\lambda)\to 1$ uniformly on $\widebar{\D}$. Thus $g(z)(z-\lambda)=1$ on $\D$. But $g(\lambda)(\lambda-\lambda)=0$, a contradiction. Thus, $\widebar{\D}=\sigma_{\mathfrak{B}}(z)$.
\end{proof}
Thus the spectrum not only depends on the element of the algebra, but also on the algebra. Precisely how this dependence occurs is given below, but it can be said that the example above is typical, both in its statement and its proof, of the general situation. To phrase these results it is necessary to introduce the polynomially convex hull of a compact subset of $\C$.
\begin{definition}
If $A$ is a set and $f:A\to\C$, we define $\|f\|_A=\sup_{z\in A}|f(z)|$. If $K$ is a compact subset of $\C$, define the \textbf{polynomially convex hull} of $K$ to be the set $\hat{K}$ given by
\[\hat{K}=\{z\in\C:|p(z)|\leq\|p\|_K\text{ for every polynomial $p$}\}.\]
The set $K$ is called \textbf{polynomially convex} if $K=\hat{K}$.
\end{definition}
Note that the polynomially convex hull of $\partial\D$ is $\widebar{\D}$, by the maximal modulus principle. This is, again, quite typical. If $K$ is any compact set, then $\C\setminus K$ has a countable number of components, only one of which is unbounded. The bounded components are sometimes called the \textbf{holes} of $K$; a few pictures should convince the reader of the appropriateness of this terminology.
\begin{proposition}
If $K$ is a compact subset of $\C$, then $\C\setminus\hat{K}$ is the unbounded component of $\C\setminus K$. Hence $K$ is polynomially convex if and only if $\C\setminus K$ is connected, if and only if $K$ is simply connnected.
\end{proposition}
\begin{proof}
The second claim follows from Theorem~\ref{simply connected domain in C iff}. Let $\{U_n\}$ be the bounded components of $\C\setminus K$ and $U_0$ be the unbounded component. Put $L=\C\setminus U_0$; hence $L=K\cup\bigcup_{n=1}^{\infty}U_n$. Clearly $K\sub\hat{K}$. If $n\geq 1$, then $U_n$ is a bounded open set and a topological argument implies $\partial U_n\sub K$. By the maximum principle $U_n\sub\hat{K}$. Thus, $L\sub\hat{K}$.\par
If $z_0\in U_0$, then $(z-z_0)^{-1}$ is analytic in a neighborhood of $L$. By Runge's theorem, there is a sequence of polynomials $\{p_n\}$ such that $\|p_n-(z-z_0)^{-1}\|_L\to 0$. If $q_n=p_n(z-z_0)$, then $\|q_n-1\|_L\to 0$. Thus for large $n$, $\|q_n-1\|<1/2$. Since $K\sub L$ and $|q_n(z_0)-1|=1$, this implies that $z_0\notin\hat{K}$. Thus $\hat{K}\sub L$.
\end{proof}
\begin{theorem}\label{Banach algebra spectrum dependence on algebra}
If $\mathfrak{A}$ and $\mathfrak{B}$ are Banach algebras with a common identity such that $\mathfrak{B}\sub\mathfrak{A}$ and $A\in\mathfrak{B}$, then
\begin{itemize}
\item[(a)] $\sigma_{\mathfrak{A}}(A)\sub\sigma_{\mathfrak{B}}(A)$ and $\partial\sigma_{\mathfrak{B}}(A)\sub\partial\sigma_{\mathfrak{A}}(A)$.
\item[(b)] $\widehat{\sigma_{\mathfrak{A}}(A)}=\widehat{\sigma_{\mathfrak{B}}(A)}$.
\item[(c)] If $U$ is a hole of $\sigma_{\mathfrak{A}}(A)$, then $U$ is either contained or disjoint from $\sigma_{\mathfrak{B}}(A)$.
\item[(d)] If $\mathfrak{B}$ is the closure in $\mathfrak{A}$ of all polynomials in $A$, then $\sigma_{\mathfrak{B}}(A)=\widehat{\sigma_{\mathfrak{A}}(A)}$. 
\end{itemize}
\end{theorem}
\begin{proof}
If an element is not invertible in $\mathfrak{A}$, then it is not invertible in $\mathfrak{B}$, of course. This implies $\sigma_{\mathfrak{A}}(A)\sub\sigma_{\mathfrak{B}}(A)$, for $A\in\mathfrak{B}$. Now assume that $\lambda\in\partial\sigma_{\mathfrak{B}}(A)$. Since $\Int\sigma_{\mathfrak{A}}(A)\sub\Int\sigma_{\mathfrak{B}}(A)$, it suffices to show that $\lambda\in\sigma_{\mathfrak{A}}(A)$. Suppose $\lambda\notin\sigma_{\mathfrak{A}}(A)$, thus there is $B\in\mathfrak{A}$ such that $B(A-\lambda I)=(A-\lambda I)B=I$. Since $\lambda\in\partial\sigma_{\mathfrak{B}}(A)$, there exists a sequence $\{\lambda_n\}$ in $\C\setminus\sigma_{\mathfrak{B}}(A)$. Let $(A-\lambda_nI)^{-1}$ be the inverse of $(A-\lambda_nI)^{-1}$ in $\mathfrak{B}$; so $(A-\lambda_nI)^{-1}\in\mathfrak{A}$. Since $\lambda_n\to\lambda$, by the continuity of inversion we see $(A-\lambda_nI)^{-1}\to B$. Thus $B\in\mathfrak{B}$ since $\mathfrak{B}$ is complete. This contradicts the fact that $\lambda\in\sigma_{\mathfrak{B}}(A)$. Now (b) is a consequence of (a) and the maximum modulus principle.\par
Let $U$ be a hole of $\sigma_{\mathfrak{A}}(A)$ and put $U_1=U\cap\sigma_{\mathfrak{B}}(A)$ and $U_2=U\setminus\sigma_{\mathfrak{B}}(A)$. So $U=U_1\cup U_2$ and $U_1\cap U_2=\emp$. Clearly $U_2$ is open. On the other hand, the fact that $\partial\sigma_{\mathfrak{B}}(A)\sub\sigma_{\mathfrak{A}}(A)$ and $U\cap\sigma_{\mathfrak{A}}(A)=\emp$ implies that $U_1=U\cap\Int\sigma_{\mathfrak{A}}(A)$, so $U_1$ is also open. Because $U$ is connected, either $U_1$ or $U_2$ is empty.\par
Now let $\mathfrak{B}$ be as in (d). From (a) and (b) it is known that $\sigma_{\mathfrak{A}}(A)\sub\sigma_{\mathfrak{B}}(A)\sub\widehat{\sigma_{\mathfrak{B}}(A)}$. Fix $\lambda\in\widehat{\sigma_{\mathfrak{B}}(A)}$. If $\lambda\notin\sigma_{\mathfrak{B}}(A)$, then $(A-\lambda I)^{-1}\in\mathfrak{B}$, so there exists a sequence $\{p_n\}$ of polynomials such that $p_n(A)\to(A-\lambda I)^{-1}$. Let $q_n(z)=(z-\lambda)p_n(z)$, then $q_n(A)\to I$, so $\|q_n(A)-I\|\to 0$. By the spectral mapping theorem, $\sigma_{\mathfrak{A}}(q_n(A))=q_n(\sigma_{\mathfrak{A}}(A))$. Thus, because $\lambda\in\widehat{\sigma_{\mathfrak{A}}(A)}$,
\begin{align*}
\|q_n(A)-I\|\geq r(q_n(A)-I)=\sup_{z\in\sigma_{\mathfrak{A}}(A)}|q_n(z)-1|=\|q_n-1\|_{\sigma_{\mathfrak{A}}(A)}\geq|q_n(\lambda)-1|=1.
\end{align*}
This is a contradiction, so the claim is proved.
\end{proof}
\begin{corollary}\label{Banach algebra spectrum subalgebra boundary point}
Let $\mathfrak{A}$ and $\mathfrak{B}$ be Banach algebras with a common identity such that $\mathfrak{B}\sub\mathfrak{A}$ and $A\in\mathfrak{B}$. If $\sigma_{\mathfrak{A}}(A)=\partial\sigma_{\mathfrak{A}}(A)$, then $\sigma_{\mathfrak{A}}(A)=\sigma_{\mathfrak{B}}(A)$.
\end{corollary}
\begin{proposition}\label{Banach algebra subalgebra given spectrum}
Let $\mathfrak{A}$ be a Banach algebra with identity and $A\in\mathfrak{A}$. Let $\{U_n\}$ be the collection of all bounded components of $\C\setminus\sigma_{\mathfrak{A}}(A)$. Then for each $N\sub\N$, there exists a Banach subalgebra $\mathfrak{B}_N$ of $\mathfrak{A}$ with identity such that
\[\sigma_{\mathfrak{B}_N}(A)=\sigma_{\mathfrak{A}}(A)\cup\bigcup_{n\in N}U_n.\]
\end{proposition}
\begin{proof}
For each $N\sub\N$, let $U_N=\bigcup_{n\in N}U_n$ and define $\mathfrak{B}_N$ to be the closure of the elements $f(A)$, where $f\in\mathcal{H}(A)$ is analytic in an open set containing $\sigma_{\mathfrak{A}}(A)\cup U_N$. Then it is easy to see that
\[\sigma_{\mathfrak{A}}(A)\sub\sigma_{\mathfrak{B}_N}(A)\sub\sigma_{\mathfrak{A}}(A)\cup U_N.\]
Fix $\lambda\in U_N$. If $\lambda\notin\sigma_{\mathfrak{B}_N}(A)$, then $(A-\lambda I)^{-1}\in\mathfrak{B}_N$ and so there are elements $\{f_n\}\sub\mathcal{H}(A)$, analytic on $\sigma_{\mathfrak{A}}\cup U_N$, such that $f_n(A)\to(A-\lambda I)^{-1}$. Let $g_n=(z-\lambda)f_n$, then $g_n$ are analytic on $\sigma_{\mathfrak{A}}(A)\cup U_N$ and $g_n(A)\to I$. Then $\|g_n(A)-I\|\to 0$. By the spectral mapping theorem, $\sigma_{\mathfrak{A}}(g_n(A))=g_n(\sigma_{\mathfrak{A}}(A))$. Thus
\[\|g_n(A)-I\|\geq r(g_n(A)-I)=\|g_n-1\|_{\sigma_{\mathfrak{A}}(A)}\]
Since each $g_n$ analytic on $\sigma_{\mathfrak{A}}\cup U_N$, the maximal modulus principle implies that
\[\|g_n-1\|_{\sigma_{\mathfrak{A}}(A)}\geq\|g_n-1\|_{\sigma_{\mathfrak{A}}(A)\cup U_N}\geq|g_n(\lambda)-1|=1.\]
This contradiction means $\lambda\in\sigma_{\mathfrak{B}_N}(A)$, so the claim is proved. 
\end{proof}
\subsection{The spectrum of a linear operator}
\begin{proposition}\label{spectrum and adjoint}
\mbox{}
\begin{itemize}
\item[(a)] If $X$ is a Banach space and $A\in\mathcal{B}(X)$, then $\sigma_l(A)=\sigma_r(A^*)$ and $\sigma(A^*)=\sigma(A)$.
\item[(b)] If $H$ is a Hilbert space and $A\in\mathcal{B}(H)$, then $\sigma_l(A)=\sigma_r(A)^*$ and $\sigma(A^*)=\sigma(A)^*$, where $z^*:=\bar{z}$ for $z\in\C$.
\end{itemize}
\end{proposition}
\begin{proof}
By Proposition~\ref{Banach space map invertible iff adjoint invertible}, $(A-\lambda I)$ is invertible iff $(A-\lambda I)^*=A^*-\lambda I$ is. This proves (a), and (b) follows similarly. 
\end{proof}
In what follows only complex Banach spaces will be considered. The case about Hilbert spaces can be done similarly, with slight modifications.
\begin{definition}
If $A\in\mathcal{B}(X)$, the \textbf{point spectrum} of $A$ is defined by
\[\sigma_p(A)=\{\lambda\in\C:N(A-\lambda I)\neq\{0\}\}.\]
Elements of $\sigma_p(A)$ are called \textbf{eigenvalues}. If $\lambda\in\sigma_p(A)$, non-zero vectors in $N(A-\lambda I)$ are called \textbf{eigenvectors}; $N(A-\lambda I)$ is called the \textbf{eigenspace} of $A$ at $\lambda$.
\end{definition}
\begin{definition}
If $A\in\mathcal{B}(X)$, the \textbf{approximate point spectrum} of $A$ is defined by
\[\sigma_{ap}(A)=\{\lambda\in\C:\inf\{\|(A-\lambda I)x\|:\|x\|=1\}=0\}.\]
Note that $\sigma_{a}(A)\sub\sigma_{ap}(A)$.
\end{definition}
\begin{proposition}\label{Banach space ap spectrum char}
If $A\in\mathcal{B}(X)$ and $\lambda\in\C$, the following statements are equivalent.
\begin{itemize}
\item[(\rmnum{1})] $\lambda\notin\sigma_{ap}(A)$.
\item[(\rmnum{2})] $A-\lambda I$ is injective with closed range.
\item[(\rmnum{3})] There is a constant $\delta>0$ such that $\|(A-\lambda I)x\|\geq\delta\|x\|$ for all $x\in X$.
\end{itemize}
\end{proposition}
\begin{proof}
Clearly it may be assumed that $\lambda=0$, and it is clear that $(\rmnum{1})\Leftrightarrow(\rmnum{3})$ and $(\rmnum{3})\Rightarrow(\rmnum{1})$. Assume (\rmnum{2}) and let $Y=R(A)$; so $A:X\to Y$ is a continuous bijection. By the inverse mapping theorem, there is a bounded operator $B:Y\to X$ such that $BAx=x$ for all $x$ in $X$. Then it is easy to see $\|Ax\|\geq\|B\|^{-1}\|x\|$, so (\rmnum{3}) holds.
\end{proof}
It may be that $\sigma_{p}(A)$ is empty, but it will be shown that $\sigma_{ap}(A)$ is never empty.
\begin{proposition}\label{Banach space operator ap spectrum contain boundary}
If $A\in\mathcal{B}(X)$, then $\partial\sigma(A)\sub\sigma_{ap}(A)$.
\end{proposition}
\begin{proof}
Let $\lambda\in\partial\sigma(A)$ and let $\{\lambda_n\}\sub\rho(A)$ such that $\lambda_n\to\lambda$. Then $\|(A-\lambda_nI)^{-1}\|\to+\infty$. In fact, if the claim were false, then by passing to a subsequence if necessary, it follows that there is a constant $M$ such that $\|(A-\lambda_nI)^{-1}\|\leq M$ for all $n$. Choose $n$ sufficiently large that $|\lambda_n-\lambda|<M^{-1}$, we then have $\|(A-\lambda I)-(A-\lambda_nI)\|<\|(A-\lambda_nI)^{-}\|^{-1}$. By Corollary~\ref{Banach algebra invertibility}, this implies that $(A-\lambda I)$ is invertible, a contradiction.\par
Let $\|x_n\|=1$ be such that $\alpha_n:=\|(A-\lambda_nI)^{-1}x_n\|>\|(A-\lambda_nI)^{-1}\|-n^{-1}$, so that $\alpha_n\to+\infty$. Put $y_n=\alpha_n^{-1}(A-\lambda_nI)^{-1}x_n$. Then $\|y_n\|=1$ and
\[(A-\lambda I)y_n=(A-\lambda_nI)y_n+(\lambda_n-\lambda)y_n=\alpha_n^{-1}x_n+(\lambda-\lambda_n)y_n.\]
so $\|(A-\lambda I)y_n\|\leq\alpha_n^{-1}+|\lambda-\lambda_n|\to 0$, which implies $\lambda\in\sigma_{ap}(A)$.
\end{proof}
\begin{example}[\textbf{The shift operator on $\ell^p$}]
For $1<p<+\infty$, define operators
\[S:\ell^p\to\ell^p,\quad (x_1,x_2,\dots)\mapsto(0,x_1,x_2,\dots)\]
and 
\[T:\ell^q\to\ell^q,\quad (x_1,x_2,\dots)\mapsto(x_2,x_3,\dots)\]
It is easy to see $T=S^*$, so $\sigma(S)=\sigma(T)$. Since $\|S\|=1$, we have $\sigma(S)=\sigma(T)\sub\widebar{\D}$. Also, it is easy to see $\sigma_p(S)=\emp$, and $\sigma_p(T)\sups\D$. Thus $\sigma(S)=\sigma(T)=\widebar{\D}$.\par
If $Tx=\lambda x$ for some nonzero $x=(x_n)\in\ell^q$ and $|\lambda|\leq 1$, then $x_{n+1}=\lambda x_n$ for $n\geq 1$, and so $x=(x_1,\lambda x_1,\lambda^2 x_1,\dots)=x_1\cdot x_\lambda$. But $x_\lambda\in\ell^q$ iff $|\lambda|<1$, so we get $\sigma_{p}(T)=\D$ and $N(T-\lambda I)=\C x_\lambda$.\par
If $|\lambda|<1$, then we see
\[\|(S-\lambda I)x\|=\|Sx-\lambda x\|\geq|\|Sx\|-|\lambda|\|x\||=(1-|\lambda|)\|x\|\]
and so $\lambda\notin\sigma_{ap}(S)$. This implies $\sigma_{ap}(S)=\partial\D$, by Proposition~\ref{Banach space operator ap spectrum contain boundary}. Also, by the same proposition, we have $\partial\D\sub\sigma_{ap}(T)$, and so $\sigma_{ap}(T)=\widebar{\D}$.
\end{example}
Let $A\in\mathcal{B}(X)$ and suppose $\Delta$ is a clopen subset of $\sigma(A)$, so that $\sigma(A)=\Delta\cup(\sigma(A)\setminus\Delta)$. As in Proposition~\ref{Banach algebra nonconnected spectrum},
\[E(\Delta)=E(\Delta;A)=\frac{1}{2\pi i}\int_C(zI-A)^{-1}\,dz\]
where $C$ is a piecewise smooth curve such that $\Delta\sub\Int C$ and $\sigma(A)\setminus\Delta\sub\Ext C$, is an idempotent. Moreover, $E(\Delta)B=BE(\Delta)$ whenever $AB=BA$. The element $E(\Delta)$ is called the \textbf{Riesz idempotent} corresponding to $\Delta$. If $\Delta$ is singleton set $\{\lambda\}$, let $E(\lambda)=E(\{\lambda\})$. Note that a singleton $\{\lambda\}$ is clopen in $\sigma(A)$ iff $\sigma$ is an isolated point of $\sigma(A)$.
\begin{proposition}\label{Banach space operator spectrum nonconnected}
Let $X$ be a Banach space and let $A\in\mathcal{B}(X)$. If $\sigma(A)=F_1\cup F_2$ are disjoint closed subsets of $\C$, then there are topologically complementary subs paces $X_1,X_2\sub X$ such that
\begin{itemize}
\item[(a)] $B(X_i)\sub X_i$ whenever $AB=BA$.
\item[(b)] If $A_i=A|_{X_i}$, then $\sigma(A_i)=F_i$.
\item[(c)] There is an invertible operator $R:X\to X_1\oplus X_2$ such that $RAR^{-1}=A_1\oplus A_2$.
\end{itemize}
\end{proposition}
\begin{proof}
Consider the idempotents $E$ associated with $F_1$. Set $X_1=R(E)$ and $X_2=N(E)$. Since $E$ is continuous, $X=R(E)\oplus N(E)$ is a topological complemention, by Proposition~\ref{TVS topological complement iff}.\par
If $AB=BA$ then $BE=EB$, by Proposition~\ref{Banach algebra nonconnected spectrum}. Thus $X_1$ and $X_2$ are invariant under $B$. This proves (a). In particular, $X_1$ and $X_2$ are invariant under $A$, so with the direct sum decomposition $X=X_1\oplus X_2$, $A$ has a diagonal form $A=A_1\oplus A_2$, where $A_1=A|_{X_1}$ and $A_2=A|_{X_2}$, this proves (c). Part (b) now follows from (c).
\end{proof}
\begin{example}
Let $\{\alpha_n\}\sub\ell^\infty$ and define $A:\ell^p\to\ell^p$ by $(Ax)(n)=\alpha_nx(n)$. Then $\sigma(A)=\widebar{\{\alpha_n\}}$ and $\sigma_p(A)=\{\alpha_n\}$. For each $k$, define $N_k=\{n\in\N:\alpha_n=\alpha_k\}$ and define $P_k:\ell^p\to\ell^p$ by $P_kx=\chi_{N_k}x$. If $\alpha_k$ is an isolated point of $\sigma(A)$, then $\{\alpha_k\}$ is a clopen subset of $\sigma(A)$ and $E(\alpha_k;A)=P_k$.
\end{example}
Suppose $A\in\mathcal{B}(X)$ and $\lambda_0$ is an isolated point in $\sigma(A)$. Hence $E(\lambda_0)=E(\lambda_0;A)$ is a well-defined idempotent. Also, $\lambda_0$ is an isolated singularity of the analytic function $z\mapsto(zI-A)^{-1}$ on $\rho(A)$. Perhaps the nature of this singularity (pole or essential singularity) will reveal something of the nature of $\lambda_0$ as an element of $\sigma(A)$.
\begin{proposition}\label{spectrum isolated point pole iff}
If $\lambda_0$ is an isolated point of $\sigma(A)$, then $\lambda_0$ is a pole of $(zI-A)^{-1}$ of order $n$ if and only if $(\lambda_0I-A)^nE(\lambda_0)=0$ and $(\lambda_0I-A)^{n-1}E(\lambda_0)\neq 0$.
\end{proposition}
\begin{proof}
Let $f(z)=(zI-A)^{-1}=\sum_nA_n(z-\lambda_0)^n$ be the Laurant expansion. Now $\lambda_0$ is a pole of order $n$ if and only if $A_{-n}\neq 0$ and $A_{-k}=0$ for $k>n$. Let $\gamma$ be a circle centered at $\lambda_0$ and contained in $\Int\Gamma$, then
\begin{align*}
A_{-k}&=\frac{1}{2\pi i}\int_{\gamma}(z-\lambda_0)^{k-1}(zI-A)^{-1}\,dz=(A-\lambda_0I)^{k-1}E(\lambda_0)
\end{align*}
thus the claim follows.
\end{proof}
\begin{corollary}
If $\lambda_0$ is an isolated point of $\sigma(A)$ and is a pole of $(z-A)^{-1}$, then $\lambda_0\in\sigma_p(A)$.
\end{corollary}
\begin{proof}
If $n$ is the order of the pole, then $\{0\}\neq R((\lambda_0I-A)^{n-1}E(\lambda_0))\sub N(A-\lambda_0I)$ by the preceding result.
\end{proof}
\subsection{The spectral theory of a compact operator}
Recall that for a Banach space $X$, $\mathcal{K}(X)$ is the algebra of all compact operators. This Banach algebra has no identity, unless $X$ is finite-dimensional. So if $A\in\mathcal{K}(X)$, then $\sigma(A)$ refers to the spectrum of $A$ as an element of $\mathcal{B}(X)$.
\begin{proposition}\label{Banach space compact operator eigenspace finite dim}
If $A\in\mathcal{K}(X)$ and $0\neq\lambda\in\sigma_p(A)$, then the eigenspace $N(A-\lambda I)$ is finite-dimensional.
\end{proposition}
\begin{proof}
Suppose there is an infinite orthonormal sequence $\{e_n\}$ in $N(A-\lambda I)$. Since $A$ is compact, there is a subsequence $\{e_{n_k}\}$ such that $\{Ae_{n_k}\}$ converges. Thus, $\{Ae_{n_k}\}$ is a Cauchy sequence. But
\[\|Ae_{n_i}-Ae_{n_j}\|^2=\lambda^2\|e_{n_i}-e_{n_j}\|^2=2\lambda^2\neq 0.\]
This contradiction shows that $N(A-\lambda I)$ must be finite dimensional.
\end{proof}
\begin{proposition}\label{Banach space compact operator eigenvalue if ap spectrum}
If $A$ is a compact operator on $\mathcal{B}(X)$, $0\neq\lambda\in\sigma_{ap}(A)$. Then $\lambda\in\sigma_p(A)$.
\end{proposition}
\begin{proof}
By hypothesis, there is a sequence of unit vectors $\{x_n\}$ such that $\|(A-\lambda I)x_n\|\to 0$. Since $A$ is compact, there is a vector $y\in X$ and a subsequence $\{x_{n_k}\}$ such that $Ax_{n_k}\to y$. Then
\[x_{n_k}=\lambda^{-1}(\lambda x_{n_k}-Ax_{n_k}+Ax_{n_k})\to\lambda^{-1}y,\]
so $\|y\|=\lambda$ and in particular $y\neq 0$. Also, we get $Ax_{n_k}\to\lambda^{-1}Ay$. This implies $\lambda^{-1}Ay=y$, so $Ay=\lambda y$ and $\lambda\in\sigma_p(A)$.
\end{proof}
\begin{proposition}\label{Banach space spectrum of compact operator is eigen or dual eigen}
If $A\in\mathcal{K}(X)$ and $0\neq \lambda\in\sigma(A)$, then either $\sigma\in\sigma_p(A)$ or $\sigma\in\sigma_p(A^*)$.
\end{proposition}
\begin{proof}
Since $\sigma_p(A)\sub\sigma(A)$, we may assume that $\lambda\notin\sigma_p(A)$ and $\lambda\notin\sigma_p(A^*)$. Since $\lambda\notin\sigma_p(T)$ the preceding proposition implies that $\lambda\notin\sigma_{ap}(A)$, so $R(A-\lambda I)$ is closed and by Proposition~\ref{polar and adjoint}, $R(A-\lambda I)=N(A^*-\lambda I)^\bot=X$. Thus $\lambda\notin\sigma(A)$, a contradiction.
\end{proof}
Before proving the main theorem of this part, some lemmas are needed.
\begin{lemma}\label{Banach space closed subspace diatance lemma}
If $M$ is a closed subspace of $X$ and $\eps>0$, then there exists $x\in X$ such that $\|x\|=1$ and $d(x,M)>1-\eps$.
\end{lemma}
\begin{proof}
Let $\delta(x)=d(x,M)$ for every $x\in X$. Now if $x_1\in X\setminus M$, there is an $m_0\in M$ such that
\[\delta(x_1)\leq\|x_1-m_0\|\leq(1+\eps)\delta(x_1).\]
Let $x=\|x_1-m_0\|^{-1}(x_1-m_0)$. Then it is easy to see that $x$ satisfies the conditions.
\end{proof}
\begin{lemma}\label{Banach space compact spectrum zero limit}
If $A\in\mathcal{K}(X)$ and $\{\lambda_n\}$ is a sequence of distinct elements in $\sigma_p(A)$, then $\lim_n\lambda_n=0$.
\end{lemma}
\begin{proof}
For each $n$ let $x_n\in N(A-\lambda_nI)$ such that $x_n\neq 0$. It follows that if $M_n=\langle x_1,\dots,x_n\rangle$ then $M_n\subsetneq M_{n+1}$ and $M_n$ is closed in $X$. By the preceding lemma there is a vector $y_n\in M_n$. such that $\|y_n\|=1$ and $d(y_n,M_{n-1})>1/2$. Let $y_n=\alpha_1x_1+\cdots+\alpha_nx_n$, then
\[(A-\lambda_nI)y_n=\alpha_1(\lambda_1-\lambda_n)x_1+\cdots+\alpha_{n-1}(\lambda_{n-1}-\lambda_n)x_{n-1}\in M_{n-1}.\]
Therefore, for $n>m$,
\begin{align*}
A(\lambda_n^{-1}y_n)-A(\lambda_m^{-1}y_m)&=\lambda_n^{-1}(A-\lambda_nI)y_n+\lambda_m^{-1}(A-\lambda_mI)y_m+y_n-y_m\\
&=y_n-[y_m+\lambda_n^{-1}(A-\lambda_nI)y_n+\lambda_m^{-1}(A-\lambda_mI)y_m]
\end{align*}
But the bracketed expression belongs to $M_{n-1}$, so $\|A(\lambda_n^{-1}y_n)-A(\lambda_m^{-1}y_m)\|\geq d(y_n,M_{n-1})>1/2$. Therefore $\{A(\lambda_n^{-1}y_n)\}$ can have no convergent subsequence. But $A$ is a compact operator, so it must be that $\{\lambda_n^{-1}y_n\}$ has no bounded subsequence. Since $\|y_n\|=1$ for all $n$, it must be that $\|\lambda_n^{-1}\|\to+\infty$, that is, $\lim_n\lambda_n=0$.
\end{proof}
\begin{theorem}[\textbf{Riesz}]\label{Banach space spectrum of compact operator}
Let $X$ be an infinite-dimensional Banach space and $A\in\mathcal{K}(X)$. Then $\sigma(A)=\{\lambda_n\}\cup\{0\}$ where $\lambda_n$ are eigenvalues with $\dim N(A-\lambda_nI)<+\infty$. Moreover, if $\sigma(A)$ is infinite then $\lim_n\lambda_n=0$.
\end{theorem}
\begin{proof}
Let $\lambda\in\sigma(A)$ with $\sigma\neq 0$, then $\lambda$ is an isolated point of $\sigma(A)$. In fact, if $\{\lambda_n\}\sub\sigma(A)$ and $\lambda_n\to\lambda$, then each $\lambda_n$ belongs to either $\sigma_p(A)$ or $\sigma_p(A^*)$ by Proposition~\ref{Banach space spectrum of compact operator is eigen or dual eigen}. So there is a subsequence $\{\lambda_{n_k}\}$ contained in $\sigma_p(A)$ or $\sigma_p(A^*)$. If $\{\lambda_{n_k}\}\sub\sigma_p(A)$, then Lemma~\ref{Banach space compact spectrum zero limit} implies $\lambda_n\to 0$, a contradiction. If $\{\lambda_{n_k}\}\sub\sigma_p(A^*)$, then the fact that $A^*$ is compact gives the same contradiction. Thus $\lambda$ must be isolated if $\lambda\neq 0$. This implies $\sigma(A)$ is countable, if infinite.\par
Fix $0\neq\lambda\in\sigma(A)$. Since $\lambda$ is an isolated point of $\sigma(A)$, the Riesz idempotent $E(\lambda)$ can be defined. Let $X_\lambda=R(E(\lambda))$ and $A_\lambda=A|_{X_\lambda}$. Then by Proposition~\ref{Banach space operator spectrum nonconnected} we have $\sigma(A_\lambda)=\{\lambda\}$. Thus $A_\lambda$ is an invertible compact operator. By Corollary~\ref{Banach space compact operator invertible iff}, $\dim X_\lambda<+\infty$, so $A_\lambda-\lambda I$ has a eigenvector in $X_\lambda$. It follows that $\lambda\in\sigma_p(A)$.\par
Now for the denouement. If $\dim X=+\infty$ and $A\in\mathcal{K}(X)$, then $A$ cannot be invertible so $0\in\sigma(A)$. If $0\neq\lambda\in\sigma(A)$, then $\lambda\in\sigma_p(A)$ and $\dim N(A-\lambda I)<+\infty$. If $\sigma(A)$ is infinite then it is countable. Moreover, Lemma~\ref{Banach space compact spectrum zero limit} says $\lim_n\lambda_n\to 0$.
\end{proof}
\begin{corollary}\label{Banach space compact operator eigenspace prop}
If $A\in\mathcal{K}(X)$ and $0\neq\lambda\in\sigma(A)$, then $\lambda$ is a pole of $(zI-A)^{-1}$, $N(A-\lambda I)\sub R(E(\lambda))$, and $\dim R(E(\lambda))<+\infty$.
\end{corollary}
\begin{proof}
The only part of this corollary that did not appear in the preceding proof is the fact that $N(A-\lambda I)\sub R(E(\lambda))$.\par
Let $\Delta=\sigma(A)\setminus\{\lambda\}$, $X_\Delta=R(E(\Delta))$, and $A_\Delta=A|_{X_\Delta}$. By Proposition~\ref{Banach space operator spectrum nonconnected}, $\sigma(A_\Delta)=\Delta$, so $A_\Delta-\lambda I$ is invertible on $X_\Delta$. If $x\in N(A-\lambda I)$, then $x=E(\lambda)x+E(\Delta)x$. Hence
\[0=(A-\lambda I)x=(A-\lambda I)E(\lambda)x+(A-\lambda I)E(\Delta)x=(A_\lambda-\lambda I)E(\lambda)x+(A_\Delta-\lambda I)E(\Delta)x.\]
But $X_\lambda$ and $X_\Delta$ are invariant under $A$, so $(A_\lambda-\lambda I)E(\lambda)x\in X_\lambda$ and $(A_\Delta-\lambda I)E(\Delta)x\in X_\Delta$. Since $X_\lambda\oplus X_\Delta=X$, we then get $(A_\lambda-\lambda I)E(\lambda)x=(A_\Delta-\lambda I)E(\Delta)x=0$. But $A_\Delta-\lambda I$ is invertible on $X_\Delta$, so this implies $E(\Delta)x=0$. That is, $x=E(\lambda x)\in X_\lambda$. Hence $N(A-\lambda I)\sub R(E(\lambda))$.
\end{proof}
The next result has a number of applications in the theory of integral equations.
\begin{theorem}[\textbf{The Fredholm Alternative}]
If $A\in\mathcal{K}(X)$ and $\lambda\neq 0$, then $R(A-\lambda I)$ is closed and $\dim N(A-\lambda I)=\dim N(A-\lambda I)^*<+\infty$.
\end{theorem}
\begin{proof}
It suffices to assume that $\lambda\in\sigma(A)$. Put $\Delta=\sigma(A)\setminus\{\lambda\}$, $X_\Delta=R(E(\Delta))$, and $A_\Delta=A|_{X_\Delta}$. Now $\sigma(A_\Delta)=\Delta$, so $A_\Delta-\lambda I$ is invertible. Thus $R(A_\Delta-\lambda I)=X_\Delta$, and
\[R(A-\lambda I)=(A-\lambda I)(X_\lambda)+(A-\lambda I)(X_\Delta)=R(A_\lambda-\lambda I)+X_\Delta.\]
Since $\dim X_\lambda<+\infty$ (Corollary~\ref{Banach space compact operator eigenspace prop}) and $X_\Delta$ is also closed, it follows that $R(A-\lambda I)$ is closed (Theorem~\ref{TVS finite dim prop}).\par
Also note that
\[X/R(A-\lambda I)=(X_\Delta+X_\lambda)/(R(A_\lambda-\lambda I)+X_\Delta)=X_\lambda/R(A_\lambda-\lambda I)\]
Since $\dim X_\lambda<+\infty$, this implies $\dim X/R(A-\lambda I)<+\infty$. But $[X/R(A-\lambda I)]^*\cong R(A-\lambda I)^\bot=N(A-\lambda I)^*$, so the second claim follows.
\end{proof}
\begin{corollary}
If $A\in\mathcal{K}(X)$ and $\lambda\neq 0$, then for every $y\in X$ there is an $x\in X$ such that $(A-\lambda I)x=y$ if and only if the only vector $x$ such that $(A-\lambda I)x=0$ is $x=0$. If this condition is satisfied, then the solution is unique.
\end{corollary}
\begin{proof}
Since $R(A-\lambda I)$ is closed, it equals $X$ if and only if $N(A-\lambda I)^*=\{0\}$. By Fredholm Alternative, this is equivalent to $N(A-\lambda I)=\{0\}$.
\end{proof}
\subsection{Commutative Banach algebras}
Recall that it is assumed that every Banach algebra is over $\C$. In this part we will examine abelian Banach algebras containing an identity.\par
A \textbf{division algebra} is an algebra such that every nonzero element has a multiplicative inverse. It may seem incongruous that the first theorem in this part allows the algebra to be nonabelian. However, the conclusion is that the algebra is abelian---and much more.
\begin{theorem}[\textbf{Gelfand-Mazur Theorem}]
If $\mathfrak{A}$ is a Banach algebra with identity that is also a division ring, then $\mathfrak{A}=\C:=\{\lambda I:\lambda\in\C\}$.
\end{theorem}
\begin{proof}
If each element of $\mathfrak{A}$ other than $0$ has an inverse in $\mathfrak{A}$ (so that $\mathfrak{A}$ is a division algebra), then if $\lambda\in\sigma(A)$, we must have $A-\lambda I=0$ (being a singular element of $\mathfrak{A}$). Thus, in this case, $\mathfrak{A}$ consists of just scalar multiples of $\C$. Since $\mathfrak{A}$ is, then, isomorphic to $\C$.
\end{proof}
As a corollary of the preceding theorem, the algebra of quaternions, $\H$, is not a Banach algebra. That is, it is impossible to put a norm on $\H$ that makes it into a Banach algebra over $\C$.
\begin{proposition}\label{Banach algebran abelian maximal ideal}
If $\mathfrak{A}$ is an abelian Banach algebra and $\mathscr{M}$ is a maximal ideal in $\mathfrak{A}$, then $\mathfrak{A}/\mathscr{M}\cong\C$ and the quotient map is a continuous homomorphism on $\mathfrak{A}$. If $\mathfrak{A}$ is an arbitrary Banach algebra and $\phi:\mathfrak{A}\to\C$ is a homomorphism, then $\phi$ is continuous with kernel $\mathscr{M}$ a maximal ideal in $\mathfrak{A}$ such that $\mathfrak{A}/\mathscr{M}\cong\C$.
\end{proposition}
\begin{proof}
We noted, in Corollary~\ref{Banach algebra closure of ideal}, that a maximal ideal $\mathscr{M}$ in a Banach algebra $\mathfrak{A}$ is closed. Since $\mathscr{M}$ is maximal, if $\mathfrak{A}$ is abelian, then $\mathfrak{A}/\mathscr{M}$ is a field---and a Banach algebra. From the preceding corollary, $\mathfrak{A}/\mathscr{M}\cong\C$, and the quotient map $\pi$ is a continuous homomorphism of $\mathfrak{A}$ onto $\C$).\par
Conversely, if $\phi$ is a homomorphism of $\mathfrak{A}$ onto $\C$, its kernel $\mathscr{M}$ is a maximal two-sided ideal in $\mathfrak{A}$. Hence $\mathscr{M}$ is closed and, from Proposition~\ref{TVS linear functional continuous iff kernel closed}, $\phi$ is continuous. In general, if $\mathfrak{A}$ is not abelian and $\mathscr{M}$ is a maximal two-sided ideal in $\mathfrak{A}$, we cannot conclude that $\mathfrak{A}/\mathscr{M}$ is a field; so that no continuous homomorphism need be associated with $\mathscr{M}$.
\end{proof}
\begin{corollary}
If $\mathfrak{A}$ is an abelian Banach algebra, there is a bijective correspondence between homomorphisms from $\mathfrak{A}$ to $\C$ and maximal ideals of $\mathfrak{A}$.
\end{corollary}
\begin{definition}
If $\mathfrak{A}$ is an abelian Banach algebra, let $\mathfrak{M}$ the collection of all nonzero homomorphisms of $\mathfrak{A}$ to $\C$. Give $\mathfrak{M}$ the relative weak$^*$ topology that it has as a subset of $\mathfrak{A}^*$. $\mathfrak{M}$ with this topology is called the \textbf{maximal ideal space} of $\mathfrak{A}$.
\end{definition}
\begin{theorem}\label{Banach algebran abelian maximal space prop}
If $\mathfrak{A}$ is an abelian Banach algebra, then its maximal ideal space $\mathfrak{M}$ is a compact Hausdorff space. Moreover, if $A\in\mathfrak{A}$, then $\sigma(A)=\mathfrak{M}(A):=\{\phi(A):\phi\in\mathfrak{M}\}$.
\end{theorem}
\begin{proof}
Since $\mathfrak{M}\sub B_{\mathfrak{A}^*}$, it suffices for the proof of the first part of the theorem to show that $\mathfrak{M}$ is weak$^*$ closed. Let $(\phi_\alpha)$ be a net in $\mathfrak{M}$ and suppose that $\phi_\alpha\to\phi\in B_{\mathfrak{A}^*}$ weakly. It is easy to see  $\phi$ is a homomorphism and $\phi\in\mathfrak{M}$. Thus $\mathfrak{M}$ is compact.\par
If $\phi\in\mathfrak{M}$, then $\phi(A-\phi(A)I)=0$, so $\phi(A)\in\sigma(A)$. Now assume that $A-\lambda I$ is not invertible. Then $A-\lambda I$ is contained in a maximal ideal $\mathscr{M}$. Let $\phi$ be the homomorphism such that $\ker\phi=\mathscr{M}$, then $\phi(A-\lambda I)=0$, and $\phi(A)=\lambda$. This shows $\sigma(A)=\mathfrak{M}(A)$.
\end{proof}
Now it is time for an example. Here is one that is a little more than an example. If $X$ is compact and $x\in X$, we have the evaluation map $\delta_x:C(X)\to\K$, which is defined by $\delta_x(f)=f(x)$. It is easy to see that $\delta_x$ is a homomorphism on the algebra $C(X)$.
\begin{proposition}\label{maximal space of C(X) homeomorphic to X}
If $X$ is compact Huasdorff and $\mathfrak{M}$ is the maximal ideal space of $C(X)$, then the map $x\mapsto\delta_x$ is a homeomorphism of $X$ onto $\mathfrak{M}$.
\end{proposition}
\begin{proof}
Let $\delta:X\to\mathfrak{M}$ be defined by $\delta(x)=\delta_x$. As was pointed out before, $\delta(x)\sub\mathfrak{M}$. By Proposition~\ref{evaluation on BC(X) is homeomorphism iff completely regular}, $\delta$ is a homeomorphism onto $\delta(X)$. Thus it only remains to show that $\delta(X)=\mathfrak{M}$. Let $\phi\in\mathfrak{M}$, there is a measure $\mu$ in $M(X)$ such that $\phi(f)=\int_Xf\,d\mu$ for all $f\in C(X)$. Also, $\|\mu\|=\|\phi\|=1$ and $\mu(X)=\int 1\,d\mu=\phi(1)=1$. Since $\mu=\mu^+-\mu^-$ and $\|\mu\|=\mu^+(X)+\mu^-(X)$, it follows that $\mu$ is positive. We now show that that $\mu$ is supported on a singleton.\par
Let $x\in\supp(\mu)$ and $\m_x:=\{f\in C(X):f(x)=0\}$. So $\m_x$ is a maximal ideal of $C(X)$. Let $f\in\ker\phi$, then $|f|^2=f\bar{f}\in\ker\phi$ so $\int|f|^2\,d\mu=0$. Since $\mu\geq 0$, it must be that $f$ vanishes on $\supp(\mu)$ and so $f\in\m_x$. This implies $\ker\phi\sub\m_x$. But since $\ker\phi$ is a maximal ideal, we then get $\ker\phi=\m_x$. This implies $\mu=\delta_x$.
\end{proof}
\begin{corollary}
Let $X$ be a compact Hausdorff space, then the maximal ideals in $C(X)$ are of the form $\m_x$, for $x\in X$.
\end{corollary}
\begin{definition}
Let $\mathfrak{A}$ be an abelian Banach algebra with maximal ideal space $\mathfrak{A}$. If $A\in\mathfrak{A}$, the \textbf{Gelfand transform} of $A$ is the function $\hat{A}:\mathfrak{M}\to\C$ defined by $\hat{A}(\phi)=\phi(A)$.
\end{definition}
\begin{theorem}\label{Banach algebra Gelfand transform prop}
If $\mathfrak{A}$ is an abelian Banach algebra with maximal ideal space $\mathfrak{M}$ and $A\in\mathfrak{A}$, then the Gelfand transform of $A$ belongs to $C(\mathfrak{M})$. The map $\Gamma:\mathfrak{A}\to C(\mathfrak{M})$ is a continuous homomorphism of $\mathfrak{A}$ into $C(\mathfrak{M})$ of norm $1$ and its kernel is $J(\mathfrak{A})$. Moreover, for each $A\in\mathfrak{A}$, $\|\hat{A}\|_\infty=r(A)$.
\end{theorem}
\begin{proof}
The continuity of $\hat{A}$ follows from the definition of weak$^*$ topology. Since each element in $\mathfrak{M}$ is a homomorphism, it is easy to see $A\mapsto\hat{A}$ is a homomorphism. Also, if $A\in\mathfrak{A}$, then
\[\|\hat{A}(\phi)\|=\|\phi(A)\|\leq\|\phi\|\|A\|=\|A\|.\]
Since $\hat{I}=1$, it follows that $\|\Gamma\|=1$. The kernel of $\Gamma$ is clearly $J(\mathfrak{A})$, and the last statement follows from Proposition~\ref{Banach algebran abelian maximal space prop}.
\end{proof}
If $\mathfrak{A}$ is an abelian algebra, say that $A\in\mathfrak{A}$ is a \textbf{generator} of $\mathfrak{A}$ if $\{p(A):p\in\C[x]\}$ is dense in $\mathfrak{A}$. Recall that if $\tau:X\to Y$ is a homeomorphism, then $\tau^*:C(Y)\to C(X)$ defined by $\tau^*(f)=f\circ\tau$ is an isometric isomorphism.
\begin{proposition}\label{Banach algebra generator spactrum isomorphic}
If $\mathfrak{A}$ is an abelian Banach algebra and $A$ is a generator of $\mathfrak{A}$, then there is a homeomorphism $\tau:\mathfrak{M}\to\sigma(A)$ such that if $\Gamma:\mathfrak{A}\to C(\mathfrak{M})$ is the Gelfand transform and $p$ is a polynomial, then $\Gamma(p(A))=\tau^*(p)$.
\end{proposition}
\begin{proof}
Define $\tau:\mathfrak{M}\to\sigma(A)$ by $\tau(\phi)=\phi(A)$. By Proposition~\ref{Banach algebran abelian maximal space prop}, $\tau$ is surjective. It is easy to see that $\tau$ is continuous. To see that $\tau$ is injective, suppose $\phi_1(A)=\phi_2(A)$, hence $\phi_1(A^n)=\phi_2(A^n)$ for all $n\in\N$. By linearity, $\phi_1(p(A))=\phi_2(p(A))$ for every polynomial $p$. Since $A$ is a generator for $\mathfrak{A}$ and $\phi_1$, $\phi_2$ are continuous on $\mathfrak{A}$, $\phi_1=\phi_2$, and $\tau$ is injective. Since $\mathfrak{M}$ is compact, $\tau$ is a homeomorphism.\par
Since $\Gamma$ and $\tau^*$ are homomorphisms, we have
\[\Gamma(p(A))(\phi)=p(\Gamma(A))(\phi)=p(\hat{A})(\phi)=p(\hat{A}(\phi))=p(\phi(A))=p(\tau(\phi))=\tau^*(p)(\phi).\]
Thus the claim follows.
\end{proof}
\begin{corollary}
If $\mathfrak{A}$ has two elements $A_1$ and $A_2$ each of which is a generator, then $\sigma(A_1)$ and $\sigma(A_2)$ are homeomorphic.
\end{corollary}
\begin{example}
Let $\mathfrak{A}$ be the closure in $C(\partial\D)$ of the polynomials in $z$. If $\mathfrak{M}$ is the maximal ideal space of $\mathfrak{A}$, then $\mathfrak{A}$ is homeomorphic to $\sigma_{\mathfrak{A}}(z)$. Now $\sigma_{\mathfrak{A}}(z)=\widebar{\D}$, as is shown in Proposition~\ref{spectrum of z in closure of polynomials in z}. The proof of Proposition~\ref{Banach algebra generator spactrum isomorphic} shows that the continuous homomorphisms on $\mathfrak{A}$ are of the form $f\mapsto f(\lambda)$ for some $\lambda$ in $S^1$.
\end{example}
\subsection{The group algebra of a locally compact abelian group}
If $G$ is a locally compact abelian group and $\mu$ is Haar measure on $G$, then $L^1(G)=L^1(\mu)$ is a Banach algebra under convolution. Because $G$ is abelian, $L^1(G)$ is abelian. Let $e$ denote the identity of $G$. If $G$ is discrete, then $\delta_e\in L^1(G)$ and $\delta_e$ is an identity for $L^1(G)$. If $G$ is not discrete, then $L^1(G)$ does not have an identity.\par
Some examples of nondiscrete locally compact abelian groups are $\R^n$ and $\T^n$. Note that $\T^\infty$ is also a compact abelian group while $\R^\infty$ fails to be locally compact. The Cantor set can be identified with the product of a countable number of copies of $\Z/2\Z$ and is thus a compact abelian group. Indeed, the product of a countable number of finite sets (with the discrete topology) is homeomorphic to the Cantor set, so that the Cantor set has infinitely many nonisomorphic group structures.\par
The aim of this part is to discuss the homomorphisms on $L^1(G)$ when $G$ is abelian and to examine the Gelfand transform. There is a bit of a difficulty here since $L^1(G)$ does not have an identity when $G$ is not discrete. Nevertheless $\delta_e\notin L^1(G)$ if $G$ is not discrete. All is not lost as $L^1(G)$ has an approximate identity of a nice type.
\begin{proposition}\label{LCH group algebra approximate identity nbhd}
If $f\in L^1(G)$ and $\eps>0$, then there is a neighborhood $U$ of $e$ such that if $g$ is a non-negative Borel function on $G$ that vanishes off $U$ and has $\int g\,d\mu=1$, then $\|f-f\ast g\|_1<\eps$.
\end{proposition}
\begin{proof}
By Proposition~\ref{LCH group int with parameter is continuous}, there is a symmetric neighborhood $U$ of $e$ such that $\|f-R_yf\|<\eps$ whenever $y\in U$. If $g$ satisfies the conditions, then since $G$ is abelian,
\begin{align*}
\|f-f\ast g\|_1&=\int_G\Big|\int_U[f(x)-f(xy^{-1})]g(y)dy\Big|\,dx\leq\int_U|g(y)|\int_G|f(x)-f(xy^{-1})|dx\Big|\,dy\\
&=\int_U|g(y)|\|f-R_{y^{-1}}f\|\,dy\leq\eps.
\end{align*}
This proves the claim.
\end{proof}
\begin{corollary}\label{LCH group algebra approximate identity exist}
There is a net $\{e_\alpha\}$ of non-negative functions in $L^1(G)$ such that $\int e_\alpha\,d\mu=1$ for all $\alpha$ and $\|e_\alpha\ast f-f\|_1\to 0$ for all $f\in L^1(G)$.
\end{corollary}
\begin{proof}
Let $\mathfrak{U}$ be the collection of all neighborhoods of $e$ and order $\mathfrak{U}$ by reverse inclusion. Let $\mathfrak{U}=\{U_\alpha\}$ where $\alpha\preceq\beta$ if and only if $U_\alpha\sups U_\beta$. For each $\alpha$ put $e_\alpha=\mu(U_\alpha)^{-1}\chi_{e_\alpha}$, so $e_\alpha\geq 0$ and $\int e_\alpha\,d\mu=1$. If $f\in L^1(G)$ and $\eps>0$, let $U_\beta$ be as in the preceding proposition. So if $\alpha\succeq\beta$, $e_\alpha$ satisfies the conditions on $g$ in Proposition~\ref{LCH group algebra approximate identity nbhd} and hence $\|f-f\ast e_\alpha\|<\eps$.
\end{proof}
\begin{corollary}\label{LCH group algebra homomorphism to C}
If $\phi:L^1(G)\to\C$ is a nonzero homomorphism, then $\phi$ is bounded and $\|\phi\|=1$.
\end{corollary}
\begin{proof}
Since maximal ideals are closed, $\phi$ is continous, hence bounded. By Proposition~\ref{norm algebra adjoining identity}, we can extend $\varphi$ to $\varphi_1:L^1(G)\times\C\to\C$ and show that $\|\phi\|\leq 1$, by Proposition~\ref{Banach algebran abelian homomorphism to C}. If $\phi(f)\neq 0$ then $\phi(f)=\lim_\alpha\phi(f\ast e_\alpha)=\phi(f)\phi(e_\alpha)$, hence $\lim_\alpha\phi(e_\alpha)=1$. Since $\|e_\alpha\|=1$ for all $\alpha$, $\|\phi\|=1$.
\end{proof}
\section{\boldmath$C^*$-algebras}
\subsection{Basic properties}
By an \textbf{involution} on a complex Banach algebra $\mathfrak{A}$, we mean a mapping $A\mapsto A^*$, from $\mathfrak{A}$ into $\mathfrak{A}$, such that
\begin{itemize}
\item[(\rmnum{1})] $(\alpha A+\beta B)^*=\bar{\alpha}A^*+\bar{\beta}B^*$,
\item[(\rmnum{2})] $(AB)^*=B^*A^*$,
\item[(\rmnum{3})] $A^{**}=A$,
\end{itemize}
where $A,B\in\mathfrak{A}$ and $\alpha,\beta\in\C$. Note that if $\mathfrak{A}$ has involution and an identity, then $I^*A=(A^*I)^*=A^{**}=A$; similarly, $AI^*=A$. Since the identity is unique, $I^*=I$.\par
A \textbf{$C^*$-algebra} is a complex Banach algebra with an involution that satisfies the additional condition that
\begin{itemize}
\item[(\rmnum{4})] $\|A^*A\|=\|A\|^2$ for all $A\in\mathfrak{A}$
\end{itemize}

If $\mathfrak{A}$ and $\mathfrak{B}$ are Banach algebras with involutions, a mapping $\varphi:\mathfrak{A}\to\mathfrak{B}$ is called a \textbf{$*$-homomorphism} if it is a homomorphism (that is, it is linear, multiplicative, and carries the unit of $\mathfrak{A}$ onto that of $\mathfrak{B}$) with the additional property that $\varphi(A^*)=\varphi(A)^*$ for each $A\in\mathfrak{A}$. If, further, $\varphi$ is bijective, then it is called a \textbf{$*$-isomorphism}. Although we impose no continuity condition in these definitions, we shall see later that $*$-homomorphisms do not increase norm and $*$-isomorphisms are norm preserving, when $\mathfrak{A}$ and $\mathfrak{B}$ are $C^*$-algebras.\par
If $\mathfrak{A}$ is a Banach algebra with involution, a subset $\mathscr{F}$ of $\mathfrak{A}$ is said to be \textbf{self-adjoint} if it contains the adjoint of each of its members. A self-adjoint subalgebra of $\mathfrak{A}$ is called a \textbf{$*$-subalgebra}. If the involution is continuous (in particular, if $\mathfrak{A}$ is a $C^*$-algebra), the closure of a $*$-subalgebra is again a $*$-subalgebra. It is clear that a closed $*$-subalgebra $\mathscr{M}$ of $\mathfrak{A}$ that contains the unit of $\mathfrak{A}$ is itself a Banach algebra with involution; if, further, $\mathfrak{A}$ is a $C^*$-algebra, then so is $\mathscr{M}$. In this last case, we say $\mathscr{M}$ is a $C^*$-subalgebra of $\mathfrak{A}$.
\begin{example}
If $H$ is a Hilbert space, $\mathfrak{A}=\mathcal{B}(H)$ is a $C^*$-algebra where for each $A\in\mathcal{B}(H)$, $A^*$ is the adjoint of $A$ (see Proposition~\ref{Hilbert space norm of adjoint}).
\end{example}
\begin{example}
If $H$ is a Hilbert space, $\mathcal{K}(H)$ is a $C^*$-subalgebra of $\mathcal{B}(H)$, though $\mathcal{K}(H)$ does not have an identity if $H$ is infinite dimensional.
\end{example}
\begin{example}
If $X$ is a compact Hausdorff space then $C(X)$ is a $C^*$-algebra where $f^*(x):=\widebar{f(x)}$ for $f$ in $C(X)$ and $x$ in $X$. If $X$ is only assumed to be locally compact, then $C_0(X)$ is a $C^*$-algebra with the same involution.
\end{example}
\begin{proposition}\label{C^* algebra norm of adjoint}
If $\mathfrak{A}$ is a $C^*$-algebra and $A\in\mathfrak{A}$, then $\|A^*\|=\|A\|$ and $\|A^*A\|=\|AA^*\|$.
\end{proposition}
\begin{proof}
From condition (\rmnum{4}) we get
\[\|A\|^2\leq\|A^*A\|\leq\|A^*\|\|A\|\]
whence $\|A\|\leq\|A^*\|$, and we obtain the reverse inequality upon replacing $A$ by $A^*$. Now by replacing $A$ with $A^*$ in (\rmnum{4}), we get
\[\|AA^*\|=\|A^{**}A^*\|=\|A^*\|^2=\|A\|^2.\]
Thus the claim follows.
\end{proof}
For a Banach algebra $\mathfrak{A}$ with identity, we have shown that $\|A\|=\|L_A\|=\|R_A\|$, so $\mathfrak{A}$ is isometrically isomorphic to a subalgebra of $\mathcal{B}(\mathfrak{A})$. For $C^*$-algebras, this result is also true, even without an identity element.
\begin{proposition}\label{C^* algebra norm is multiplication}
If $A\in\mathfrak{A}$ is a $C^*$-algebra and $A\in\mathfrak{A}$, then
\[\|A\|=\sup\{\|AB\|:B\in\mathfrak{A},\|B\|=1\}=\sup\{\|BA\|:B\in\mathfrak{A},\|B\|=1\}.\]
\end{proposition}
\begin{proof}
Since $\mathfrak{A}$ is a Banach algebra, we have $\|L_A\|\leq\|A\|$ and $\|R_A\|\leq\|A\|$. Let $B=A^*/\|A\|$, then since $\|A^*\|=\|A\|$ and $\|A^*A\|=\|A\|^2$, we have $\|B\|=1$ and $\|L_A(B)\|=\|A\|$, so the first equality follows. The proof of the other equality is similar.
\end{proof}
If $L:\mathfrak{A}\to\mathcal{B}(\mathfrak{A})$ is defined by $L(A)=L_A$, then $L$ is a homomorphism and an isometry. The map $L$ is called the \textbf{left regular representation} of $\mathfrak{A}$.\par
The left regular representation can be used to discuss the process of
adjoining an identity to $\mathfrak{A}$. Since $\mathfrak{A}$ is isomorphic to a subalgebra $\mathcal{B}(\mathfrak{A})$ and $\mathcal{B}(\mathfrak{A})$ has an identity, why not just look at the subalgebra of $\mathcal{B}(\mathfrak{A})$ generated by $L(\mathfrak{A})$ and the identity operator? Why not, indeed. This is just what is done below.
\begin{proposition}\label{C^* algebra adjoining identity}
If $\mathfrak{A}$ is a $C^*$-algebra, then there is a $C^*$-algebra $\mathfrak{A}_1$ with an identity such that $\mathfrak{A}_1$ contains $\mathfrak{A}$ as an ideal. If $\mathfrak{A}$ does not have an identity, then $\mathfrak{A}_1/\mathfrak{A}$ is one dimensional. If $\mathfrak{B}$ is a $C^*$-algebra with identity, and $\varphi:\mathfrak{A}\to\mathfrak{B}$ is a $^*$-homomorphism, then the map $\varphi_1:\mathfrak{A}_1\to\mathfrak{B}$ defined by $\varphi_1(A+\alpha I)=\varphi(A)+\alpha I$ for $A\in\mathfrak{A}$ and $\alpha\in\C$ is a $*$-homomorphism, with $\|\varphi\|\leq\|\varphi_1\|$.
\end{proposition}
\begin{proof}
It may be assumed that $\mathfrak{A}$ does not have an identity. Let $\mathfrak{A}_1=\mathfrak{A}\oplus\C=\{A+\alpha I:A\in\mathfrak{A},\alpha\in\C\}$. Define multiplication and addition in the obvious way. Let $(A+\alpha I)^*:=A^*+\bar{\alpha}I$ and define the norm on $\mathfrak{A}$ by
\[\|A+\alpha I\|:=\sup\{\|AB+\alpha B\|:B\in\mathfrak{A},\|B\|\leq 1\}=\|L_A+\alpha I\|_{\mathcal{B}(\mathfrak{A})}.\]
It is clear that $\mathfrak{A}_1$ becomes a Banach algebra with this norm and $\mathfrak{A}$ is isometrically isometric to $\mathfrak{A}+\{0\}$ in $\mathfrak{A}_1$, in view of Proposition~\ref{C^* algebra norm of adjoint}. Now we establish condition (\rmnum{4}) for $\mathfrak{A}_1$.\par
Fix $A\in\mathfrak{A}$ and $\alpha\in\C$. If $\eps>0$, then there is a $B\in\mathfrak{A}$ such that $\|B\|=1$ and
\begin{align*}
\|A+\alpha I\|^2-\eps&<\|AB+\alpha B\|^2=\|(B^*A^*+\bar{\alpha}B^*)(AB+\alpha B)\|\\
&=\|B^*(A^*+\bar{\alpha}I)(A+\alpha I)B\|\leq\|(A^*+\bar{\alpha}I)(A+\alpha I)\|.
\end{align*}
For the other inequality, note that $\|(A+\alpha I)^*(A+\alpha I)\|\leq\|(A+\alpha I)^*\|\|A+\alpha I\|$. So the proof will be complete if it can be shown that $\|(A+\alpha I)^*\|\leq\|A+\alpha I\|$. Now if $B\in\mathfrak{A}$, then
\[\|(A+\alpha I)^*B\|=\|A^*B+\bar{\alpha}B\|=\|B^*A+\alpha B^*\|=\|B^*(A+\alpha I)\|\leq\|B\|\|A+\alpha I\|.\]
Taking supremum over all such $B$ gives the desired inequality.\par
It remains to prove the statement concerning the $*$-homomorphism $\varphi_1$, that $\varphi_1(A^*)=\varphi(A)^*$. This follows since
\[\varphi_1((A+\alpha I)^*)=\varphi(A^*)+\bar{\alpha}I=\varphi(A^*)+\bar{\alpha}I=\varphi(A)^*+\bar{\alpha}I=(\varphi(A)+\alpha)^*.\]
Thus the proof is completed.
\end{proof}
If $\mathfrak{A}$ is a $C^*$-algebra with identity and $A\in\mathfrak{A}$, then $\sigma(A)$, the spectrum of $A$, is well defined. If $\mathfrak{A}$ does not have an identity, $\sigma(A)$ is defined as the spectrum of $A$ as an element of the $C^*$-algebra $\mathfrak{A}_1$ obtained in Proposition~\ref{C^* algebra adjoining identity}. Without further remarks, we may always assume that our $C^*$-algebra $\mathfrak{A}$ has an identity.\par
We now introduce some terminology concerning elements of a Banach algebra $\mathfrak{A}$ with involution, and note certain immediate consequences of the conditions above. Motivated by the example of the algebra $\mathcal{B}(H)$, we call $A^*$ the adjoint of $A$, and $A$ is \textbf{self-adjoint} if $A=A^*$, \textbf{normal} if $A$ commutes with $A^*$, and \textbf{unitary} if $A^*A=AA^*=I$. The set of all self-adjoint elements of $\mathfrak{A}$ is a real vector space, while the unitary elements form a multiplicative group, the \textbf{unitary group} of $\mathfrak{A}$. Each $A\in\mathfrak{A}$ can be expressed (uniquely) in the form $H+iK$, where 
\[H=\frac{A+A^*}{2},\quad K=\frac{A-A^*}{2i}\]
are self-adjoint elements of $\mathfrak{A}$, called the \textbf{real} and \textbf{imaginary parts} of $A$; moreover, $A$ is normal if and only if $H$ commutes with $K$. From (\rmnum{2}), $A$ is invertible if and only if $A^*$ is invertible, and then $(A^{-1})^*=(A^*)^{-1}$. By applying this result, with $A-\lambda I$ and its adjoint $A^*-\bar{\lambda}I$ in place of $A$ and $A^*$, it follows that the spectra of $A$ and $A^*$ satisfy $\sigma(A^*)=\sigma(A)^*$. Accordingly, these elements have the same spectral radius, $r(A^*)=r(A)$.
\begin{proposition}\label{C^* algebra spectrum prop}
Suppose that $A$ is an element of a $C^*$-algebra $\mathfrak{A}$.
\begin{itemize}
\item[(a)] If $A$ is normal then $r(A)=\|A\|$.
\item[(b)] If $A$ is self-adjoint then $\sigma(A)$ is a compact subset of the real line $\R$, and contains at least one of the two real numbers $\pm\|A\|$.
\item[(c)] If $A$ is unitary then $\|A\|=1$ and $\sigma(A)$ is a compact subset of the unit circle $S^1$.
\end{itemize}
\end{proposition}
\begin{proof}
First assume that $A$ is self-adjoint. Then since $A^*=A$, we have
\[\|A^{2n}\|=\|(A^*)^nA^n\|=\|(A^n)^*A^n\|=\|A^n\|^2\]
By induction we see $\|A^n\|=\|A\|^n$ when $n$ is a power of $2$. Therefore the spectral radius formula implies $r(A)=\|A\|$.\par
Now let $A$ be normal and $H$ the self-adjoint element $A^*A$. It follows from the preceding argument, together with Proposition~\ref{Banach algebra spectrum prop} and the $C^*$ property of the norm, that
\[\|A\|^2=\|A^*A\|=r(A^*A)\leq r(A^*)r(A)=r(A)^2\leq\|A\|^2\]
so $r(A)=\|A\|$.\par
With $A$ self-adjoint in $\mathfrak{A}$, $\sigma(A)$ is compact and so contains a scalar with absolute value $r(A)$; and $r(A)=\|A\|$, from part (a) of the present proposition. Consequently, if suffices to prove that $\sigma(A)\sub\R$. For this, suppose that $\lambda\in\sigma(A)$, where $\lambda=a+ib$. For each $n\in\N$, define $B_n=A-aI+inbI$, and observe that $i(n+1)b\in\sigma(B_n)$, so 
\begin{align*}
(n+1)^2b^2&=|i(n+1)b|^2\leq r(B_n)^2\leq\|B_n\|^2=\|B_n^*B_n\|\\
&=\|(A-aI)^2+n^2b^2I\|\leq\|A-aI\|^2+n^2b^2.
\end{align*}
Thus $(2n+1)b^2\leq\|A-aI\|^2$ for all $n$, which implies $\|A-aI\|=+\infty$ unless $b=0$. Thus $\lambda\in\R$.\par
Now assume that $A$ is unitary. Then from $A^*A=I$ we have $\|A\|^2=\|I\|=1$, so $\|A\|=1$. Also, if $\lambda\in\sigma(A)$ then $\lambda^{-1}\in\sigma(A^{-1})=\sigma(A^*)=\sigma(A)$, hence $|\lambda|\leq 1$ and $|\lambda^{-1}|\leq 1$, which implies $|\lambda|=1$.\par
Let $\varphi:\mathfrak{A}\to\mathfrak{B}$ be a $*$-homomorphism between $C^*$-algebra. If $\mathfrak{A}$ has an identity, it is not assumed that $\varphi(I)$ is the identity of $\mathfrak{B}$. However, it is easy to see that $\varphi(I)$ is the identity for $\widebar{\varphi(\mathfrak{A})}$. If $\mathfrak{A}$ does not have an identity, then $\varphi$ can be extended to a $*$-homomorphism $\varphi_1:\mathfrak{A}_1\to\mathfrak{B}$ with $\|\varphi\|\leq\|\varphi_1\|$ such that $\varphi_1(I)=I$. Thus it suffices to prove the proposition under the additional assumption that $\mathfrak{A}$ and $\mathfrak{B}$ have identities and $\varphi(I)=I$.
\end{proof}
\begin{corollary}\label{C^* algebra normal nilpotent is zero}
If $A$ is a normal element of a $C^*$-algebra $\mathfrak{A}$, and is nilpotent. Then $A=0$.
\end{corollary}
\begin{proof}
Since $A^n=0$ for some $n$, we have $r(A)=0$, so $\|A\|=0$ and $A=0$.
\end{proof}
By the fact that self-adjoint elements have real spectrum, we can prove that the spectrum of elements in a $C^*$-algebra does not depend on the algebra itself.
\begin{proposition}\label{C^* algebra spectrum in subalgebra}
Let $\mathfrak{A}$ and $\mathfrak{B}$ be $C^*$-algebras with a common identity and norm such that $\mathfrak{B}\sub\mathfrak{A}$. Then for $A\in\mathfrak{A}$, we have $\sigma_{\mathfrak{A}}(A)=\sigma_{\mathfrak{B}}(A)$.
\end{proposition}
\begin{proof}
First assume that $A$ is hermitian and let $\mathscr{C}$ be the $C^*$-algebra generated by $A$ and $I$. By Proposition~\ref{C^* algebra spectrum prop}, $\sigma_{\mathscr{C}}(A)\sub\R$, so by Corollary~\ref{Banach algebra spectrum subalgebra boundary point} we have $\sigma_{\mathfrak{A}}(A)=\sigma_{\mathscr{C}}(A)=\sigma_{\mathfrak{B}}(A)$, so the claim follows in this case.\par
Now let $A$ be arbitrary. It suffices to show that if $A$ is invertible in $\mathfrak{B}$, then $A$ is invertible in $\mathfrak{A}$. So suppose there is a $B\in\mathfrak{B}$ such that $AB=BA=I$. Thus, $(A^*A)(BB^*)=(BB^*)(A^*A)=I$. Since $A^*A$ is hermitian, the first part of the proof implies $A^*A$ is invertible in $\mathfrak{A}$. But inverses are unique, so $BB^*=(A^*A)^{-1}\in\mathfrak{A}$. Hence $B=B(B^*A^*)=(BB^*)A\in\mathfrak{A}$.
\end{proof}
\begin{proposition}\label{C^* algebra homomorphism to C prop}
If $\mathfrak{A}$ is a $C^*$-algebra and $\phi:\mathfrak{A}\to\C$ is a non-zero homomorphism, then:
\begin{itemize}
\item[(a)] $\phi(A)\in\R$ when $A$ is self-adjoint;
\item[(b)] $\phi(A^*)=\widebar{\phi(A)}$ for all $A\in\mathfrak{A}$;
\item[(c)] $\phi(A^*A)\geq 0$ for all $A\in\mathfrak{A}$;
\item[(d)] if $A$ is unitary, then $|\phi(A)|=1$.
\end{itemize}
\end{proposition}
\begin{proof}
If $\mathfrak{A}$ has no identity, extend $\phi$ to $\mathfrak{A}_1$ by letting $\phi(I)=1$. Thus, we may assume that $\mathfrak{A}$ has an identity. By Proposition~\ref{Banach algebran abelian homomorphism to C}, $\|\phi\|=1$. If $A=A^*$ and $t\in\R$,
\[|\phi(A+itI)|^2\leq\|A+itI\|^2=\|(A+itI)^*(A+itI)\|=\|A^2+i^2I\|\leq\|A\|^2+t^2.\]
If $\phi(A)=a+ib$, then this yields
\[\|A\|^2+t^2\geq|a+i(b+t)|^2=a^2+(b+t)^2.\]
hence $\|A\|^2\geq a^2+b^2+2bt$ for all $t\in\R$. If $b\neq 0$, then letting $t\to+\infty$ or $-\infty$ then gives a contradiction. Thus $\phi(A)\in\R$.\par
For $A\in\mathfrak{A}$, let $A=H+iK$, where $H$ and $K$ are self-adjoint. Since $\phi(H),\phi(K)\in\R$ by (a) and $A^*=H-iK$, (b) follows. Also,
\[\phi(A^*A)=\phi(H+iK)\phi(H-iK)=|\phi(H+iK)|^2\geq 0,\]
so (c) holds. Finally, if $A$ is unitary, then $\widebar{\phi(A)}=\phi(A^*)=\phi(A^{-1})=\phi(A)^{-1}$. Thus $|\phi(A)|=1$.
\end{proof}
\subsection{The continuous functional calculus}
\begin{theorem}\label{C^* algebra Gelfand transform prop}
If $\mathfrak{A}$ is an abelian $C^*$-algebra and $\mathfrak{A}$ is its maximal ideal space, then the Gelfand transform $\Gamma:\mathfrak{A}\to C(\mathfrak{M})$ is an isometric $*$-isomorphism.
\end{theorem}
\begin{proof}
By Proposition~\ref{Banach algebra Gelfand transform prop}, $\|\Gamma\|=1$, so $\|\hat{A}\|\leq\|A\|$ for all $A\in\mathfrak{A}$. But $\|\hat{A}\|_\infty$ is the spectral radius of $A$, so by Proposition~\ref{Banach algebra complex spectrum nonempty}, $\|\hat{A}\|=\|A\|$ for every hermitian element $A\in\mathfrak{A}$. In particular, $\|A^*A\|=\|\hat{A^*A}\|$ for every $A$ in $\mathfrak{A}$.\par
If $A\in\mathfrak{A}$ and $\phi\in\mathfrak{M}$, then
\[\hat{A^*}(\phi)=\phi(A^*)=\widebar{\phi(A)}=\hat{A}(\phi)^*.\]
Thus $\Gamma$ is a $*$-homomorphism.\par
Because $\Gamma$ is an isometry, it has closed range. To show that $\Gamma$ is surjective, therefore, it suffices to show that it has dense range. This is accomplished by applying the Stone-Weierstrass Theorem. Note that $\hat{I}=1$, so $\Gamma(\mathfrak{A})$ is a subalgebra of $C(\mathfrak{M})$ containing the constants. Because $\Gamma$ preserves the involution, $\Gamma(\mathfrak{A})$ is closed under complex conjugation. It remains to show that $\Gamma(\mathfrak{A})$ separates the points of $\mathfrak{M}$. But if $\phi_1$ and $\phi_2$ are distinct homomorphisms in $\mathfrak{M}$, they are distinct because there is an $A\in\mathfrak{A}$ such that $\phi_1(A)\neq\phi_2(A)$. Thus $\hat{A}(\phi_1)\neq\hat{A}(\phi_2)$. This proves the claim.
\end{proof}
\begin{corollary}
If $\mathfrak{A}$ is an abelian $C^*$-algebra without identity and $\mathfrak{M}$ is its maximal ideal space, then the Gelfand transform $\Gamma:\mathfrak{A}\to C_0(\mathfrak{M})$ is an isometric $*$-isomorphism of $\mathfrak{A}$ onto $C_0(\mathfrak{M})$.
\end{corollary}
Let $\mathfrak{A}$ be an arbitrary $C^*$-algebra and let $A$ be a normal element of $\mathfrak{A}$. So if $\mathfrak{B}=C^*(A)$, the $C^*$-algebra generated by $A$ and $I$, $\mathfrak{B}$ is abelian. Hence $\mathfrak{B}\cong C(\mathfrak{M})$, where $\mathfrak{M}$ is the maximal ideal space of $\mathfrak{B}$. So by Theorem~\ref{C^* algebra Gelfand transform prop} if $f\in C(\mathfrak{M})$, there is a unique element $B$ of $\mathfrak{B}$ such that $\hat{B}=f$. We want to think of $B$ as $f(A)$ and thus define a functional calculus for normal elements of a $C^*$-algebra. To be useful, however, we should have a ready way of identifying $\mathfrak{M}$. Moreover, since $\mathfrak{B}=C^*(A)$ and thus depends on $A$, it should be that $\mathfrak{M}$ depends on $A$ in a clear way. The idea embodied in Proposition~\ref{Banach algebra generator spactrum isomorphic} that $\mathfrak{M}$ and $\sigma(A)$ are homeomorphic via a natural map is the key here, although it is not directly applicable here since $A$ is not a generator of $C^*(A)$ as a Banach algebra but only as a $C^*$-algebra. (If $A=A^*$, then $A$ is a generator of $C^*(A)$ as a Banach algebra.) Nevertheless the result is true.
\begin{proposition}\label{C^* algebra generator spectrum isomorphic}
If $\mathfrak{A}$ is an abelian $C^*$-algebra and maximal ideal space $\mathfrak{M}$ and $A\in\mathfrak{A}$ such that $\mathfrak{A}=C^*(A)$, then the map $\tau:\mathfrak{M}\to\sigma(A)$ defined by $\tau(\phi)=\phi(A)$ is a homeomorphism. If $p(z,\bar{z})$ is a polynomial in $z$ and $\bar{z}$ and $\Gamma:\mathfrak{A}\to C(\mathfrak{M})$ is the Gelfand transform, then $\Gamma(p(A,A^*))=\tau^*(p)$.
\end{proposition}
\begin{proof}
We know that $\tau$ is continuous and surjective. By Proposition~\ref{C^* algebra homomorphism to C prop} every element in $\mathfrak{M}$ is a $*$-homomorphism, so it follows like Proposition~\ref{Banach algebra generator spactrum isomorphic} that $\tau$ is injective. The late equality can be proved similarly, using the fact that $A^*$ commutes with $A$.
\end{proof}
If $\tau:\mathfrak{M}\to\sigma(A)$ is defined as in the preceding proposition, then $\tau^*:C(\sigma(A))\to C(\mathfrak{M})$ is defined by $\tau^*(f)=f\circ \tau$. Note that $\tau^*$ is a $*$-isomorphism and an isometry, because $\tau$ is a homeomorphism. Note that $C^*(A)$ is the closure of $\{p(A,A^*):p(z,\bar{z})\text{ is a polynomial}\}$. Now such a polynomial $p(z,\bar{z})$ is, of course, a function on $\sigma(A)$. We define a map $\rho:C(\sigma(A))\to C^*(A)$ so that the following diagram commutes:
\begin{equation}\label{C^* algebra continuous function calculus def}
\begin{tikzcd}
C^*(A)\ar[rr,"\Gamma","\cong"']&&C(\mathfrak{M})\\
&C(\sigma(A))\ar[ru,"\tau^*","\cong"']\ar[lu,swap,"\rho"]&
\end{tikzcd}
\end{equation}
Note that if $\mathfrak{A}$ is any $C^*$-algebra and $A$ is a normal element of $\mathfrak{A}$, then $\mathfrak{B}=C^*(A)$ is an abelian $C^*$-algebra contained in $\mathfrak{A}$ and so $(\ref{C^* algebra continuous function calculus def})$ applies. Moreover, in light of Proposition~\ref{C^* algebra spectrum in subalgebra}, the spectrum of $A$ does not depend on whether $A$ is considered as an element of $\mathfrak{B}$ or $\mathfrak{A}$. The following definition is, therefore, unambiguous.
\begin{definition}
If $\mathfrak{A}$ is a $C^*$-algebra and $A\in\mathfrak{A}$ is normal, let $\rho:C(\sigma(A))\to C^*(A)$ be as in $(\ref{C^* algebra continuous function calculus def})$. If $f\in C(\sigma(A))$, define $f(A):=\rho(f)$. The map $f\mapsto f(A)$ is called the \textbf{(continuous) functional calculus} for $A$.
\end{definition}
Note that if $p(z,\bar{z})$ is a polynomial in $z$ and $\bar{z}$, then $\rho(p)=p(A,A^*)$. In particular, $\rho(z^m\bar{z}^n)=A^m(A^*)^n$ so that $\rho(z)=A$, $\rho(\bar{z})=A^*$ and $\rho(1)=I$.\par
The properties of this functional calculus can be obtained from the fact that $\rho$ is an isometric $*$-isomorphism of $C(\sigma(A))$ into $\mathfrak{A}$---with one exception. How does this functional calculus compare with the Riesz functional calculus? If $f\in\mathcal{H}(A)$ then $f|_{\sigma(A)}\in C(\sigma(A))$; so $f(A)$ has two possible interpretations. Or does it?
\begin{proposition}\label{C^* algebra continuous function calculus prop}
If $\mathfrak{A}$ is a $C^*$-algebra and $A$ is a normal element of $\mathfrak{A}$, then the functional calculus has the following properties.
\begin{itemize}
\item[(a)] $f\mapsto f(A)$ is a $*$-isomorphism.
\item[(b)] $\|f(A)\|=\|f\|_\infty$.
\item[(c)] $f\mapsto f(A)$ is an extension of the Riesz functional calculus
\end{itemize}
Moreover, the functional calculus is unique in the sense that if $\tau:C(\sigma(A))\to C^*(A)$ is a $*$-homomorphism that extends the Riesz functional calculus, then $\tau(f)=f(A)$ for every $f\in C(\sigma(A))$.
\end{proposition}
\begin{proof}
Let $\rho:C(\sigma(A))\to C^*(A)$ be the map defined by $\rho(f)=f(A)$. From $(\ref{C^* algebra continuous function calculus def})$, (a) and (b) are immediate.\par
Let $\pi:\mathcal{H}(A)\to\mathfrak{A}$ denote the map defined by the Riesz functional calculus. Since $\rho(z)=\pi(z)=A$, an algebraic manipulation gives that $\rho(f)=\pi(f)$ for every rational function $f$ with poles off $\sigma(A)$. If $f\in\mathcal{H}(A)$, then by Runge's Theorem there is a sequence $\{f_n\}$ of such rational functions such that $f_n(z)\to f(z)$ uniformly in a neighborhood of $\sigma(A)$. Thus $\pi(f_n)\to\pi(f)$. By (b), $\rho(f_n)\to\rho(f)$. Thus $\rho(f)=\pi(f)$.\par
To prove uniqueness, let $\tau:C(\sigma(A))\to\mathfrak{A}$ be a $*$-homomorphism that extends the Riesz functional calculus. If $f\in C(\sigma(A))$, then there is a sequence $\{p_n\}$ of polynomials in $z$ and $\bar{z}$ such that $p_n(z,\bar{z})\to f(z)$ uniformly on $\sigma(A)$. But $\tau(p_n)=p_n(A,A^*)$ and $p_n(A,A^*)\to f(A)$. Hence $\tau(f)=f(A)$.
\end{proof}
Because of the uniqueness statement in the preceding theorem, it is not necessary to remember the form of the functional calculus $f\mapsto f(A)$, but only the fact that it is an isometric $*$-monomorphism that extends the Riesz functional calculus. Indeed, by the uniqueness of the Riesz functional calculus, it suffices to have that $f\mapsto f(A)$ is an isometric $*$-monomorphism such that if $f(z)=1$, then $f(A)=1$, and if $f(z)=z$, then $f(A)=A$. Any properties or applications of the functional calculus can be derived or justified using only these properties. There may, however, be an occasion when the precise form of the functional calculus facilitates a proof. There are also situations in which the definition of the functional calculus gets in the way of a proof and the properties in Proposition~\ref{C^* algebra continuous function calculus prop} give the clean way of applying this powerful tool.
\begin{proposition}[\textbf{Spectral Mapping Theorem}]
If $\mathfrak{A}$ is a $C^*$-algebra and $A$ is a normal element of $\mathfrak{A}$, then for every $f\in C(\sigma(A))$, $\sigma(f(A))=f(\sigma(A))$.
\end{proposition}
\begin{proof}
Let $\rho:C(\sigma(A))\to\mathfrak{A}$ be defined by $\rho(f)=f(A)$. So $\rho$ is a $*$-isomorphism. Hence $\sigma(f(A))=\sigma(\rho(f))=\sigma(f)$. But $\sigma(f)=f(\sigma(A))$, so the claim follows.
\end{proof}
We conclude this part with some further applications of function calculus.
\begin{proposition}\label{C^* algebra unitary generated}
Each element $A$ of a $C^*$-algebra $\mathfrak{A}$ is a finite linear combination of unitary elements of $\mathfrak{A}$.
\end{proposition}
\begin{proof}
It is sufficient to consider the case in which $A$ is self-adjoint and $\|A\|\leq 1$. In these circumstances, $\sigma(A)$ is a subset of the interval $[-1,1]$, and we can define $f\in C(\sigma(A))$ by $f(t)=t+i\sqrt{1-t^2}$. Since
\[t=\frac{f(t)+\widebar{f(t)}}{2},\quad |f(t)|^2\equiv 1\]
for each $t$ in $\sigma(A)$, it follows that the element $U:=f(A)$ of $\mathfrak{A}$ satisfies
\[A=\frac{U+U^*}{2},\quad UU^*=U^*U=I.\]
This proves the claim.
\end{proof}
\begin{proposition}\label{C^* algebra homomorphism prop}
Suppose that $\mathfrak{A}$ and $\mathfrak{B}$ are $C^*$-algebras and $\varphi:\mathfrak{A}\to\mathfrak{B}$ is a $*$-homomorphism.
\begin{itemize}
\item[(a)] For each $A\in\mathfrak{A}$, $\sigma(\varphi(A))\sub\sigma(A)$ and $\|\varphi(A)\|\leq\|A\|$; in particular, $\varphi$ is continuous.
\item[(b)] If $A$ is a normal element of $\mathfrak{A}$ and $f\in C(\sigma(A))$, then $\varphi(f(A))=f(\varphi(A))$.
\item[(c)] $\varphi(\mathfrak{A})$ is a $C^*$-subalgebra of $\mathfrak{B}$.
\item[(d)] If $\varphi$ is a $*$-monomorphism, then $\|\varphi(A)\|=\|A\|$ and $\sigma(\varphi(A))=\sigma(A)$ for each $A\in\mathfrak{A}$.
\end{itemize}
\end{proposition}
\begin{proof}
Let $A\in\mathfrak{A}$. If $\lambda\in\sigma(\varphi(A))$ then $\varphi(A)-\alpha I=\varphi(A-\alpha I)$ is not invertible, hence $A-\alpha I$ can not be invertible. it follows that $\sigma(\varphi(A))\sub\sigma(A)$ and hence $r(\varphi(A))\leq r(A)$. So, using Proposition~\ref{C^* algebra spectrum prop}(a) and the fact that $A^*A$ is self-adjoint, we get
\[\|\varphi(A)\|^2=\|\varphi(A^*A)\|=r(\varphi(A^*A))\leq r(A^*A)=\|A^*A\|=\|A\|^2.\]
This proves (a).\par
Now if $\{p_n\}$ is a sequence of polynomials in $z$ and $\bar{z}$ tending to $f$ uniformly on $\sigma(A)$ (hence, from (a), on $\sigma(\varphi(A))$), then $\varphi(p_n(A,A^*))\to\varphi(f(A))$ and $p_n(\varphi(A),\varphi(A)^*)\to f(\varphi(A))$. Since $\varphi(p_n(A,A^*))=p_n(\varphi(A),\varphi(A)^*)$ for each $n$, (b) follows.\par
Since $\varphi(\mathfrak{A})$ is a $*$-subalgebra of $\mathfrak{B}$ (containing $I$), it suffices to show that $\varphi(\mathfrak{A})$ is closed in $\mathfrak{B}$. Let $B\in\mathfrak{B}$ with $\|B-\varphi(A_n)\|\to 0$ for some $\{A_n\}\sub\mathfrak{A}$. By expressing $B$ and $A_n$'s in terms of their real and imaginary parts, we reduce to the case in which $B$ and the $A_n$'s are self-adjoint. Upon passing to a subsequence of $\{A_n\}$, we may suppose also that
\[\|\varphi(A_{n+1})-\varphi(A_n)\|<2^{-n}.\]
Let $f_n$ be a continuous function on $\R$, with values in the real interval $[-2^{-n},2^{-n}]$, such that $f_n(t)=t$ when $|t|\leq 2^{-n}$. From part (b), and since $f_n$ restricts to the identity mapping on $\sigma(\varphi(A_{n+1})-\varphi(A_n))$,
\[\varphi(A_{n+1})-\varphi(A_n)=f_n(\varphi(A_{n+1})-\varphi(A_n))=\varphi(f_n(A_{n+1}-A_n)).\]
Since $\|f_n\|_\infty\leq 2^{-n}$, we have $\|f_n(A_{n+1}-A_n)\|<2^{-n}$, so the series $A_1+\sum_nf_n(A_{n+1}-A_n)$ converges to an element $A\in\mathfrak{A}$. The continuity of $\varphi$ implies
\begin{align*}
\varphi(A)&=\lim_m\Big[\varphi(A_1)+\sum_{n=1}^{m-1}\varphi(f_n(A_{n+1}-A_n))\Big]\\
&=\lim_m\Big[\varphi(A_1)+\sum_{n=1}^{m-1}\varphi(A_{n+1})-\varphi(A_n)\Big]=\lim_m\varphi(A_m)=B.
\end{align*}
Thus $B\in\varphi(\mathfrak{A})$ and cliam (c) follows.\par
Suppose now that $\varphi$ is a $*$-monomorphism. With $B$ self-adjoint in $\mathfrak{A}$, it follows from (a) that $\sigma(\varphi(B))\sub\sigma(B)$. If strict inclusion occurs, there is a nonzero element $f$ of $C(\sigma(B))$, whose restriction to $\sigma(\varphi(B))$ is identically zero. From part (b) of the theorem, we have $f(B)\neq 0$ but $\varphi(f(B))=f(\varphi(B))=0$. Since $\varphi$ is injective, this is a contradiction. Hence $\sigma(\varphi(B))=\sigma(B)$, and so $r(\varphi(B))=r(B)$ for each self-adjoint $B\in\mathfrak{A}$.\par
Now let $A\in\mathfrak{A}$ and $B=A^*A$. Then it follows from the discussion above and Proposition~\ref{C^* algebra spectrum prop} that
\[\|A\|^2=\|A^*A\|=r(A^*A)=r(\varphi(A^*A))=\|\varphi(A)\|^2\]
so $\|\varphi(A)\|=\|A\|$. Since $\varphi(\mathfrak{A})$ is a $C^*$-subalgebra of $\mathfrak{B}$, by Proposition~\ref{C^* algebra spectrum in subalgebra}, the spectrum of $\varphi(A)$ in $\mathfrak{B}$ is the same as its spectrum in $\varphi(\mathfrak{A})$; and $\sigma(A)=\sigma_{\varphi(\mathfrak{A})}(\varphi(A))$, since $\varphi$ is an isomorphism from $\mathfrak{A}$ onto $\varphi(\mathfrak{A})$.
\end{proof}
\subsection{Ideals and quotients of $C^*$-algebras}
\begin{proposition}\label{C^* algebra closed ideal under function calculus}
If $\mathscr{I}$ is a closed left or right ideal in the $C^*$-algebra $\mathfrak{A}$, $A\in\mathscr{I}$ slef-adjoint, and $f\in C(\sigma(A))$ with $f(0)=0$, then $f(A)\in\mathscr{I}$.
\end{proposition}
\begin{proof}
Note that if $I$ is proper, then $0\in\sigma(A)$ since $A$ cannot be invertible. Since $\sigma(A)\sub\R$, the Weierstrass Theorem implies there is a sequence $\{p_n\}$ of polynomials such that $p_n(t)\to f(t)$ uniformly on $\sigma(A)$. Hence $p_n(0)\to f(0)=0$. Thus $q_n(t)=p_n(t)-p_n(0)\to f(t)$ uniformly on $\sigma(A)$ and $q_n(0)=0$ for all $n$. Thus $q_n(A)\in\mathscr{I}$ and by the functional calculus, $\|q_n(A)-f(A)\|\to 0$. Hence $f(A)\in\mathscr{I}$.
\end{proof}
\begin{corollary}
If $\mathscr{I}$ is a closed left or right ideal, $A\in\mathscr{I}$ is self-adjoint. Then $A^+,A^-$, $|A|$, and $|A|^{1/2}\in I$.
\end{corollary}
Note that if $\mathscr{I}$ is a left ideal of $\mathfrak{A}$, then $\mathscr{I}^*=\{A^*:A\in\mathscr{I}\}$ is a right ideal. Therefore a left ideal $\mathscr{I}$ is an ideal if $A^*\in\mathscr{I}$ whenever $A\in\mathscr{I}$. Note that the converse holds when $\mathscr{I}$ is closed.
\begin{theorem}\label{C^* algebra closed ideal under adjoint}
If $\mathscr{I}$ is a closed ideal in the $C^*$-algebra $\mathscr{I}$, then $A^*\in\mathscr{I}$ whenever $A\in\mathscr{I}$.
\end{theorem}
\begin{proof}
Fix $A$ in $\mathscr{I}$. Thus $A^*A\in\mathscr{I}$ since $\mathscr{I}$ is an ideal. The idea is to construct a sequence $\{u_n\}$ of continuous functions defined on $[0,+\infty)$ such that
\begin{itemize}
\item[(a)] $u_n(0)=0$ and $u_n\geq 0$.
\item[(b)] $\|Au_n(A^*A)-A\|\to 0$.
\end{itemize}
If such a sequence $\{u_n\}$ can be constructed, then $u_n(A^*A)\geq 0$ and $u_n(A^*A)\in\mathscr{I}$ by Proposition~\ref{C^* algebra closed ideal under function calculus}. Also, $u_n(A^*A)A^*\in\mathscr{I}$ since $\mathscr{I}$ is an ideal and $\|u_n(A^*A)A^*-A^*\|\to 0$ by (b). Thus $A^*\in\mathscr{I}$ whenever $A\in\mathscr{I}$. It remains to construct the sequence $\{u_n\}$.\par
Note that
\begin{align*}
\|Au_n(A^*A)-A\|^2&=\|[u_n(A^*A)A^*-A^*][Au_n(A^*A)-A]\|\\
&=\|u_n(A^*A)A^*Au_n(A^*A)-2A^*Au_n(A^*A)+A^*A\|\\
&=\|A^*A[u_n(A^*A)-1]^2\|=\|f_n\|_{\sigma(A^*A)}\leq\|f_n\|_{[0,+\infty)},
\end{align*}
where $f_n(t)=t[u_n(t)-1]^2$. If $u_n(t)=nt$ for $0\leq t\leq 1/n$ and $u(t)=1$ for $t\geq 1/n$, then it is seen that $\|f_n\|_{[0,+\infty)}\to 0$; so the conditions are satisfied.
\end{proof}
Notice that the construction of the sequence $\{u_n\}$ actually proves more.
\begin{proposition}\label{C^* algebra local approximate identity}
If $\mathfrak{A}$ is a $C^*$-algebra and $\mathscr{I}$ is an ideal of $\mathfrak{A}$, then for every $A\in\mathfrak{A}$ there is a sequence $\{I_n\}$ of positive elements in $\mathscr{I}$ such that:
\begin{itemize}
\item[(a)] $\{I_n\}$ is increasing and $\|I_n\|\leq 1$ for all $n$.
\item[(b)] $\|AI_n-A\|\to 0$.
\end{itemize}
\end{proposition}
We now turn now to an important consequence of Theorem~\ref{C^* algebra closed ideal under adjoint}.
\begin{theorem}\label{C^* algebra quotient by closed ideal}
Let $\mathfrak{A}$ be a $C^*$-algebra and $\mathscr{I}$ be a closed ideal of $\mathfrak{A}$. For each $A+\mathscr{I}$ in $\mathfrak{A}/\mathscr{I}$ define $(A+\mathscr{I})^*=A^*+\mathscr{I}$. Then $\mathfrak{A}/\mathscr{I}$ with its quotient norm is a $C^*$-algebra.
\end{theorem}
To prove this, we fisrt need a lemma.
\begin{lemma}
If $\mathscr{I}$ is an ideal in a $C^*$-algebra $\mathfrak{A}$ and $A\in\mathfrak{A}$, then
\[\|A+\mathscr{I}\|=\inf\{\|A-AB\|:B\in\mathscr{I},H\geq 0,\|B\|\leq 1\}.\]
\end{lemma}
\begin{proof}
If $(B_{\mathscr{I}})^+:=B_{\mathscr{I}}\cap\mathfrak{A}^+$ and $\alpha:=\inf\{\|A-AH:H\in(B_{\mathscr{I}})^+\}$, then since $A\mathscr{I}\sub\mathscr{I}$, we have $\|A+\mathscr{I}\|\leq\alpha$. Let $B\in\mathscr{I}$ and let $\{I_n\}$ be a sequence in $(B_{\mathscr{I}})^+$ such that $\|B-BI_n\|\to 0$. Now $0\leq I-I_n\leq I$, so $\|(A+B)(I-I_n)\|\leq\|A+B\|$, hence
\begin{align*}
\|A+B\|&\geq\varliminf_{n\to+\infty}\|(A+B)(I-I_n)\|=\varliminf_{n\to+\infty}\|(A-AI_n)+(B-B)I_n\|\\
&=\varliminf_{n\to+\infty}\|A-AI_n\|\geq\alpha.
\end{align*}
This proves the claim.
\end{proof}
\begin{proof}[Proof of Theorem~\ref{C^* algebra quotient by closed ideal}]
The only difficult part of this proof is to show that $\|A+\mathscr{I}\|^2=\|A^*A+\mathscr{I}\|$ for every $A$ in $\mathfrak{A}$. Since $A^*\in\mathscr{I}$ whenever $A\in\mathscr{I}$, $\|A+\mathscr{I}\|=\|A^*+\mathscr{I}\|$ for all $A$ in $\mathscr{I}$. Thus the submultiplicativity of the norm implies
\[\|A^*A+\mathscr{I}\|=\|(A^*+\mathscr{I})(A+\mathscr{I})\|\leq\|A^*+\mathscr{I}\|\|A+\mathscr{I}\|=\|A+\mathscr{I}\|^2.\]
On the other hand, the preceding lemma gives that
\begin{align*}
\|A+\mathscr{I}\|^2&=\inf\{\|A-AB\|^2:B\in(B_{\mathscr{I}})^+\}=\inf\{\|(I_B)A^*A(I-B)\|:B\in(B_{\mathscr{I}})^+\}\\
&\leq\inf\{\|A^*A(I-B)\|:B\in(B_{\mathscr{I}})^+\}=\|A^*A+\mathscr{I}.
\end{align*}
This proves the theorem.
\end{proof}
We turn now to some specific examples of $C^*$-algebras and their ideals. Our first example will be the $C^*$-algebra $C(X)$, with $X$ compact Hausdorff. For any subset $S\sub X$, we can associate an ideal $I(S)$ of $C(X)$ by
\[I(S)=\{f\in C(X):f(x)=0\text{ for all $x\in S$}\}.\]
Similarly, for an ideal $\mathscr{I}$ in $C(X)$, we can associate a subset $V(\mathscr{I})$ of $X$ by
\[V(\mathscr{I})=\{x\in X:f(x)=0\text{ for all $f\in\mathscr{I}$}\}.\]
It is easy to see $V(\mathscr{I})$ is a closed ideal and $I(S)$ is a closed subset, whatever $S$ and $\mathscr{I}$ are. It turns out that all closed iedals arise in this fashion.
\begin{theorem}\label{closed ideal in C(X)}
Let $X$ be a compact Hausdorff space, $S\sub X$, and $\mathscr{I}$ be an ideal of $C(X)$. Then $V(I(S))=\widebar{S}$ and $I(V(\mathscr{I}))=\widebar{I}$. Therefore, closed ideals in $C(X)$ corresponds to closed subsets in $X$. Moreover, $C(X)/I(S)$ is isometrically isomorphic to $C(S)$.
\end{theorem}
\begin{proof}
If $\mu\in M(X)$ and $\mu\bot\mathscr{I}$, then $\int|f|^2\,d\mu=0$ for each $f\in\mathscr{I}$ since $|f|^2=f\bar{f}\in\mathscr{I}$. Thus each $f$ must vanish on the support of $\mu$; hence $V(\mathscr{I})\sub\supp(\mu)$, or equivalently $|\mu|(X\setminus V(\mathscr{I}))=0$. Conversely, if $\mu\in M(X)$ and $\supp(\mu)\sub V(\mathscr{I})$, it follows that $\inf f\,d\mu=0$ for all $f\in\mathscr{I}$, hence we have proved
\[\mathscr{I}^\bot=\{\mu\in M(X):\supp(\mu)\sub V(\mathscr{I})\}=\{\mu\in M(X):|\mu|(X\setminus V(\mathscr{I}))=0\}.\]
Since we have the Dirac measure $\delta_x$ for each $x\in X$, it is now easy to see
\[\widebar{I}=\mathscr{I}^{\bot\bot}=\{f\in C(X):f(x)=0\text{ for all $x\in V(\mathscr{I})$}\}=I(V(\mathscr{I})).\]
The other claim is easy to prove: it is clear that $\widebar{S}\sub V(I(S))$. Any if $x\notin\widebar{S}$, then there exists a function $f\in I(\widebar{S})$ such that $f(x)=1$, which implies $x\notin V(I(S))$. This proves $V(I(S))=\widebar{S}$. The last claim is easy to verify.
\end{proof}
\begin{proposition}\label{Hilbert space nonzero closed ideal}
Let $H$ be a Hilbert space. If $\mathscr{I}$ is a closed ideal of $\mathcal{B}(H)$, then $\mathscr{I}\supseteq\mathcal{K}(H)$ or $\mathscr{I}=(0)$.
\end{proposition}
\begin{proof}
Suppose $\mathscr{I}\neq(0)$ and let $T$ be a nonzero operator in $\mathscr{I}$. Thus there are vectors $x_0,x_1$ in $H$ such that $Tx_0=x_1\neq 0$. Let $y_0,y_1$ be arbitrary nonzero vectors in $H$. Define $A:H\to H$ and $B:H\to H$ by
\[Ax=\|y_0\|^{-2}\langle x,y_0\rangle x_0,\quad Bx=\|x_1\|^{-2}\langle x,x_1\rangle y_1.\]
Then $Ay_0=x_0$, $Bx_1=y_1$, and $Ax=0$ if $x\bot y_0$. Thus $BTAx=0$ if $x\bot y_0$ and $BTAy_0=y_1$. Hence for any pair of nonzero vectors $y_0,y_1\in H$ the rank-one operator that takes $y_0$ to $y_1$ and is zero on $\{y_0\}^\bot$ belongs to $\mathscr{I}$. From here it easily follows that $\mathscr{I}$ contains all finite-rank operators. Since $\mathscr{I}$ is closed, $\mathscr{I}\supseteq\mathcal{K}(H)$.
\end{proof}
\subsection{Positive elements}
We recall that a bounded linear operator $A$, acting on a Hilbert space $H$, is said to be positive if $\langle Ax,x\rangle\geq 0$ for each $x\in H$.
\begin{proposition}\label{Hilbert space positive operator iff}
If $H$ is a Hilbert space and $A\in\mathcal{B}(H)$, then $A$ is a positive operator iff $A$ is self-adjoint and $\sigma(A)\sub\R^+$. 
\end{proposition}
\begin{proof}
If $A$ is positive, then it is slef-adjoint by Proposition~\ref{Hilbert space Hermitian iff}. Also, if $x\in H$ and $\lambda<0$, then
\[\|(A-\lambda I)x\|^2=\|Ax\|^2-2\lambda\langle Ax,x\rangle+\lambda^2\|x\|^2\geq\lambda^2\|x\|^2\]
thus $\lambda\notin\sigma_{ap}(A)=\sigma_l(A)$. Since $A$ is slef-adjoint, $\sigma_l(A)=\sigma(A)$, so $\lambda\notin\sigma(A)$. Thus $\sigma(A)\sub\R^+$.\par
Conversely, if $A$ is a self-adjoint element of $\mathcal{B}(H)$, and $\sigma(A)$, the equation $f(t)=\sqrt{t}$ defines a real-valued continuous function $f$ on $\sigma(A)$. By means of the function calculus, for $A$ as a member of the $C^*$-algebra $\mathcal{B}(H)$, we obtain a self-adjoint operator $H=f(A)$ such that $H^2=A$. Since
\[\langle Ax,x\rangle=\langle H^2x,x\rangle=\langle Hx,Hx\rangle\geq 0\]
we see $A$ is a positive operator. Accordingly, the positive operators are precisely those that are self-adjoint and have spectrum contained in $\R^+$.
\end{proof}
Motivated by this proposition, we describe an element $A$ of a $C^*$-algebra as \textbf{positive} if $A$ is self-adjoint and $\sigma(A)\sub\R^+$; we denote by $\mathfrak{A}^+$ the set of all positive elements of $\mathfrak{A}$. From the preceding discussion, this definition is consistent with our earlier conventions when $\mathfrak{A}=\mathcal{B}(H)$.
\begin{proposition}\label{C^* algebra positive element prop}
Let $\mathfrak{A}$ be a $C^*$-algebra and $A\in\mathfrak{A}$.
\begin{itemize}
\item[(a)] If $A\in\mathfrak{A}^+$, then $\|A\|\in\sigma(A)$.
\item[(b)] If $\mathfrak{B}$ is a $C^*$-subalgebra of $\mathfrak{A}$, then $\mathfrak{B}^+=\mathfrak{A}^+\cap\mathfrak{B}$.
\item[(c)] If $\varphi$ is a $*$-homomorphism from $\varphi$ into a $C^*$-algebra $\mathfrak{C}$ and $A\in\mathfrak{A}^+$, then $\varphi(A)\in\mathfrak{C}^+$.
\end{itemize}
\end{proposition}
\begin{proof}
From Proposition~\ref{C^* algebra spectrum prop}, $\|A\|\in\sigma(A)$ when $A\in\mathfrak{A}^+$. A self-adjoint element $B$ of $\mathfrak{B}$ is positive relative to $\mathfrak{B}$ if and only if it is positive relative to $\mathfrak{A}$ (that is, ), since it has the same spectrum in $\mathfrak{B}$ as in $\mathfrak{A}$.\par
If $\varphi:\mathfrak{A}\to\mathfrak{C}$ is a $*$-homomorphism and $A\in\mathfrak{A}^+$, then $\varphi(A)$ is self-adjoint and $\sigma(\varphi(A))\sub\sigma(A)$, by Proposition~\ref{C^* algebra homomorphism prop}(a). Thus $\varphi(A)\in\mathfrak{C}^+$.
\end{proof}
\begin{example}
If $\mathfrak{A}=C(X)$, then $f$ is positive in $\mathfrak{A}$ if and only if $f(x)\geq 0$ for all $x$ in $X$. This follows from the fact that $\sigma(f)=f(X)$.
\end{example}
\begin{example}
Let $(X,\mathcal{A},\mu)$ be a measure space and $\mathfrak{A}=L^\infty(\mu)$. For $f\in\mathfrak{A}$, $f\geq 0$ if and only if $f\geq 0$ $\mu$-almost everywhere on $X$.
\end{example}
\begin{proposition}\label{C^* algebra slef-adjoint positive negative}
Suppose that $A$ is a self-adjoint element of a $C^*$-algebra $\mathfrak{A}$ and $f\in C(\sigma(A))$.
\begin{itemize}
\item[(a)] $f(A)\in\mathfrak{A}^+$ iff $f\geq 0$ on $\sigma(A)$.
\item[(b)] $\|A\|I\pm A\in\mathfrak{A}$.
\item[(c)] There are unique positive elements $P,N\in\mathfrak{A}$ such that $A=P-N$ and $PN=NP=0$. Moreover, $\|A\|=\max\{\|P\|,\|N\|\}$.
\end{itemize}
\end{proposition}
\begin{proof}
Part (a) follows from the spectral mapping theorem, and (b) follows from (a). Now we prove (c). Since $A$ is self-adjoint, $\sigma(A)\sub\R$. Let $f(t)=\max\{t,0\}$ and $g(t)=-\min\{t,0\}$. Then $f,g\in C(\R)$ and $f(t)-g(t)=t$. Using the functional calculus, let $P=f(A)$ and $N=g(A)$. So $P$ and $N$ are hermitian and by the spectral mapping theorem $P,N$ are positive. Also,
\[P-N=f(A)-g(A)=A,\quad PN=NP=(fg)(A)=0.\]
To show uniqueness, let $P_1,N_1\in\mathfrak{A}^+$ such that $P_1-N_1=A$ and $P_1N_1=N_1P_1=0$. Let $\{p_n\}$ be a sequence of polynomials such that $p_n(0)=0$ for all $n$ and $p_n(t)\to f(t)$ uniformly on $\sigma(A)$. Hence $p_n(A)\to f(A)$ in $\mathfrak{A}$. But $P_1A=AP_1$, so $P_1p_n(A)=p_n(A)P_1$ for all $n\in\N$, hence $P_1P=PP_1$. Similarly, it follows that $A,P,N,P_1,N_1$ are pairwise commuting slef-adjoint elements of $\mathfrak{A}$. Let $\mathfrak{B}$ be the $C^*$-algebra generated by $A,P,N,P_1,N_1$; so $\mathfrak{B}$ is abelian. Hence $\mathfrak{B}\cong C(\mathfrak{M})$ where $\mathfrak{M}$ is the maximal ideal space of $\mathfrak{B}$. The uniqueness now follows from the corresponding uniqueness statement for $C(\mathfrak{M})$.\par
Finally, since $t,f(t),g(t)$, as elements of $C(\sigma(A))$, satisfy $\|t\|=\max\{\|f\|,\|g\|\}$, it follows that $\|A\|=\max\{\|P\|,\|N\|\}$.
\end{proof}
The decomposition $A=P-N$ of a slef-adjoint element $A$ is sometimes called the \textbf{orthogonal decomposition} of $A$. The elements $P$ and $N$ are called the \textbf{positive and negative parts} of $A$ and are denoted by $P=A^+$ and $N=A^-$. Also, we define $|A|=A^++A^-$.
\begin{corollary}
Each element $A$ of a $C^*$-algebra $\mathfrak{A}$ is a linear combination of at most four members of $\mathfrak{A}^+$.
\end{corollary}
\begin{proposition}\label{C^* algebra root of positive}
If $A\in\mathfrak{A}^+$ and $n\geq 1$, there is a unique element $B\in\mathfrak{A}^+$ such that $A=B^n$.
\end{proposition}
\begin{proof}
Since $A\in\mathfrak{A}^+$, the function $f(t)=t^{1/n}$ is continuous on $\sigma(A)$ so $B=f(A)$ is defined. It is clear that $B^n=A$. The uniqueness can be proved similarly as in Proposition~\ref{C^* algebra slef-adjoint positive negative}.
\end{proof}
If $A\in\mathfrak{A}^+$, then the unique $B$ obtained in Proposition~\ref{C^* algebra root of positive} is called the \textbf{$n$-th root} of $A$ and is denoted by $B=A^{1/n}$. Note that if $B$ is not assumed to be positive, it is not necessarily unique. A similar procedure can be used to introduce an element $A^\alpha$ of $\mathfrak{A}^+$, for other real values of $\alpha$. With $f_\alpha$ defined by $f_\alpha(t)=t^\alpha$, $f_\alpha$ is a continuous non-negative real-valued function on $\sigma(A)$ when $\alpha>0$ (for all real $\alpha$, if $A$ is invertible). Note that $f_\alpha(t)f_\beta(t)=f_{\alpha+\beta}(t)$, $f_0(t)=1$, and $f_1(t)=t$, when $A$ is invertible. With $A^\alpha$ defined as $f_\alpha(A)$, it follows that $A^\alpha\in\mathfrak{A}^+$, $A^{\alpha}A^\beta=A^{\alpha+\beta}$, $A^1=A$, and $A^0=I$ if $A$ is invertible.\par
Note that one may also want to define $|A|=(A^2)^{1/2}$, for a self-adjoint element $A\in\mathfrak{A}$. It turns out that this definition coincides with the previous one.
\begin{proposition}\label{C^* algebra suqre root for self-adjoint}
Let $A\in\mathfrak{A}$ be self-adjoint. Then $|A|=(A^2)^{1/2}=A^++A^-$.
\end{proposition}
\begin{proof}
Let $A=A^+-A^-$. then since $A^+A^-=A^-A^+=0$, we have
\[A^2=(A^+-A^-)^2=(A^+)^2+(A^-)^2=(A^++A^-)^2.\]
Thus by Proposition~\ref{C^* algebra root of positive}, we see $(A^2)^{1/2}=A^++A^-$.
\end{proof}
The point of Proposition~\ref{C^* algebra suqre root for self-adjoint} is that we can extend the definition of absolute value to all element of $\mathfrak{A}$. Namely, for $A\in\mathfrak{A}$, we define $|A|:=(A^*A)^{1/2}$.\par
Our next objective is to give a number of conditions equivalent to positivity for elements of a $C^*$-algebra. For this purpose, we require the following preliminary result.
\begin{lemma}\label{C^* algebra A^*A negative iff A=0}
If $\mathfrak{A}$ is a $C^*$-algebra, $A\in\mathfrak{A}$, and $-A^*A\in\mathfrak{A}^+$, then $A=0$.
\end{lemma}
\begin{proof}
Let $A=H+iK$, with $H$ and $K$ self-adjoint in $\mathfrak{A}$. Since $\sigma(H)\sub\R$ and $\sigma(H^2)=\{z^2:z\in\sigma(H)\}\sub\R^+$, it follows that $H^2$ (and similarly $K^2$) is positive. Since $AA*$ is self-adjoint, and $\sigma(-AA^*)\sub\sigma(-A^*A)\cup\{0\}\sub\R^+$ by Proposition~\ref{Banach algebra spectrum prop}, so $-AA^*$ is positive. Now
\begin{align*}
A^*A+AA^*=(H-iK)(H+iK)+(H+iK)(H-iK)=2H^2+2K^2,
\end{align*}
and so $A^*A=2(H^2+K^2)-AA^*$. Since all three terms on the right-hand side of the last equation are positive, $A^*A$ (as well as $-A^*A$) is positive and so $A^*A=0$, by Proposition~\ref{C^* algebra spectrum prop}. Thus $\|A\|=0$ and $A=0$.
\end{proof}
\begin{theorem}\label{C^* algebra self-adjoint is positive iff}
If $\mathfrak{A}$ is a $C$*-algebra and $A\in\mathfrak{A}$, then the following statements are equivalent.
\begin{itemize}
\item[(\rmnum{1})] $A$ is positive.
\item[(\rmnum{2})] $A=B^2$ for some self-adjoint element $B\in\mathfrak{A}$.
\item[(\rmnum{3})] $A=H^*H$ for some $H\in\mathfrak{A}$.
\item[(\rmnum{4})] $A$ is slef-adjoint and $\|A-\alpha I\|\leq\alpha$ for all $\alpha\geq\|A\|$.
\item[(\rmnum{5})] $A$ is slef-adjoint and $\|A-\alpha I\|\leq\alpha$ for some $\alpha\geq\|A\|$. 
\end{itemize}
If $H$ is a Hilbert space and $\mathfrak{A}$ is a $C^*$-subalgebra of $\mathcal{B}(H)$, the preceding three conditions are equivalent to
\begin{itemize}
\item[(\rmnum{6})] $\langle Ax,x\rangle\geq 0$ for all $x\in H$.
\end{itemize}
\end{theorem}
\begin{proof}
It is clear that (\rmnum{2}) implies (\rmnum{3}) and (\rmnum{4}) implies (\rmnum{5}). By Proposition~\ref{C^* algebra root of positive}, (\rmnum{1}) implies (\rmnum{2}). Assume (\rmnum{5}). Since $A$ is slef-adjoint, $\sigma(A)\sub[-\alpha,\alpha]$. Moreover, $\|A-\alpha I\|=\|z-\alpha\|_{\sigma(A)}$, so it is then clear that $\sigma(A)\sub\R^+$ iff $\|A-\alpha I\|\leq\alpha$.\par
Suppose next that $A=H^*H$, for some $H$ in $\mathfrak{A}$. Since $A$ is self-adjoint, it has the decomposition $A^+-A^-$. With $C:=HA^-$, we have
\[C^*C=A^-H^*HA^-=A^-(A^+-A^-)A^-=-(A^-)^3.\]
Since $A^-\in\mathfrak{A}^+$ and $(A^-)^3$ has spectrum $\{z^3:z\in\sigma(A^-)\}$, it follows that $-C^*C\in\mathfrak{A}^+$. From lemma~\ref{C^* algebra A^*A negative iff A=0}, $C=0$; so $(A^-)^3=0$ and, since $A^-$ is self-adjoint, $A^-=0$ by Corollary~\ref{C^* algebra normal nilpotent is zero}. Thus $A=A^+\in\mathfrak{A}^+$.\par
With $\mathfrak{A}$ a $C^*$-subalgebra of $\mathcal{B}(H)$, $\mathfrak{A}^+=\mathcal{B}(H)^+\cap\mathfrak{A}$. Accordingly, in proving the equivalence of (\rmnum{1}) and (\rmnum{5}) in this situation, it suffices to consider the case in which $\mathfrak{A}=\mathcal{B}(H)$. The required result then amounts to the following assertion: if $A\in\mathcal{B}(H)$, then $\langle Ax,x\rangle\geq 0$ for each $x\in H$ iff $A=A^*$ and $\sigma(A)\sub\R^+$.
\end{proof}
\begin{corollary}\label{C^* algebra unitary equivalent positive}
If $\mathfrak{A}$ is a $C^*$-algebra, $A\in\mathfrak{A}^+$, and $B\in\mathfrak{A}$, then $B^*AB\in\mathfrak{A}^+$.
\end{corollary}
\begin{proof}
This follows from the observation $B^*AB=B^*A^{1/2}A^{1/2}B=(A^{1/2}B)^*(A^{1/2}B)$.
\end{proof}
Now we consider the property of the subset $\mathfrak{A}^+$ in $\mathfrak{A}$.
\begin{theorem}\label{C^* algebra positive set prop}
Suppose that $\mathfrak{A}$ is a $C^*$-algebra.
\begin{itemize}
\item[(a)] $\mathfrak{A}^+$ is closed in $\mathfrak{A}$.
\item[(b)] $\alpha A\in\mathfrak{A}^+$ if $A\in\mathfrak{A}^+$ and $\alpha\geq 0$.
\item[(c)] $A+B\in\mathfrak{A}^+$ if $A,B\in\mathfrak{A}^+$.
\item[(d)] $AB\in\mathfrak{A}^+$ if $A,B\in\mathfrak{A}^+$ and $AB=BA$.
\item[(e)] If $A\in\mathfrak{A}^+$ and $-A\in\mathfrak{A}^+$, then $A=0$. 
\end{itemize}
\end{theorem}
\begin{proof}
From Theorem~\ref{C^* algebra self-adjoint is positive iff},
\[\mathfrak{A}^+=\{A\in\mathfrak{A}:A=A^*,\|A-\|A\|I\|\leq\|A\|\}\]
whence $\mathfrak{A}^+$ is closed (since the norm is continuous on $\mathfrak{A}$). Now (b) and (e) follows from the spectral mapping theorem, and (d) follows from Proposition~\ref{Banach algebra spectrum prop}.\par
If $A,B\in\mathfrak{A}^+$, then
\[\|A-\|A\|I\|\leq\|A\|,\quad \|B-\|B\|I\|\leq\|B\|,\]
whence
\[\|A+B-(\|A\|+\|B\|)I\|\leq\|A\|+\|B\|\]
and from Theorem~\ref{C^* algebra self-adjoint is positive iff}, it follows that $A+B\in\mathfrak{A}^+$.
\end{proof}
Suppose that $\mathfrak{A}_h$ is the real linear space consisting of all self-adjoint elements of a $C^*$-algebra $\mathfrak{A}$. Since the adjoint operation is norm continuous, $\mathfrak{A}_h$ is closed in $\mathfrak{A}$, and is therefore a real Banach space. From Theorem~\ref{C^* algebra positive set prop}, it is an ordered vector space with a closed positive cone $\mathfrak{A}^+$. In the partial ordering on $\mathfrak{A}_h$, $A\leq B$ if and only if $B-A\in\mathfrak{A}^+$; and, of course,
\[\mathfrak{A}^+=\{A\in\mathfrak{A}_h:A\geq 0\}.\]
From Proposition~\ref{C^* algebra slef-adjoint positive negative}(b), $-\|A\|I\leq A\leq\|A\|I$ for each $A$ in $\mathfrak{A}_h$; in particular, therefore, $I$ is an order unit for $\mathfrak{A}_h$. (Recall that an order unit is an element $E$ such that for any $A\in\mathfrak{A}_h$, there exist $\alpha>0$ such that $A\leq\alpha E$.) Moreover
\[\|A\|=\inf\{\alpha\geq 0:-\alpha I\leq A\leq\alpha I\}.\]
Just as in the case of real-number inequalities, one can add inequalities between self-adjoint elements of $\mathfrak{A}$ (because sums of positive elements are positive), multiply through by positive scalars (because positive multiples of positive elements are positive), and take limits (because $\mathfrak{A}^+$ is closed in $\mathfrak{A}$), while multiplication by a negative scalar reverses inequalities. Since a product of commuting positive elements is positive, it follows that $AC\leq BC$ whenever $A\leq B$, $C\in\mathfrak{A}^+$, and $C$ commutes with both $A$ and $B$. This last condition is essential, since without it, $AC$ and $BC$ are not self-adjoint. The corresponding non-abelian result, that $C^*AC\leq C^*BC$ whenever $A\leq B$ and $C\in\mathfrak{A}$, however, is a
consequence of Corollary~\ref{C^* algebra unitary equivalent positive}.
\begin{proposition}\label{C^* algebra positive element invertible iff}
Let $\mathfrak{A}$ be a $C^*$-algebra and $A\in\mathfrak{A}^+$. Then $A$ is invertible iff $A\geq\alpha I$ for some positive real number $\alpha$.
\end{proposition}
\begin{proof}
Note that $A\geq\alpha I$ iff $A-\alpha I\in\mathfrak{A}^+$. Since $A$ is invertible $0\notin\sigma(A)$ and $\sigma(A)$ is compact, the claim is clear now.
\end{proof}
\begin{proposition}\label{C^* algebra positive element order prop}
Suppose that $A$ and $B$ are self-adjoint elements of a $C^*$-algebra $\mathfrak{A}$.
\begin{itemize}
\item[(a)] If $-B\leq A\leq B$, then $\|A\|\leq\|B\|$.
\item[(b)] If $0\leq A\leq B$, then $A^{1/2}\leq B^{1/2}$.
\item[(c)] If $0\leq A\leq B$ and $A$ is invertible, then $B$ is invertible and $B^{-1}\leq A^{-1}$.
\end{itemize}
\end{proposition}
\begin{proof}
If $-B\leq A\leq B$ then
\[-\|B\|I\leq-B\leq A\leq B\leq\|B\|I,\]
it follows that $r(A)\leq\|B\|$, so $\|A\|\leq\|B\|$.\par
Suppose that $0\leq A\leq B$ and $A$ is invertible. Then $A\geq\alpha I$, for some positive real number $\alpha$; hence $B\geq\alpha I$, and so $B$ is invertible. Moreover, by Corollary~\ref{C^* algebra unitary equivalent positive},
\[0\leq B^{-1/2}AB^{-1/2}\leq B^{-1/2}BB^{-1/2}=I\]
so $\|B^{-1/2}AB^{-1/2}\|\leq 1$ by (a). Thus
\[\|A^{1/2}B^{-1/2}\|^2=\|(A^{1/2}B^{-1/2})^*(A^{1/2}B^{-1/2})\|=\|B^{-1/2}AB^{-1/2}\|\leq 1.\]
(Note that $A^{1/2}\leq B^{-1/2}$ may not be self-adjoint.) From this, we observe
\[\|A^{1/2}B^{-1}A^{1/2}\|=\|A^{1/2}B^{-1/2}(A^{1/2}B^{-1/2})^*\|\leq 1,\]
whence $A^{1/2}B^{-1}A^{1/2}\leq I$, and therefore $B^{-1}\leq A^{-1}$.\par
Furthermore, we also note that
\[\|B^{-1/4}A^{1/2}B^{-1/4}\|=r(B^{-1/4}A^{1/2}B^{-1/4})=r(A^{1/2}B^{-1/4}B^{-1/4})\leq\|A^{1/2}B^{-1/2}\|\leq 1,\]
thus $B^{-1/4}A^{1/2}B^{-1/4}\leq I$, and $A^{1/2}\leq B^{1/2}$. This proves (c), and (b) in the case in which $A$ is invertible. The general case for (b) can be done by taking $A+\eps I$ and let $\eps\to 0^+$.
\end{proof}
This part closes with an application of positivity to obtain the polar decomposition of an operator. If $\lambda\in\C$, then $\lambda=|\lambda|e^{i\theta}$ for some $\theta$; this is the polar decomposition of $\lambda$. Can an analogue be found for operators? To answer this question we might first ask what is the analogue of $|\lambda|$ and $e^{i\theta}$ among operators. If $A\in\mathcal{B}(H,K)$, then the proper definition for $|A|$ would seem to be $|A|=(A^*A)^{1/2}\in\mathcal{B}(H)$. How about an analogue of $e^{i\theta}$? Should it be a unitary operator? An isometry? For an arbitrary operator neither of these is appropriate. The following new class of operators is needed.
\begin{definition}
A \textbf{partial isometry} is an operator $W\in\mathcal{B}(H,K)$ such that for $x\in N(W)^\bot$ we have $\|Wx\|=\|x\|$. The space $N(W)^\bot$ is called the \textbf{initial space} of $W$ and the space $R(W)$ is called the \textbf{final space} of $W$.
\end{definition}
\begin{proposition}\label{Hilbert space partial isometry iff}
Let $W\in\mathcal{B}(H,K)$. The the following are equivalent.
\begin{itemize}
\item[(\rmnum{1})] $W$ is a partial isometry. 
\item[(\rmnum{2})] $W^*$ is a projection.
\item[(\rmnum{3})] $W^*W$ is a projection.
\item[(\rmnum{4})] $WW^*$ is a projection.
\item[(\rmnum{5})] $WW^*W=W$.
\item[(\rmnum{6})] $W^*WW^*=W^*$.  
\end{itemize}
Moreover, in the affirmative case, the range of $W$ and $W^*$ are closed, $W^*W$ is the projection onto $N(W)^\bot$, and $WW^*$ is the projection onto $R(W)$.
\end{proposition}
\begin{proof}
First assume that $W$ is a partial isometry. Fix $x\in K$ and consider $\langle W^*WW^*x,y\rangle$ and $\langle W^*x,y\rangle$ for $y\in H$. If $y\in N(W)$ then
\[\langle W^*WW^*x,y\rangle=\langle WW^*x,Wy\rangle=0=\langle x,Wy\rangle=\langle W^*x,y\rangle.\]
However, since $W$ is an isometry on $N(W)=\widebar{R(W^*)}$, it preserves the inner product of two elements of $\widebar{R(W^*)}$. So if $y\in N(W)^\bot=\widebar{R(W^*)}$, then
\[\langle W^*WW^*x,y\rangle=\langle WW^*x,Wy\rangle=\langle W^*x,y\rangle.\]
Since $H=N(W)\oplus N(W)^\bot$, this implies $\langle W^*WW^*x,y\rangle=\langle W^*x,y\rangle$ for any $x\in K$ and $y\in H$, thus $W^*WW^*=W^*$. This proves $(\rmnum{1})\Rightarrow(\rmnum{6})$. Also, note that $(WW^*W)^*=W^*WW^*$, so (\rmnum{5}) is equivalent to (\rmnum{6}).\par
With (\rmnum{5}) and (\rmnum{6}), it follows that $W^*W$ is an idempotent and self-adjoint. Thus by Proposition~\ref{Hilbert space idempotent is projection iff}, $W^*W$ is a projection. Similarly, $WW^*$ is also a projection.\par
Now suppose that $WW^*$ is a projection and let $x\in N(W)^\bot=\widebar{R(W^*)}$. Then there exists a sequence $(x_n)$ in $H$ such that $\lim_nW^*x_n=x$. Notice that
\begin{align*}
\|Wx\|^2&=\lim_n\|WW^*x_n\|^2=\lim_n\langle WW^*x_n,WW^*x_n\rangle=\lim_n\langle (WW^*)^2x_n,x_n\rangle\\
&=\lim_n\langle WW^*x_n,x_n\rangle=\lim_n\langle W^*x_n,W^*x_n\rangle=\langle x,x\rangle=\|x\|^2
\end{align*}
This proves that $W$ is a partial isometry. Similarly, we can show that $(\rmnum{3})\Rightarrow(\rmnum{2})$.\par
Now we have proved that
\[(\rmnum{1})\Rightarrow(\rmnum{6})\Leftrightarrow(\rmnum{5})\Rightarrow(\rmnum{4})\Rightarrow(\rmnum{1}).\]
A similar process, starting from (\rmnum{2}), then completes the proof of the equivalences.\par
Now assume that $W$ is a partial isometry. To see that $R(W)$ is closed, suppose $x\in\widebar{R(W)}$. Then there exists a sequence of vectors $(x_n)$ in $K$ such that $x=\lim_nWx_n$. Then
\[WW^*x=\lim_nWW^*Wx_n=\lim_nW^*x_n=x.\]
Thus $x\in R(W)$ and so $R(W)$ is closed.\par
Next we want to show that $WW^*$ is the projection onto the range of $W$. To begin, let $y\in R(T)$, with $y=Tx$ for some $x\in H$. Then
\[WW^*y=WW^*Wx=Wx=y.\]
However, if $y\in R(W)^\bot=N(W^*)$, clearly $WW^*y=0$. Thus $WW^*$ is the projection onto $R(W)$. The claim that $R(W^*)$ is closed and $W^*W$ is the projection on $N(W)^\bot=\widebar{R(W^*)}=R(W^*)$ is a dual consequence.
\end{proof}
\begin{proposition}
If $W$ is a partial isometry, then $W*W$ is the projection onto the initial space of $W$ and $WW^*$ is the projection onto the final space of $W$.
\end{proposition}
\begin{theorem}[\textbf{Polar Decomposition}]
If $A\in\mathcal{B}(H,K)$, then there is a partial isometry $W$ with $N(A)^\bot$ as its initial space and $\widebar{R(A)}$ as its final space such that $A=W|A|$. Moreover, if $A=UP$ where $P$ is positive and $U$ is a partial isometry with $N(U)=N(P)$, then $P=|A|$ and $U=W$.
\end{theorem}
\begin{proof}
If $x\in H$ then
\[\|Ax\|^2=\langle Ax,Ax\rangle=\langle A^*Ax,x\rangle=\||A|x\|^2,\]
thus $\|Ax\|^2=\||A|x\|^2$. If $W:R(|A|)\to R(A)$ is defined by
\[W(|A|x)=Ax\]
Then be the equality above, $W$ is a well-defined isometry. Since we have
\[\widebar{R(A^*)}=N(A)^\bot=N(A^*A)^\bot=\widebar{R(A^*A)},\] 
it follows that $R(A^*A)$ is dense in $N(A)^\bot$. But $A^*A=|A|^2$, so $R(|A|)$ is also dense in $N(A)^\bot$. Thus $W$ extends to an isometry $W:N(A)^\bot\to\widebar{R(A)}$. If $Wx$ is defined to be $0$ for $x\in N(A)$, then $W$ is a partial isometry and $W|A|=A$.\par
For the uniqueness, note that $A^*A=PU^*UP$. Now $U^*U=E$ is the projection onto $N(U)^\bot=N(P)^\bot=\widebar{R(P)}$, thus $A^*A=PEP=P^2$. By the uniqueness of the positive square root, $P=|A|$. Since $A=U|A|$, we see $U|A|x=Ax$. That is, $U$ and $W$ agree on a dense subset of their common initial space. Hence $U=W$.
\end{proof}
\subsection{Positive linear functionals}
In this part, we study linear functionals on a subspace of a $C^*$-algebra. In most applications of the results described below, it suffices to consider the case in which the subspace is the whole $C^*$-algebra; but occasionally, the more general setting is required.\par
We assume throughout that $\mathscr{M}$ is a self-adjoint subspace of a $C^*$-algebra $\mathfrak{A}$, and contains the unit $I$ of $\mathfrak{A}$. The set $\mathscr{M}\cap\mathfrak{A}^+$ of all positive elements of $\mathscr{M}$ is denoted by $\mathscr{M}^+$. If $\mathscr{M}\sub\mathfrak{B}\sub\mathfrak{A}$, where $\mathfrak{B}$ is a $C^*$-subalgebra of $\mathfrak{A}$, then
\[\mathscr{M}^+=\mathscr{M}\cap\mathfrak{A}^+=\mathscr{M}\cap\mathfrak{B}\cap\mathfrak{A}^+=\mathscr{M}\cap\mathfrak{B}^+;\]
so $\mathscr{M}^+$ is unchanged if $\mathscr{M}$ is viewed as a subspace of $\mathfrak{B}$ instead of $\mathfrak{A}$. Since $\mathscr{M}$ contains the real and imaginary parts of each of its members, while each self-adjoint $A$ in $\mathscr{M}$ is the difference of two elements of $\mathfrak{A}^+$, namely $(\|A\|I\pm A)/2$, it follows that $\mathscr{M}$ is the linear span of $\mathscr{M}^+$.\par
With $\rho$ a linear functional on $\mathscr{M}$, the equation $\rho^*(A):=\widebar{\rho(A^*)}$ for $A\in\mathscr{M}$ defines another such functional $\rho^*$. We say $\rho$ is \textbf{Hermitian} if $\rho=\rho^*$; that is, if $\rho(A^*)=\widebar{\rho(A)}$ for each $A$ in $\mathscr{M}$. By expressing elements of $\mathscr{M}$ in terms of their real and imaginary parts, it follows that $\rho$ is hermitian if and only if $\rho(H)=\rho^*(H)$ whenever $H\in\mathscr{M}$ is self-adjoint; so $\rho$ is Hermitian if and only if $\rho(H)$ is real for each self-adjoint $H$ in $\mathscr{M}$. Each linear functional $\rho$ on $\mathscr{M}$ can be expressed, uniquely, in the form $\rho_1+i\rho_2$, where $\rho_1=(\rho+\rho^*)/2$ and $\rho_2=(\rho-\rho^*)/2i$ are Hermitian.
\begin{proposition}\label{C^* algebra bounded Hermitian functional norm}
If $\rho$ is a bounded Hermitian functional on $\mathscr{M}$, then
\[\|\rho\|=\sup\{|\rho(H)|:H=H^*\in\mathscr{M},\|H\|\leq 1\}.\]
\end{proposition}
\begin{proof}
For given $\eps>0$, we can choose $A$ in the unit ball of $\mathscr{M}$ so that $|\rho(A)|>\|\rho\|-\eps$. For a suitable scalar $\alpha$ with $|\alpha|=1$,
\[\|\rho\|-\eps<|\rho(A)|=\rho(\alpha A)=\widebar{\rho(\alpha A)}=\rho((\alpha A)^*).\]
With $H_0$ the real part of $\alpha A$, it is clear that $\|H_0\|\leq 1$ and $|\rho(H)|=|\rho(A)|>\|\rho\|-\eps$. Thus the claim follows.
\end{proof}
A linear functional $\rho$ on $\mathscr{M}$ is said to be \textbf{positive} if $\rho(A)\geq 0$ for each $A\in\mathscr{M}^+$; if, further, $\rho(I)=1$, $\rho$ is called a \textbf{state of $\mathscr{M}$}.
\begin{proposition}
A positive linear functional $\rho$ is Hermitian.
\end{proposition}
\begin{proof}
If $A=A^*\in\mathscr{M}$, then $\rho(\|A\|I\pm A)\geq 0$ since $\|A\|I\pm A\geq 0$, and $\rho(A)$ is real because
\[\rho(A)=\frac{\rho(\|A\|I+A)-\rho(\|A\|I-A)}{2}.\]
This proves the claim.
\end{proof}
The real vector space $\mathscr{M}_h$, consisting of all self-adjoint elements of $\mathscr{M}$, is a partially ordered vector space, with positive cone $\mathscr{M}^+$ and order unit $I$. A linear functional $\rho$ on $\mathscr{M}$ is hermitian if and only if its restriction $\rho|_{\mathscr{M}_h}$ is a linear functional (of course, real-valued) on $\mathscr{M}_h$; and each linear functional on $\mathscr{M}_h$ extends, uniquely, to a Hermitian linear functional on $\mathscr{M}$. Moreover, $\rho$ is positive (or a state of $\mathscr{M}$) if and only if $\rho|_{\mathscr{M}_h}$ is positive (or a state of $\mathscr{M}_h$). The positive linear functionals on $\mathscr{M}$ form a cone $\mathcal{P}$, in the real vector space consisting of all Hermitian linear functionals on $\mathscr{M}$. (Note that $\mathcal{P}\cap-\mathcal{P}=\{0\}$ because $\mathscr{M}$ is the linear span of $\mathscr{M}^+$) Hence there is a partial order relation on the Hermitian linear functionals: $\rho_1\leq\rho_2$ if and only if $\rho_2-\rho_1$ is positive.\par
With $H$ a Hilbert space and $x\in H$, the equation
\[\omega_x(A)=\langle Ax,x\rangle\for A\in\mathcal{B}(H)\]
defines a linear functional $\omega_x$ on $\mathcal{B}(H)$, In view of the equivalence of two concepts of positivity for Hilbert space operators, $\omega_x(A)\geq 0$ whenever $A\in\mathcal{B}(H)^+$. Since, also, $\omega_x(I)=\|x\|^2$, it follows that $\omega_x$ is a positive linear functional on $\mathcal{B}(H)$, and is a state if $\|x\|=1$. If $\mathfrak{A}$ is a $C^*$-subalgebra of $\mathcal{B}(H)$, and (as usual) $\mathscr{M}$ is a self-adjoint subspace of $\mathfrak{A}$ that contains $I$, the restriction $\omega_x|_{\mathfrak{M}}$ is a positive linear functional on $\mathscr{M}$. The states of $\mathscr{M}$ that arise in this way, from unit vectors in $H$, are called \textbf{vector states} of $\mathscr{M}$.
\begin{proposition}\label{C^* algebra positive functional inequality}
If $\rho$ is a positive linear functional on a $C^*$-algebra $\mathfrak{A}$, then
\[|\rho(B^*A)|^2\leq\rho(A^*A)\rho(B^*B)\for A,B\in\mathfrak{A}.\]
\end{proposition}
\begin{proof}
With $A$ in $\mathfrak{A}$, we have $A^*A\in\mathfrak{A}^+$, and therefore $\rho(A^*A)\geq 0$. From this, and since $\rho$ is Hermitian, the equation
\[\langle A,B\rangle=\rho(B^*A)\]
defines a semidefinite inner product on $\mathfrak{A}$, and we have the Cauchy-Schwarz inequality, which is exactly the claim.
\end{proof}
We refer to the inequality occurring in Proposition~\ref{C^* algebra positive functional inequality} as the Cauchy-Schwarz inequality for $\rho$.
\begin{theorem}\label{C^* algebra positive functional positive iff}
If $\mathscr{M}$ is a self-adjoint subspace of a $C^*$-algebra $\mathfrak{A}$ and contains the unit $I$ of $\mathfrak{A}$, a linear functional $\rho$ on $\mathscr{M}$ is positive if and only if $\rho$ is bounded and $\|\rho\|=\rho(I)$.
\end{theorem}
\begin{proof}
Suppose first that $\rho$ is positive (and therefore Hermitian). With $A$ in $\mathscr{M}$, let $\alpha$ be a scalar of modulus $1$ such that $\alpha\rho(A)\geq 0$, and let $H$ be the real part of $\alpha A$. Then $\|H\|\leq\|A\|$, so $H\leq\|H\|I\leq\|A\|I$ and
\[\|A\|\rho(I)-\rho(H)=\rho(\|A\|I-H)\geq 0,\]
therefore
\begin{align*}
|\rho(A)|=\rho(\alpha A)=\widebar{\rho(\alpha A)}=\rho((\alpha A)^*)=\rho\Big(\frac{\alpha A+\bar{\alpha}A^*}{2}\Big)=\rho(H)\leq\rho(I)\|A\|.
\end{align*}
This shows that $\rho$ is bounded, with $\|\rho\|\leq\rho(I)$; and the reverse inequality is evident.\par
Conversely, suppose that $\rho$ is bounded and $\|\rho\|=\rho(I)$; it suffices to consider the case in which $\|\rho\|=\rho(I)=1$. With $A\in\mathscr{M}^+$, let $\rho(A)=a+ib$, where $a$ and $b$ are real. In order to prove that $\rho$ is positive, we have to show that $a\geq 0$ and $b=0$. For small positive $t$,
\[\sigma(I-tA)=\{1-t\alpha:\alpha\in\sigma(A)\}\sub[0,1]\]
since $\sigma(A)\sub\R^+$; so $\|I-tA\|\leq 1$. Hence
\[1-ta\leq|1-t(a+ib)|=|\rho(I-tA)|\leq 1\]
and therefore $a\geq 0$. With $B_n\in \mathscr{M}$ defined by $B_n=A-aI+inbI$, for each positive integer $n$,
\[\|B_n\|^2=\|B_n^*B_n\|=\|(A-aI)^2+n^2b^2I\|\leq\|A-aI\|^2+n^2b^2.\]
Hence
\[(n+1)^2b^2=|\rho(B_n)|^2\leq\|A-aI\|^2+n^2b^2,\]
and thus $b=0$.
\end{proof}
From Theorem~\ref{C^* algebra positive functional positive iff}, each state $\rho$ of $\mathscr{M}$ is a bounded linear functional on $\mathscr{M}$, with $\|\rho\|=1$. Accordingly, the set $\mathcal{S}(\mathscr{M})$ of all states of $\mathscr{M}$ is contained in the unit ball in the dual space $\mathscr{M}^*$. It is convex and weak$^*$ closed, since
\[\mathcal{S}(\mathscr{M})=\{\rho\in\mathscr{M}^*:\rho(I)=1,\rho(A)\geq 0\text{ for all $A\in\mathscr{M}^+$}\}\]
and is therefore weak$^*$ compact. It follows that $\mathcal{S}(\mathscr{M})$, with the weak$^*$ topology, is a compact Hausdorff space, the \textbf{state space} of $\mathscr{M}$.
\begin{proposition}\label{C^* algebra state fixed value}
If $\mathfrak{A}$ is a $C^*$-algebra with identity $I$ and $\mathscr{M}$ a self-adjoint subspace of $\mathfrak{A}$ containing $I$. Then for each $A\in\mathscr{M}$ and $\alpha\in\sigma(A)$, there is a state $\rho$ of $\mathscr{M}$ such that $\rho(A)=\alpha$.
\end{proposition}
\begin{proof}
For all complex numbers $\beta$ and $\gamma$, $\alpha\beta+\gamma\in\sigma(\beta A+\gamma I)$, and therefore $|\alpha\beta+\gamma|\leq\|\beta A+\gamma I\|$. Accordingly, the equation $\rho_0(\beta A+\gamma I):=\alpha\beta+\gamma$ defines (unambiguously) a linear functional $\rho_0$ on the subspace $\C A+\C I$, and $\rho_0(A)=\alpha$, $\rho_0(I)=1$, $\|\rho_0=1$. By the Hahn-Banach theorem, $\rho_0$ extends to a bounded linear functional $\rho$ on $A$, with $\|\rho\|=1$. From Theorem~\ref{C^* algebra positive functional positive iff}, $\rho$ is positive (and is therefore a state); and $\rho(A)=\alpha$.
\end{proof}
\begin{theorem}\label{C^* algebra state space prop}
Suppose that $\mathfrak{A}$ is a $C^*$-algebra with identity $I$, $\mathscr{M}$ is a self-adjoint subspace of $\mathfrak{A}$ containing $I$, and $A\in\mathscr{M}$.
\begin{itemize}
\item[(a)] If $\rho(A)=0$ for each state $\rho$ of $\mathscr{M}$, then $A=0$.
\item[(b)] If $\rho(A)$ is real for each state $\rho$ of $\mathscr{M}$, then $A$ is slef-adjoint.
\item[(c)] If $\rho(A)\geq 0$ for each state $\rho$ of $\mathscr{M}$, then $A\in\mathscr{M}^+$.
\item[(d)] If $A$ is normal, there is a state $\rho$ of $\mathscr{M}$ such that $|\rho(A)|=\|A\|$.
\end{itemize}
\end{theorem}
\begin{proof}
Suppose first that $A$ is self-adjoint and $\rho(A)=0$ for each state $\rho$ of $\mathscr{M}$. From Proposition~\ref{C^* algebra state fixed value}, $\sigma(A)=\{0\}$, so $\|A\|=r(A)=0$ and $A=0$. Next, let $A=H+iK$, with $H$ and $K$ self-adjoint in $\mathscr{M}$. If $\rho(A)=0$ for each state $\rho$ of $\mathscr{M}$, then $\rho(H)=\rho(K)=0$, since $\rho(A)=\rho(H)+i\rho(K)$ and $\rho(H)$ and $\rho(K)$ are real. From the preceding argument, $H=K=0$, whence $A=0$.\par
Now if $\rho(A)$ is real for all sate $\rho$, then
\[\rho(A-A^*)=\rho(A)-\widebar{\rho(A)}=0.\]
Thus $A=A^*$ by (a) and $A$ is self-adjoint. Similarly, if $\rho(A)\geq 0$ for all $\rho$, then $A\in\mathscr{M}^+$, by Proposition~\ref{C^* algebra state fixed value}.\par
If $A$ is normal, then $r(A)=\|A\|$, so $\sigma(A)$ contains a scalar $\alpha$ such that $|\alpha|=\|A\|$. By Proposition~\ref{C^* algebra state fixed value}, $\alpha=\rho(A)$, for some state $\rho$ of $\mathscr{M}$.
\end{proof}
Our next objective is to provide a Jordan decomposition for Hermitian functionals on a $C^*$-algebra $\mathfrak{A}$. For this purpose, we require the following lemma, which will be needed again later when we characterize those subsets of the state space $\mathcal{S}(\mathscr{M})$ that retain some of the properties of $\mathcal{S}(\mathscr{M})$ set out in Theorem~\ref{C^* algebra state space prop}.
\begin{lemma}\label{C^* algebra closed convex hull of norm states}
Suppose that $\mathfrak{A}$ is a $C^*$-algebra with identity $I$, $\mathscr{M}$ is a self-adjoint subspace of $\mathfrak{A}$ containing $I$, and $\mathcal{S}_0$ is a set of states of $\mathscr{M}$. If
\[\|H\|=\sup\{|\rho(H)|:\rho\in\mathcal{S}_0\}\]
for each self-adjoint $H$ in $\mathscr{M}$, then $\widebar{\conv}(\mathcal{S}_0\cup-\mathcal{S}_0)$ is the set of all Hermitian functionals in the unit ball of $\mathscr{M}^*$.
\end{lemma}
\begin{proof}
The set of all Hermitian functionals in the unit ball $B_{\mathscr{M}^*}$ is convex and weak$^*$ closed, and contains $\mathcal{S}_0\cup-\mathcal{S}_0$; so it contains its closed convex hull. We have to show that the two sets coincide. Suppose the contrary, and let $\rho_0$ be a Hermitian functional on $\mathscr{M}$ such that $\|\rho_0\|\leq 1$ and $\rho_0\notin\widebar{\conv}(\mathcal{S}_0\cup-\mathcal{S}_0)$. By the Hahn-Banach theorem, and since the weak$^*$ continuous linear functionals on $\mathscr{M}^*$ arise from elements of $\mathscr{M}$, there is an $A$ in $\mathscr{M}$ such that $\rho_0(A)=1$ and $\rho(A))=a$ for all $\rho\in\widebar{\conv}(\mathcal{S}_0\cup-\mathcal{S}_0)$. With $H$ the real part of $A$, for every hermitian functional $\rho$ on $\mathscr{M}$, we have
\[\rho(H)=\frac{\rho(A)+\rho(A^*)}{2}=\Re(\rho(A));\]
so $\rho_0(H)=1$ and $\rho(H)=0$ for all $\rho\in\widebar{\conv}(\mathcal{S}_0\cup-\mathcal{S}_0)$. Thus $|\rho(H)|=0$ for $\rho\in\mathcal{S}_0$ and 
\[1=\rho_0(H)\leq\|H\|=\sup\{|\rho_0(H)|:\rho\in\mathcal{S}_0\}=0\]
which is a contradiction.
\end{proof}
\begin{theorem}\label{C^* algebra decomposition}
If $\mathfrak{A}$ is a $C^*$-algebra with idneitty $I$ and $\mathscr{M}$ is a self-adjoint subspace of $\mathfrak{A}$ containing $I$, each bounded Hermitian functional $\rho$ on $\mathscr{M}$ can be expressed in the form $\rho^+-\rho^-$, where $\rho^+$ and $\rho^-$ are positive linear functionals on $\mathscr{M}$ and $\|\rho\|=\|\rho^+\|+\|\rho^-\|$. If $\mathscr{M}$ is the whole of $\mathfrak{A}$, these conditions determine $\rho^+$ and $\rho^-$ uniquely.
\end{theorem}
\begin{proof}
We may assume that $\|\rho\|=1$. With $\mathcal{S}$ the state space of $\mathscr{M}$,
\[\|A\|=\sup\{|\tau(A)|:\tau\in\mathcal{S}\}.\]
for each self-adjoint $A$ in $\mathscr{M}$, from Theorem~\ref{C^* algebra state space prop}(d) and since $\|\tau\|\leq 1$ when $\tau\in\mathcal{S}$. By Lemma~\ref{C^* algebra closed convex hull of norm states}, $\rho\in\widebar{\conv}(\mathcal{S}\cup-\mathcal{S})$. However, it is straightforward to verify that $\widebar{\conv}(\mathcal{S}\cup-\mathcal{S})$ is given by
\[\widebar{\conv}(\mathcal{S}\cup-\mathcal{S})=\{a\sigma-b\tau:\sigma,\tau\in\mathcal{S},a,b\geq 0,a+b=1\}\]
and it is weak$^*$-compact. From this, and the preceding paragraph, $\rho=a\sigma-b\tau$, with $\sigma$ and $\tau$ in $\mathcal{S}$; $a,b\geq 0$ and $a+b=1$. With $\rho^+$ and $\rho^-$ the positive linear functionals $a\sigma$ and $b\tau$, respectively, we have $\rho=\rho^+-\rho^-$ and $\|\rho^+\|+\|\rho^-\|=a+b=1=\|\rho\|$. This proves the first part of the theorem.\par
Suppose now that $\mathscr{M}=\mathfrak{A}$. To prove the uniqueness of the decomposition of $\rho$, we assume that $\rho=\sigma-\tau=\sigma'-\tau'$ where $\sigma,\tau,\sigma',\tau'$ are positive linear functionals on $\mathfrak{A}$ and
\[\|\rho\|=\|\sigma\|+\|\tau\|=\|\sigma'\|+\|\tau'\|=1.\]
Given $\eps>0$, choose a self-adjoint $H$ in the unit ball of $\mathfrak{A}$ for which $\rho(H)>\|\rho\|-\eps^2/2$, and let $K=(I-H)/2$. Then $0\leq K\leq I$ and
\[\sigma(I)+\tau(I)=\|\sigma\|+\|\tau\|=\|\rho\|<\rho(H)+\eps^2/2=\sigma(H)-\tau(H)+\eps^2/2,\]
so
\[\sigma(K)+\tau(I-K)=\frac{1}{2}[\sigma(I-H)+\tau(I+H)]<\eps^2/4.\]
Since $K,I-K\in\mathfrak{A}^+$, while $\sigma$ and $\tau$ are positive linear functionals, this implies $0<\sigma(K)<\eps^2/4$ and $0<\tau(I-K)<\eps^2/4$. With $A$ in $\mathfrak{A}$, the Cauchy-Schwarz inequality gives
\begin{align*}
|\sigma(KA)|^2&=|\sigma(K^{1/2}K^{1/2}A)|^2\leq\sigma(K)\sigma(A^*KA)\leq\frac{\eps^2}{4}\|A\|^2,\\
|\tau((I-K)A)|^2&=|\tau((I-K)^{1/2}(I-K)^{1/2}A)|^2\leq\tau(I-K)\tau(A^*(I-K)A)\leq\frac{\eps^2}{4}\|A\|^2.
\end{align*}
From this, and a similar argument for $\sigma'$ and $\tau'$, we have
\[|\sigma(KA)|\leq\frac{\eps}{2}\|A\|,\quad |\sigma'(KA)|\leq\frac{\eps}{2}\|A\|,\quad|\tau((I-K)A)|\leq\frac{\eps}{2}\|A\|,\quad|\tau'((I-K)A)|\leq\frac{\eps}{2}\|A\|.\]
Now $\sigma-\sigma'=\tau-\tau'$,
\[\sigma(A)-\sigma'(A)=\sigma(KA)-\sigma'(KA)+\tau((I-K)A)-\tau'((I-K)A)\]
and so $|\sigma(A)-\sigma'(A)|\leq 2\eps\|A\|$. Since the last inequality has been proved for each positive $\eps$, it follows that $\sigma=\sigma'$, whence $\tau=\tau'$.
\end{proof}
\begin{corollary}
If $\mathfrak{A}$ is a $C^*$-algebra with identity $I$ and $\mathscr{M}$ is a self-adjoint subspace of $\mathfrak{A}$ containing $I$, each bounded linear functional on $\mathscr{M}$ is a linear combination of at most four states of $\mathscr{M}$.
\end{corollary}
Since the state space $\mathcal{S}(\mathscr{M})$ of $\mathscr{M}$ is convex and weak$^*$ compact, it has extreme points; indeed, by the Krein-Milman theorem, $\mathcal{S}(\mathscr{M})$ is the weak$^*$ closed convex hull of the set $\mathcal{P}(\mathscr{M})$ of its extreme points. Elements of $\mathcal{P}(\mathscr{M})$ are called \textbf{pure states} of $\mathscr{M}$, and the weak$^*$ closure $\widebar{\mathcal{P}(\mathscr{M})}$ is called the \textbf{pure state space} of $\mathscr{M}$. In general, $\mathcal{P}(\mathscr{M})$ is not a closed subset of $\mathscr{M}^*$, and the pure state space then has elements that are not pure states.\par
A linear functional $\rho$ on $\mathscr{M}$ is a pure state if and only if its restriction $\rho|_{\mathscr{M}_h}$ to the partially ordered vector space $\mathscr{M}_h$ consisting of all self-adjoint elements of $\mathscr{M}$, is a pure state of $\mathscr{M}_h$. Indeed, this follows from similar assertions, concerning Hermitian linear functionals and states, occurring in the discussion preceding Proposition~\ref{C^* algebra positive functional inequality}.\par
The following characterization for a pure sate follows easily from definition.
\begin{proposition}\label{C^* algebra pure state iff}
Suppose that $\mathfrak{A}$ is a $C^*$-algebra with identity $I$, $\mathscr{M}$ is a self-adjoint subspace of $\mathfrak{A}$ that contains $I$. Then a state $\rho$ on $\mathscr{M}$ is a pure state if and only if each positive functional $\tau$ on $\mathscr{M}$ such that $\tau\leq\rho$ is a scalar multiple of $\rho$.
\end{proposition}
\begin{proof}
If the stated condition holds for $\rho$ and $\rho=t\rho_1+(1-t)\rho_2$, with $0<t<1$ and $\rho_1,\rho_2\in\mathcal{S}(\mathscr{M})$, then $0\leq t\rho_1\leq\rho$, so that $t\rho_1=\alpha\rho$. Since $\rho_1(I)=\rho(I)=1$, it follows that $t=\alpha$ and $\rho_1=\rho$. Similarly, $\rho_2=\rho$, so $\rho_1=\rho_2$ and $\rho$ is pure.\par
Conversely, assume that $\rho$ is pure and $0\leq\tau\leq\rho$. Then $0\leq\tau(I)\leq\rho(I)=1$. If $\tau(I)=0$, then for each $A\in\mathscr{M}$, we have
\[0=\tau(-\|A\|I)\leq\tau(A)\leq\tau(\|A\|I)=0,\]
and so $\tau(A)=0$. Thus $\tau=0=0\cdot\rho$. If $\tau(I)=1$, a similar argument shows that $\tau=\rho$, so $\tau=1\cdot\rho$. If $0<\tau(I)<1$, then we have
\[\rho=(1-\tau(I))\frac{\rho-\tau}{1-\tau(I)}+\tau(I)\frac{\tau}{\tau(I)}.\]
Since $\rho$ is pure, $\rho=\tau/\tau(I)$, so $\tau$ is a multiple of $\rho$.
\end{proof}
Note that for each $A\in\mathscr{M}$, the evaluation map $\delta_A$ is a weak$^*$ continuous linear functional on $\mathcal{S}(\mathscr{M})$, and Theorem~\ref{C^* algebra state space prop} implies that, for $A$ normal in $\mathfrak{A}$,
\[\|A\|=\sup\{\Re(\delta_A(\tau)):\tau\in\mathcal{S}(\mathscr{M})\}=\sup\{|\delta_A(\tau)|:\tau\in\mathcal{S}(\mathscr{M})\}.\]
Combine this with the Krein-Milman theorem, we obtain the following results.
\begin{theorem}\label{C^* algebra pure state space prop}
Suppose that $\mathfrak{A}$ is a $C^*$-algebra with identity $I$, $\mathscr{M}$ is a self-adjoint subspace of $\mathfrak{A}$ that contains $I$, and $A\in\mathfrak{A}$.
\begin{itemize}
\item[(a)] If $\rho(A)=0$ for each pure state $\rho$ of $\mathscr{M}$, then $A=0$.
\item[(b)] If $\rho(A)$ is real for each pure state $\rho$ of $\mathscr{M}$, then $A$ is slef-adjoint.
\item[(c)] If $\rho(A)\geq 0$ for each pure state $\rho$ of $\mathscr{M}$, then $A\in\mathscr{M}^+$.
\item[(d)] If $A$ is normal, there is a pure state $\rho$ of $\mathscr{M}$ such that $|\rho(A)|=\|A\|$.
\end{itemize}
\end{theorem}
\begin{proof}
If $\rho(A)=0$ (or $\rho(A)$ is real, or $\rho(A)\geq 0$) for all $\rho$ in $\mathcal{P}(\mathscr{M})$, then the same is true for all $\rho$ in $\mathcal{S}(\mathscr{M})$, since every state is a weak$^*$ limit of convex combinations of pure states. In view of this, the first three parts of the theorem follow, at once, from the corresponding assertions in Theorem~\ref{C^* algebra state space prop}. Also, the last statement follows from Example~\ref{LCHS real functional minimal on extreme point}.
\end{proof}
\begin{theorem}\label{C^* algebra state subspace generating iff}
If $\mathfrak{A}$ is a $C^*$-algebra with identity $I$, $\mathscr{M}$ is a self-adjoint subspace of $\mathfrak{A}$ that contains $I$, and $\mathcal{S}_0$ is a subset of the state space $\mathcal{S}(\mathscr{M})$, the following four conditions are equivalent:
\begin{itemize}
\item[(\rmnum{1})] If $A\in\mathscr{M}$ and $\rho(A)\geq 0$ for each $\rho$ in $\mathcal{S}_0$, then $A\in\mathfrak{A}^+$.
\item[(\rmnum{2})] For each self-adjoint $H$ in $\mathscr{M}$, $\|H\|=\sup\{|\rho(H)|:\rho\in\mathcal{S}_0$\}.
\item[(\rmnum{3})] $\widebar{\conv}(\mathcal{S}_0)=\mathcal{S}(\mathscr{M})$.
\item[(\rmnum{4})] $\mathcal{P}(\mathscr{M})\sub\overline{\mathcal{S}_0}$.
\end{itemize}
\end{theorem}
\begin{proof}
The fact that $(\rmnum{2})\Leftrightarrow(\rmnum{3})$ is contained in Theorem~\ref{Krein-Milman closed convex hull equal iff linear functional}, and $(\rmnum{3})\Leftrightarrow(\rmnum{4})$ follows from Theorem~\ref{Krein-Milman closed convex hull equal iff extreme point}.\par
We now prove that $(\rmnum{1})\Rightarrow(\rmnum{2})$. With $H$ self-adjoint in $\mathscr{M}$, set $\alpha=\sup\{|\rho(H)|:\rho\in\mathcal{S}_0\}\leq\|H\|$ and note that
\[\rho(\alpha I\pm H)=\alpha\pm\rho(H)\geq 0.\]
If (\rmnum{1}) is satisfied, then $\alpha I\pm H\in\mathscr{M}^+$, hence $-\alpha I\leq H\leq\alpha I$ and so $\|H\|=\alpha$. Thus (\rmnum{1}) implies (\rmnum{2}).\par
Finally, suppose that $\mathcal{P}(\mathscr{M})\sub\overline{\mathcal{S}_0}$. If $A\in\mathscr{M}$ and $\rho(A)\geq 0$ for each $\rho$ in $\mathcal{S}_0$, then the same is true for each $\rho$ in $\mathcal{P}(\mathscr{M})$, thus for any $\rho\in\mathcal{S}(\mathscr{M})$. By Theorem~\ref{C^* algebra state space prop}(c), $A\in\mathfrak{A}^+$, so (\rmnum{4}) implies (\rmnum{1}).
\end{proof}
\begin{corollary}
If $A$ is a self-adjoint operator acting on a Hilbert space $H$, then
\[\|A\|=\sup\{|\langle Ax,x\rangle:x\in H,\|x\|=1\}.\]
If $\mathscr{M}$ is a self-adjoint subspace of $\mathcal{B}(H)$ containing $I$ and $\mathcal{S}_0$ is the set of all vector states of $\mathcal{B}(H)$, then $\mathcal{P}(\mathscr{M})\sub\overline{\mathcal{S}_0}$ and $\mathcal{S}(\mathscr{M})=\widebar{\conv}(\mathcal{S}_0)$.
\end{corollary}
\begin{proof}
If $A\in\mathcal{B}(H)$ and $\langle Ax,x\rangle\geq 0$, then $A\in\mathcal{B}(H)^+$ by Theorem~\ref{C^* algebra self-adjoint is positive iff}. Thus the claim follows from Theorem~\ref{C^* algebra state subspace generating iff}.
\end{proof}
To conclude this part, we characterize pure states on an abelian $C^*$-algebra.
\begin{proposition}\label{C^* algebra pure state multiplicative for center}
If $\mathfrak{A}$ is a $C^*$-algebra with center $\mathscr{C}$ and $\rho$ is a pure state of $\mathfrak{A}$, then $\rho(AC)=\rho(A)\rho(C)$ for all $A\in\mathfrak{A}$ and $C\in\mathscr{C}$. Moreover, the restriction $\rho|_{\mathscr{C}}$ is a pure state of $\mathscr{C}$.
\end{proposition}
\begin{proof}
In order to show that $\rho(AC)=\rho(A)\rho(C)$ when $A\in\mathfrak{A}$ and $C\in\mathscr{C}$, it suffices (by linearity) to consider the case in which $0\leq C\leq I$. In this case, for each $H$ in $\mathfrak{A}^+$, we have $0\leq HC\leq H$, and thus $0\leq\rho(HC)\leq\rho(H)$, since $H$ commutes with $C$. Hence the equation $\rho_0(A)=\rho(AC)$ defines a positive linear functional $\rho_0$ on $\mathfrak{A}$, and $\rho_0\leq\rho$. Since $\rho$ is a pure state, so is its restriction $\rho|_{\mathfrak{A}_h}$ to the partially ordered vector space $\mathfrak{A}_h$ of all self-adjoint elements of $\mathfrak{A}$. Since $\rho_0|_{\mathfrak{A}_h}\leq\rho|_{\mathfrak{A}_h}$, it follows from Proposition~\ref{C^* algebra pure state iff} that $\rho_0|_{\mathfrak{A}_h}=\alpha(\rho|_{\mathfrak{A}_h})$, for some scalar $\alpha$. Hence $\rho_0=\alpha\rho$ and
\[\rho(AC)=\rho_0(A)=\alpha\rho(A)=\alpha\rho(I)\rho(A)=\rho_0(I)\rho(A)=\rho(C)\rho(A)\]
for each $A\in\mathfrak{A}$.
\end{proof}
\begin{proposition}\label{C^* algebra pure state for abelian}
A non-zero linear functional $\rho$ on an abelian $C^*$-algebra $\mathfrak{A}$ is a pure state if and only $\rho\in\mathfrak{M}$, the maximal ideal space of $\mathfrak{A}$.
\end{proposition}
\begin{proof}
The first assertion of Proposition~\ref{C^* algebra pure state multiplicative for center} includes, as a special case, the fact that pure states of an abelian $C^*$-algebra are multiplicative.\par
Conversely, suppose that $\rho$ is a multiplicative linear functional on $\mathfrak{A}$. Then $\rho$ is a $*$-homomorphism from $\mathfrak{A}$ to $\C$, so by Proposition~\ref{Banach algebran abelian homomorphism to C} it is bounded and $\|\rho\|=1$, thus a state of $\mathfrak{A}$. In order to prove that $\rho$ is pure, suppose that $\rho=a\rho_1+b\rho_2$, where $\rho_1,\rho_2\in\mathcal{S}(\mathfrak{A})$, $a,b\geq 0$ and $a+b=1$. With $A$ self-adjoint in $\mathfrak{A}$,
\[[\rho_i(A)]^2=[\rho_i(IA)]^2\leq\rho_i(I)\rho_i(A^2)=\rho_i(A^2)\for i=1,2,\]
by the Cauchy-Schwarz inequality. Accordingly,
\begin{align*}
0=&\rho(A^2)-[\rho(A)]^2=a\rho_1(A^2)+b\rho_2(A^2)-[a\rho_1(A)+b\rho_2(B)]^2\\
&\geq a(a+b)[\rho_1(A)]^2+b(a+b)[\rho_2(A)]^2-[a\rho_1(A)+b\rho_2(B)]^2\\
&=ab[\rho_1(A)-\rho_2(A)]^2\geq 0.
\end{align*}
From this, $\rho_1(A)=\rho_2(A)$ for each self-adjoint $A\in\mathfrak{A}$; so $\rho_1=\rho_2$, whence $\rho$ is a pure state.
\end{proof}
\begin{corollary}
The set $\mathcal{P}(\mathscr{M})$ of pure states of an abelian $C^*$-algebra is a closed subset of the state space $\mathcal{S}(\mathscr{M})$.
\end{corollary}
\subsection{Representations of \boldmath$C^*$-algebras}
A \textbf{representation} of a $C^*$-algebera is a pair $(\pi,H)$, where $H$ is a Hilbert space and $\pi:\mathfrak{A}\to\mathcal{B}(H)$ is a $*$-homomorphism. Here we only consider $C^*$-algebras \textit{with identities}. If $\mathfrak{A}$ has an identity, it is assumed that $\pi(I)=I$. Often mention of $H$ is suppressed and we say that $\pi$ is a representation.\par
If, in addition, $\pi$ is one-to-one (hence, a $*$- monomorphism), it is called a \textbf{faithful representation}. Our main purpose in this part is to show that every $C^*$-algebra has a faithful representation on some Hilbert space.\par
Suppose that $\pi$ is a representation of a $C^*$-algebra $\mathfrak{A}$ on a Hilbert space $H$. In view of our convention that $*$-homomorphisms preserve units, and from Proposition~\ref{C^* algebra homomorphism prop}, $\|\pi(A)\|\leq\|A\|$ for each $A\in\mathfrak{A}$ (whence $\pi$ is continuous), and $\|\pi(A)\|=\|A\|$ if $\pi$ is faithful. The set $\{A\in\mathfrak{A}:\pi(A)=0\}$ is a closed two-sided ideal in $\mathfrak{A}$, the \textbf{kernel} of $\pi$. If there is a vector $x\in H$ for which the linear subspace
\[\pi(\mathfrak{A})x=\{\pi(A)x:A\in\mathfrak{A}\}\]
is dense in $H$, then $\pi$ is called a \textbf{cyclic representation}, and $x$ is called a \textbf{cyclic vector} (or \textbf{generating vector}) for $\pi$. It turns out that there is an intimate connection between states of $\mathfrak{A}$ and cyclic representations; and the proof of the existence of a faithful representation depends on the construction, from states, of an abundance of cyclic representations.
\begin{example}
If $H$ is a Hilbert space and $\mathfrak{A}$ is a $C^*$-subalgebra of $\mathcal{B}(H)$, then the inclusion map $\mathfrak{A}\hookrightarrow\mathcal{B}(H)$ is a representation. Suppose
that $M$ is a closed subspace of $H$, and is invariant under each operator in $\mathfrak{A}$. When $A\in\mathfrak{A}$, the restriction $A|_{M}$ can be viewed as a bounded linear operator on $M$, and coincides with the compression of $A$ to $M$. Since compression is an adjoint preserving process, it is easily verified that the mapping $A\mapsto A|_M$ is a $*$-homomorphism, and is therefore a representation of $\mathfrak{A}$ on $\mathcal{B}(M)$. With $A\in\mathfrak{A}$, $M$ is invariant under both $A$ and $A^*$, and so reduces $A$; equivalently, $A$ commutes with the projection $P$ from $H$ onto $M$. Accordingly, the orthogonal complement $M^\bot$ is invariant under each operator in $\mathfrak{A}$, and gives rise to a representation $A\mapsto A|{M^\bot}$ of $\mathfrak{A}$ on $M^\bot$.
\end{example}
\begin{example}
If $n$ is any cardinal number and $H$ is a Hilbert space, let $H^{(n)}$ denote the direct sum of $H$ with itself $n$ times. If $A\in\mathcal{B}(H)$, then $A^{(n)}$ is the direct sum of $A$ with itself $n$ times; so $A^{(n)}\in\mathcal{B}(H^{(n)})$ and $\|A^{(n)}\|=\|A\|$. The operator $A^{(n)}$ is called the inflation of $A$. If $\pi:\mathfrak{A}\to\mathcal{B}(H)$ is a representation, the inflation of $\pi$ is the map $\pi^{(n)}:\mathfrak{A}\to\mathcal{B}(H^{(n)})$ defined by $\pi^{(n)}(A)=\pi(A)^{(n)}$ for all $A\in\mathfrak{A}$.
\end{example}
\begin{example}
If $(X,\mathcal{A},\mu)$ is a $\sigma$-finite measure space and $H=L^2(\mu)$, then $\pi:L^\infty(\mu)\to\mathcal{B}(H)$ defined by $\pi(\phi)=M_\phi$ is a representation.
\end{example}
\begin{example}
If $X$ is a compact Hausdorff space and $\mu$ is a positive Borel measure on $X$, then $\pi:C(X)\to\mathcal{B}(L^2(\mu))$ defined by $\pi(f)=M_f$ is a representation.
\end{example}
\begin{example}
Let $H$ be a Hilbert space, $\mathcal{F}\sub\mathcal{B}(H)$, and $x\in H$. Since $\mathfrak{A}x$ is invariant under each operator in $\mathfrak{A}$, the same is true of the closed subspace $[\mathfrak{A}x]:=\overline{\langle\mathfrak{A}x\rangle}$, so the mapping $A\mapsto A|_{[\mathfrak{A}x]}$ is a representation of $\mathfrak{A}$ on $[\mathfrak{A}x]$. The representation $A\mapsto A|_{[\mathfrak{A}x]}$ of $\mathfrak{A}$ on $[\mathfrak{A}x]$ is cyclic, having $x$ as a cyclic vector.
\end{example}
Suppose that $\pi$ is a representation of a $C^*$-algebra $\mathfrak{A}$ on a Hilbert space $H$ and $x$ is a unit vector in $H$. With $\omega_x$ the corresponding vector state of $\mathcal{B}(H)$, the composite function $\omega_x\circ\pi$ is a state $\rho$ of $\mathfrak{A}$. Indeed, since $\omega_x=I$, $\pi(\mathfrak{A}^+)\sub\mathcal{B}(H)^+$, and
\[\rho(A)=\omega_x(\pi(A))=\langle\pi(A)x,x\rangle\for A\in\mathfrak{A},\]
it is evident that $\rho$ is a positive linear functional on $\mathfrak{A}$, and $\rho(I)=\omega_x(I)=1$. We will show that each state of a $C^*$-algebra arises in this way, from a vector state in an appropriate representation. We first need an auxiliary result.
\begin{proposition}\label{C^* algebra state left kernel}
If $\rho$ is a state of a $C^*$-algebra $\mathfrak{A}$, the set
\[\mathscr{L}_\rho=\{A\in\mathfrak{A}:\rho(A^*A)=0\}\]
is a closed left ideal in $\mathfrak{A}$, and $\rho(B^*A)=0$ whenever $A\in\mathscr{L}_\rho$ and $B\in\mathfrak{A}$. The equation
\[\langle A+\mathscr{L}_\rho,B+\mathscr{L}_\rho\rangle=\rho(B^*A)\]
defines an inner product on the quotient linear space $\mathfrak{A}/\mathscr{L}_p$.
\end{proposition}
\begin{proof}
Since $\rho$ is positive (and hence, also, Hermitian), we can define a semidefinite inner product $\langle\cdot,\cdot\rangle_0$ on $\mathfrak{A}$ by $\langle A,B\rangle_0=\rho(B^*A)$ and $\mathscr{L}_\rho=\{A\in\mathfrak{A}:\langle A,A\rangle_0=0\}$. Thus $\mathscr{L}_\rho$ is a linear subspace of $\mathfrak{A}$ and the equation
\[\langle A+\mathscr{L}_\rho,B+\mathscr{L}_\rho\rangle=\langle A,B\rangle_0=\rho(B^*A)\]
defines a definite inner product on $\mathfrak{A}/\mathscr{L}_p$. If $A\in\mathscr{L}_p$ and $B\in\mathfrak{A}$, then
\[|\rho(B^*A)|^2\leq\rho(B^*B)\rho(A^*A)=0\]
so $\rho(B^*A)=0$. Upon replacing $B$ by $B^*BA$, it follows that
\[\rho((BA)^*BA)=\rho((B^*BA)^*A)=0\]
and so $BA\in\mathscr{L}_p$ whenever $A\in\mathscr{L}_p$. Hence $\mathscr{L}_\rho$ is a left ideal of $\mathfrak{A}$, and is closed since $\rho$ is continuous.
\end{proof}
We refer to $\mathscr{L}_\rho$ as the \textbf{left kernel} of the state $\rho$.
\begin{theorem}\label{C^* cyclic representation for state}
If $\rho$ is a state of a $C^*$-algebra $\mathfrak{A}$, there is a cyclic representation $\pi_\rho$ on a Hilbert space $H_\rho$ and a unit cyclic vector $x_\rho$ for $\pi_\rho$ such that $\rho=\omega_{x_\rho}\circ\pi_\rho$; that is,
\[\rho(A)=\langle\pi(A)x_\rho,x_\rho\rangle\for A\in\mathfrak{A}.\]
\end{theorem}
\begin{proof}
With $\mathscr{L}_\rho$ the left kernel of $\rho$, the quotient linear space $\mathfrak{A}/\mathscr{L}_\rho$ is a pre-Hilbert space relative to the definite inner product defined, as in Proposition~\ref{C^* algebra state left kernel}, by
\[\langle A+\mathscr{L}_\rho,B+\mathscr{L}_\rho\rangle=\rho(B^*A).\]
Its completion is a Hilbert space $H_\rho$.\par
If $A,B_1,B_2\in\mathfrak{A}$, since $\mathscr{L}_\rho$ is a left ideal in $\mathfrak{A}$, $B_1+\mathscr{L}_\rho=B_2+\mathscr{L}_\rho$ implies $AB_1+\mathscr{L}_\rho=AB_2+\mathscr{L}_\rho$. Accordingly, the equation $\pi(A)(B+\mathscr{L}_\rho)=AB+\mathscr{L}_\rho$ defines, unambiguously, a linear operator $\pi(A)$ acting on the pre-Hilbert space $\mathfrak{A}/\mathscr{L}_\rho$. Now
\[\|A\|^2I-A^*A=\|A^*A\|I-A^*A\in\mathfrak{A}^+\]
hence $B^*(\|A\|^2I-A^*A)B\in\mathfrak{A}^+$, and therefore
\begin{align*}
&\|A\|^2\|B+\mathscr{L}_\rho\|^2-\|\pi(A)(B+\mathscr{L}_\rho)\|^2=\|A\|^2\|B+\mathscr{L}_\rho\|^2-\|AB+\mathscr{L}_\rho\|^2\\
&=\|A\|^2\rho(B^*B)-\rho(B^*A^*AB)=\rho(B^*(\|A\|^2I-\|A^*A\|)B)\geq 0.
\end{align*}
for all $A$ and $B$ in $\mathfrak{A}$. Thus $\pi(A)$ is bounded, with $\|\pi(A)\|\leq\|A\|$; and $\pi(A)$ extends by continuity to a bounded linear operator $\pi_\rho(A)$ acting on $H_\rho$.\par
Since $\pi(I)$ is the identity operator on $\mathfrak{A}/\mathscr{L}_\rho$, $\pi_\rho(I)$ is the identity operator on $H_\rho$. When $A,B,C\in\mathfrak{A}$ and $\alpha,\beta\in\C$,
\begin{align*}
\pi_\rho(\alpha A+\beta B)(C+\mathscr{L}_\rho)&=(\alpha A+\beta B)C+\mathscr{L}_\rho=(\alpha\pi_\rho(A)+\beta\pi_\rho(B))(C+\mathscr{L}_\rho),\\
\pi_\rho(AB)(C+\mathscr{L}_\rho)&=ABC+\mathscr{L}_\rho=\pi_\rho(A)(BC+\mathscr{L}_\rho)=\pi_\rho(A)\pi_\rho(B)(C+\mathscr{L}_p),\\
\langle\pi_\rho(A)(B+\mathscr{L}_\rho),C+\mathscr{L}_\rho\rangle&=\langle AB+\mathscr{L}_\rho,C+\mathscr{L}_\rho\rangle=\rho(C^*AB)=\rho((A^*C)^*B)\\
&=\langle B+\mathscr{L}_\rho),A^*C+\mathscr{L}_\rho\rangle=\langle B+\mathscr{L}_\rho,\pi_\rho(A^*)(C+\mathscr{L}_\rho)\rangle.
\end{align*}
From these relations, and since $\mathfrak{A}/\mathscr{L}_\rho$ is dense in $H_\rho$, it follows that $\pi_\rho:\mathfrak{A}\to\mathcal{B}(H_\rho)$ is a representation. With $x_\rho$ the vector $I+\mathscr{L}_\rho$ in $\mathfrak{A}/\mathscr{L}_\rho$, we have
\[\pi_\rho(A)x_\rho=A+\mathscr{L}_\rho\for A\in\mathfrak{A}\]
Hence $\pi_\rho(\mathfrak{A})x_\rho$ is dense in $H_\rho$ and $x_\rho$ is a cyclic vector for $\pi_\rho$. Moreover,
\[\langle\pi(A)x_\rho,x_\rho\rangle=\langle A+\mathscr{L}_\rho,I+\mathscr{L}_\rho\rangle=\rho(A).\]
In particular, $\|x_\rho\|^2=\rho(I)=1$.
\end{proof}
The method used to produce a representation from a state, in the proof of Theorem~\ref{C^* cyclic representation for state}, is called the Gelfand-Neumark-Segal construction, or GNS construction, and provides one of the basic tools of $C^*$-algebra theory. The associated notation will be used frequently, sometimes without comment; when $\rho$ is a state of a $C^*$-algebra $\mathfrak{A}$, the symbols $H_\rho$, $\pi_\rho$, and $x_\rho$ always bearthe meaning attached to them in the theorem. In applications, the properties of $H_\rho$, $\pi_\rho$, and $x_\rho$ set out in the theorem are more important than the details of the construction used to produce them. In a sense made precise in the following proposition, the Hilbert space $H_\rho$, the cyclic representation $\pi_\rho$, and the unit cyclic vector $x_\rho$, are (essentially) uniquely determined by the condition $\rho=\omega_{x_\rho}\circ\pi_\rho$.
\begin{proposition}\label{C^* algebra GNS construction unique}
Suppose that $\rho$ is a state of a $C^*$-algebra $\mathfrak{A}$ and $\pi$ is a cyclic representation of $\mathfrak{A}$ on a Hilbert space $H$ such that $\rho=\omega_x\circ\pi$ for some unit cyclic vector $x$ for $\pi$. If $H_\rho$, $\pi_\rho$, and $x_\rho$ are the Hilbert space, cyclic representation, and unit cyclic vector produced from $\rho$ by the GNS construction, there is an isomorphism $U$ from $H_\rho$ onto $H$ such that
\[x=Ux_\rho\And \pi(A)=U\pi_\rho(A)U^*\for A\in\mathfrak{A}.\]
\end{proposition}
\begin{proof}
For each $A\in\mathfrak{A}$,
\[\|\pi(A)x\|^2=\langle\pi(A)x,\pi(A)x\rangle=\langle \pi(A^*A)x,x\rangle=\rho(A^*A)=\langle\pi_\rho(A^*A)x_\rho,x_\rho\rangle=\|\pi_\rho(A)x_\rho\|^2.\]
If $A,B\in\mathfrak{A}$ and $\pi_\rho(A)x_\rho=\pi_\rho(B)x_\rho$, it follows from the above equations (with $A-B$ in place of $A$) that $\pi(A)x=\pi(B)x$. Accordingly, the equation $U_0\pi_\rho(A)x_\rho=\pi(A)x$ defines a norm-preserving linear operator from $\pi_\rho(\mathfrak{A})x_\rho$ onto $\pi(\mathfrak{A})x$. Since $\pi_\rho(\mathfrak{A})x_\rho$ is dense in $H_\rho$ and $\pi(\mathfrak{A})x$ is dense in $H$, $U_0$ extends by continuity to an isomorphism $U$ from $H_\rho$ onto $H$, and
\[Ux_\rho=U_0\pi_\rho(I)x_\rho=\pi(I)x=x.\]
For $A,B\in\mathfrak{A}$, note that
\[U\pi_\rho(A)\pi_\rho(B)x_\rho=U\pi_\rho(AB)x_\rho=\pi(AB)x=\pi(A)\pi(B)x=\pi(A)U\pi_\rho(B)x_\rho.\]
Since vectors of the form $\pi_\rho(B)x_\rho$ form a dense subset of $H_\rho$, it follows that $U\pi_\rho(A)=\pi(A)U$, and thus $\pi(A)=U\pi_\rho(A)U^*$.
\end{proof}
Suppose that $\mathfrak{A}$ is a $C^*$-algebra and that $\pi$ and $\eta$ are representations of $\mathfrak{A}$ on Hilbert spaces $H$ and $K$, respectively. We say that $\pi$ and $\eta$ are (unitarily) equivalent if there is an isomorphism $U$ from $H$ onto $K$ such that $\eta(A)=U\pi(A)U^*$ for each $A\in\mathfrak{A}$. If $\rho$ is a state of $\mathfrak{A}$, $\pi$ is a cyclic representation of $\mathfrak{A}$, and $\rho=\omega_x\circ\pi$ for some unit cyclic vector $x$ for $\pi$, it follows from Proposition~\ref{C^* algebra GNS construction unique} that $\pi$ is equivalent to the representation $\pi$, obtained from $\rho$ by the GNS construction. In addition, the isomorphism $U$ can be chosen so that $Ux_\rho=x$.
\begin{corollary}
If $x$ is a unit vector in a Hilbert space $H$, $\mathfrak{A}$ is a $C^*$-subalgebra of $\mathcal{B}(H)$, and $\rho$ is the vector state $\omega_x|_{\mathfrak{A}}$. Then the representation $\pi_\rho$ obtained from p by the GNS construction is equivalent to the representation $A\mapsto A|_{[\mathfrak{A}x]}$ on the Hilbert space $[\mathfrak{A}x]$. The isomorphism $U:H_\rho\to[\mathfrak{A}x]$ that implements this equivalence can be chosen so that $Ux_\rho=x$.
\end{corollary}
\begin{proof}
This follows from Proposition~\ref{C^* algebra GNS construction unique}, since $x$ is a unit cyclic vector for the representation $\pi:A\mapsto A|_{[\mathfrak{A}x]}$, and $\rho=\omega_x\circ\pi$.
\end{proof}
We prove next that the set of all representations of a $C^*$-algebra $\mathfrak{A}$, obtained from (pure) states of $\mathfrak{A}$ by the GNS construction, is large enough to "separate" the elements of $\mathfrak{A}$.
\begin{proposition}\label{C^* algebra nonzero representation on element}
If $A$ is a non-zero element of a $C^*$-algebra $\mathfrak{A}$, there is a pure state $\rho$ of $\mathfrak{A}$ such that $\pi_\rho(A)\neq 0$, where $\pi_\rho$ is the representation obtained from $\rho$ by the GNS construction.
\end{proposition}
\begin{proof}
By Theorem~\ref{C^* algebra pure state space prop} there is a pure state $\rho$ of $\mathfrak{A}$ such that $\rho(A)\neq 0$, equivalently $\langle\pi_\rho(A)x_\rho,x_\rho\rangle\neq 0$, whence $\pi_\rho(A)\neq 0$.
\end{proof}
In order to complete the proof that every $C^*$-algebra has a faithful representation, we need the concept of a "direct sum" of representations. Suppose that $\mathfrak{A}$ is a $C^*$-algebra, $(H_{s})_{s\in S}$ is a family of Hilbert spaces, and $\pi_s$ is a representation of $\mathfrak{A}$ on $H_s$, for each $s\in S$. For $A\in\mathfrak{A}$, by Proposition~\ref{C^* algebra homomorphism prop} we have $\|\pi_s(A)\|\leq\|A\|$, so the direct sum $\bigoplus_s\pi_s(A)$ is a bounded linear operator acting on the Hilbert space $\bigoplus_sH_s$. From the results set out at the end of the subsection on direct sums, it is apparent that the mapping
\[\pi:\mathfrak{A}\to\mathcal{B}(\bigoplus_sH_s),\quad A\mapsto\bigoplus_s\pi_s(A)\]
is a representation of $\mathfrak{A}$ on $\bigoplus_sH_s$. We call $\pi$ the direct sum of the family $(\pi_s)$ of representations of $\mathfrak{A}$, and write $\pi=\bigoplus_s\pi_s$.
\begin{proposition}\label{C^* algebra representation is sum of cyclic}
If $\pi:\mathfrak{A}\to\mathcal{B}(H)$ is a representation of the $C^*$-algebra $\mathfrak{A}$, then there is a family of cyclic representations $(\pi_s)$ of $\mathfrak{A}$ such that $\pi$ and $\bigoplus_s\pi_s$ are equivalent.
\end{proposition}
\begin{proof}
let $\mathscr{E}$ be the collection of all subsets $E$ of nonzero vectors in $H$ such that $\pi(\mathfrak{A})e\bot\pi(\mathfrak{A})f$ for $e,f\in E$ with $e\neq f$. Order $\mathscr{E}$ by inclusion. An application of Zorn's Lemma implies that $\mathscr{E}$ has a maximal element $E_0$. Let $H_0=\bigoplus_{e\in E_0}[\pi(\mathfrak{A})e]$. If $h\in H\cap H_0^\bot$, then $\langle\pi(A)e,h\rangle=0$ for every $A$ in $\mathfrak{A}$ and $e\in E_0$. So if $A,B\in\mathfrak{A}$ and $e\in E_0$,
\[0=\pi(B^*A)e,h\rangle=\langle\pi(A)e,\pi(B)h\rangle.\]
That is, $\pi(A)e\bot\pi(A)h$ for all $e$ in $E_0$. Hence $E_0\cup\{h\}\in\mathscr{E}$; by the maximality of $E_0$ it must be that $h=0$.  Therefore $H=H_0$.\par
For $e\in E_0$ let $H_e=[\pi(\mathfrak{A})e]$. Clearly $H_e$ is invariant for each $A\in\mathfrak{A}$, so $H_e$ reduces $\pi(A)$ for each $A\in\mathfrak{A}$. If $\pi_e:\mathfrak{A}\to\mathcal{B}(H_e)$ is defined by $\pi_e(A)=\pi(A)|_{H_e}$, then $\pi_e$ is a representation of $\mathfrak{A}$ and $\pi=\bigoplus_{e\in E_0}\pi_e$.
\end{proof}
\begin{theorem}[\textbf{Gelfand-Neumark theorem}]
Each $C^*$-algebra has a faithful representation.
\end{theorem}
\begin{proof}
With $\mathfrak{A}$ a $C^*$-algebra, let $\mathcal{S}_0$ be any family of states of $\mathfrak{A}$ that contains all the pure states. Let $\pi$ be the direct sum of the family $\{\pi_\rho:\rho\in\mathcal{S}_0\}$ where $\pi_\rho$, is the representation obtained from $\rho$ by the GNS construction. If $A\in\mathfrak{A}$ and $\pi(A)=0$, then $\pi_\rho(A)=0$ for all $r\rho\in\mathcal{S}_0$; in particular, $\pi_\rho(A)=0$ for each pure state $\rho$ of $\mathfrak{A}$, and $A=0$ by Proposition~\ref{C^* algebra nonzero representation on element}. Hence $\pi$ is a faithful representation of $\mathfrak{A}$.
\end{proof}
\begin{remark}
If $\pi$ is a faithful representation of a $C^*$-algebra $\mathfrak{A}$ on a Hilbert space $H$, then $\pi$ is isometric and $\pi(\mathfrak{A})$ is a $C^*$-subalgebra of $\mathcal{B}(H)$, by Proposition~\ref{C^* algebra homomorphism prop}. Accordingly, the Gelfand-Neumark theorem can be restated as follows: if $\mathfrak{A}$ is a $C^*$-algebra, there is a Hilbert space $H$ such that $\mathfrak{A}$ is $*$-isomorphic to a $C^*$-subalgebra of $\mathcal{B}(H)$.
\end{remark}
\section{Normal operators on Hilbert space}
In this section the spectral theorem for normal operators on a Hilbert space is proved. This theorem is then used to answer a number of questions concerning normal operators. In fact, the Spectral Theorem can be used to answer essentially every question about normal operators.
\subsection{Strong and weak topology on \boldmath$\mathcal{B}(H)$}
In this part we explore some properties of the weak and strong operator topologies for $\mathcal{B}(H)$. Although these results are stated for Hilbert spaces, most of them hold also for Banach spaces, with appropriate modifications.
\begin{definition}
If $H$ is a Hilbert space, the \textbf{weak operator topology} on $\mathcal{B}(H)$ is the locally convex topology defined by the seminorms $\{p_{x,y}(A):x,y\in H\}$ where $p_{x,y}(A)=|\langle Ax,y\rangle|$. The \textbf{strong operator topology} is the topology defined on $\mathcal{B}(H)$ by the family of seminorms $\{p_x:x\in X\}$ where $p_x(A)=\|Ax\|$.
\end{definition}
Let $(A_\alpha)$ be a net in $\mathcal{B}(H)$. We say $A_\alpha$ converges weakly if it converges in the weak operator topology, \textbf{strongly} if in the strong operator topology, and \textbf{uniformly} if in the norm topology.
\begin{proposition}
Let $H$ be a Hilbert space and let $(A_\alpha)$ be a net in $\mathcal{B}(H)$.
\begin{itemize}
\item[(a)] $A_\alpha\to A$ weakly if and only if $\langle A_\alpha x,y\rangle\to\langle Ax,y\rangle$ for all $x,y\in H$.
\item[(b)] If $\sup_\alpha\|A_\alpha\|<+\infty$ and $S$ is a total subset of $H$, then $A_\alpha\to A$ if and only if $\langle A_\alpha x,y\rangle\to\langle Ax,y\rangle$ for all $x,y\in S$.
\item[(c)] $A_\alpha\to A$ strongly if and only if $\|A_\alpha x-Ax\|\to 0$ for all $x\in H$.
\item[(d)] If $\sup_\alpha\|A_\alpha\|<+\infty$ and $S$ is a total subset of $H$, then $A_\alpha\to A$ if and only if $\|A_\alpha x-Ax\|\to 0$ for all $x\in S$.
\item[(e)] If $H$ is separable, then the weakly operator topology and the strong operator topology are metrizable on bounded subsets of $\mathcal{B}(H)$.
\end{itemize}
\end{proposition}
\begin{proof}
The first four claims are clear, part (e) follows from (b,d) and the observation that if $H$ is separable, then $H$ has a countable total subset.
\end{proof}
\begin{proposition}\label{Hilbert space dual of B(H) strong and weak}
If $\varphi:\mathcal{B}(H)\to\C$ is a linear functional, then the following statements are equivalent.
\begin{itemize}
\item[(\rmnum{1})] $\varphi$ is strongly continuous. 
\item[(\rmnum{2})] $\varphi$ is weakly continuous.
\item[(\rmnum{3})] There are vectorsg $x_1,\dots,x_n$ and $y_1,\dots,y_n$ in $H$ such that $\varphi(A)=\sum_{i=1}^{n}\langle Ax_i,y_i\rangle$ for every $A\in\mathcal{B}(H)$. 
\end{itemize}
\end{proposition}
\begin{proof}
Clearly (c) implies (b) and (b) implies (a). So assume (a). By Proposition~\ref{LCS by seminorm continuous iff} there are vectors $x_1,\dots,x_n\in H$ such that
\[|\varphi(A)|\leq\sum_{i=1}^{n}\|Ax_i\|\leq\sqrt{n}\Big(\sum_{i=1}^{n}\|Ax_i\|^2\Big)^{1/2}.\]
for every $A\in\mathcal{B}(H)$. Replacing $x_i$ by $\sqrt{n}x_i$, it may be assumed that
\[|\varphi(A)|\leq\sum_{i=1}^{n}\|Ax_i\|\leq\Big(\sum_{i=1}^{n}\|Ax_i\|^2\Big)^{1/2}=:p(A).\]
Now $p$ is a seminorm and $p(A)=0$ implies $\varphi(A)=0$. Let $K$ be the closure of $\{Ax_1\oplus Ax_2\oplus\cdots\oplus Ax_n:A\in\mathcal{B}(H)\}$, so $K\sub H^{(n)}$. Note that if $Ax_1\oplus\cdots\oplus Ax_n=0$, then $p(A)=0$ and hence $\varphi(A)=0$. Thus $\Phi(Ax_1\oplus\cdots\oplus Ax_n)=\varphi(A)$ is a well-defined linear functional on a dense subspace of $K$. But
\[|\Phi(Ax_1\oplus\cdots\oplus Ax_n)|=|\varphi(A)|\leq p(A)=\|Ax_1\oplus\cdots\oplus Ax_n\|,\]
so $\Phi$ can be extended to a bounded linear functional $\Phi_1$ on $H^{(n)}$. Hence by Reisz representation theorem there are vectors $y_1,\dots,y_n$ in $H$ such that
\[\Phi_1(h_1\oplus\dots\oplus h_n)=\langle h_1\oplus\cdots\oplus h_n,y_1\oplus\cdots\oplus y_n\rangle=\sum_{i=1}^{n}\langle h_i,y_i\rangle.\]
In particular, $\varphi(A)=\Phi(Ax_1\oplus\cdots\oplus Ax_n)=\sum_{i=1}^{n}\langle Ax_i,y_i\rangle$.
\end{proof}
\begin{corollary}
If $\mathscr{C}$ is a convex subset of $\mathcal{B}(H)$, then the weakly closure of $\mathscr{C}$ equals the strong closure of $\mathcal{B}(H)$.
\end{corollary}
When discussing the closure of a convex set it is usually better to discuss the strong one. Shortly an "algebraic" characterization of the strong closure of a subalgebra of $\mathcal{B}(H)$ will be given. But first recall that if $1\leq n\leq\infty$, $\mathcal{H}^{(n)}$ denotes the direct sum of $H$ with itself $n$ times. If $A\in\mathcal{B}(H)$, $A^{(n)}$ is the operator on $H^{(n)}$ defined by $A^{(n)}(x_1,\dots,x_n)=(Ax_1,\dots,Ax_n)$. If $\mathscr{S}\sub\mathcal{B}(H)$, $\mathscr{S}^{(n)}=\{A^{(n)}:A\in\mathscr{S}\}$. It is rather interesting that the strong closure of an algebra can be characterized using its lattice of invariant subspaces.
\begin{proposition}\label{Hilbert space subalgebra closure by invariant space}
If $\mathfrak{A}$ is a subalgebra of $\mathcal{B}(H)$ containing $I$, then the strong closure of $\mathfrak{A}$ is
\[\{B\in\mathcal{B}(H):\text{for every finite $n$, $\Lat(\mathfrak{A}^{(n)})\sub\Lat(B^{(n)})$}\}.\]
\end{proposition}
\begin{proof}
Assume that $B\in\mathrm{cl}_{s}\mathfrak{A}$, and let $x_1\oplus\cdots\oplus x_n\in\Lat(\mathfrak{A}^{(n)})$. Then for any $\eps>0$, there exists $A_1,\dots,A_n$ such that $\|A_ix_i-Bx_i\|<\eps$. But $A_ix_i\in\Lat(\mathfrak{A})$, so since $\Lat(\mathfrak{A})$ is closed, we see $Bx_i\in\Lat(\mathfrak{A})$ for each $i$, and $x_1\oplus\cdots\oplus x_n\in\Lat(B^{(n)})$. This proves $\Lat(\mathfrak{A}^{(n)})\sub\Lat(B^{(n)})$.\par
Conversely, assume that $B$ belongs to the set above. Fix $x_1,\dots,x_n\in H$ and $\eps>0$. It must be shown that there is $A\in\mathfrak{A}$ such that $\|(A-B)x_i\|<\eps$ for $1\leq i\leq n$.\par
Let $M=\bigvee\{Ax_1\oplus\dots\oplus Ax_n:A\in\mathfrak{A}\}\sub H^{(n)}$. Since $\mathfrak{A}$ is an algebra, $M\in\Lat(\mathfrak{A}^{(n)})\sub\Lat(B^{(n)})$. Because $I\in\mathfrak{A}$, $x_1\oplus\cdots\oplus x_n\in M$. Since $\{Ax_1\oplus\cdots\oplus Ax_n:A\in\mathfrak{A}\}$ is a dense subspace and $Bx_1\oplus\cdots\oplus Bx_n\in M$, there is $A\in\mathfrak{A}$ with $\sum_{i=1}^{n}\|(A-B)x_i\|^2<\eps^2$; hence $B\in\mathrm{cl}_s\mathfrak{A}$.
\end{proof}
\begin{proposition}
The closed unit ball of $\mathcal{B}(H)$ is weakly compact.
\end{proposition}
\begin{proof}
Endow $H$ with the weak topology, so that the unit ball of $H$ is compact ($H$ is reflexive). For each $x\in H$ let $D_x=\{y\in H:\|y\|\leq\|x\|\}$, and let $D=\prod_{x\in H}D_x$. Endow $D$ with the product topology, then $D$ is compact by Tychonoff's theorem. The elements of $D$ are precisely those maps $A$ from $H$ to $H$ such that $\|Ax\|\leq\|x\|$, and $B_{\mathcal{B}(H)}$ consists of those elements of $D$ that are linear.
Moreover, the relative topologies that $B_{\mathcal{B}(H)}$ inherits from the product topology on $D$ and the weak operator topology on $\mathcal{B}(H)$ both coincide with the topology of pointwise convergence, so it suffices to see that $B_{\mathcal{B}(H)}$ is closed in $D$. But this is easy, since linearity is preserved under limits.
\end{proof}
\begin{proposition}\label{Hilbert space weakly convergent operator bounded}
If $\{A_\alpha\}$ is weakly convergent net in $\mathcal{B}(H)$, then $\sup_\alpha\|A_\alpha\|<+\infty$. 
\end{proposition}
\begin{proof}
Assume that $A_\alpha\to A$ weakly. Then for every $x,y\in H$, we have $\langle A_\alpha x,y\rangle\to\langle Ax,y\rangle$. Thus the net $\{A_\alpha x\}$ is weakly-bounded in $H$, hence bounded in $H$. By the uniform boundedness principle, we see $\{A_\alpha\}$ is bounded in the norm topology.
\end{proof}
\begin{proposition}\label{Hilbert space continuity of composition}
Let $\{A_\alpha\}$ and $\{B_\alpha\}$ be nets in $\mathcal{B}(H)$.
\begin{itemize}
\item[(a)] If $A_\alpha\to A$ weakly and $B_\alpha\to B$ strongly, then $A_\alpha B_\alpha\to AB$ weakly.
\item[(b)] If $A_\alpha\to A$ strongly and $B_\alpha\to B$ strongly, then $A_\alpha B_\alpha\to AB$ strongly.
\end{itemize}
\end{proposition}
\begin{proof}
Assume the conditions in (a). Then for $x,y\in H$,
\[\langle (A_\alpha B_\alpha-AB)x,y\rangle=\langle A_\alpha(B_\alpha-B)x,y\rangle+\langle (A_\alpha-A)Bx,y\rangle.\]
Since $A_\alpha\to A$ weakly, the second sum tends to $0$. Since $B_\alpha\to B$ strongly, we have
\[|\langle A_\alpha(B_\alpha-B)x,y\rangle|\leq\|A_\alpha\|\|B_\alpha-B\|\|x\|\|y\|.\]
Since $A_\alpha\to A$ weakly, $\|A_\alpha\|$ is uniformly bounded, so it follows that the first sum tends to zero and claim (a) follows.\par
Now assume that $A_\alpha\to A$ strongly and $B_\alpha\to B$ strongly, then
\[\|(A_\alpha B_\alpha-AB)x\|\leq\|A_\alpha(B_\alpha-B)x\|+\|(A_\alpha-A)Bx\|.\]
Similar to the argument above, we see $\|(A_\alpha B_\alpha-AB)x\|\to 0$, so claim (b) follows.
\end{proof}
\begin{example}
Let $(X,\mathfrak{A},\mu)$ be a $\sigma$-finite measure space. If $\phi\in L^\infty(\mu)$, let $M_\phi$ be the multiplication operator on $L^2(\mu)$. Then a net $\{\phi_\alpha\}$ converges weak$^*$ to $\phi$ if and only if $M_{\phi_\alpha}\to M_\phi$. In fact, if $f,g\in L^2(\mu)$ and $\phi_\alpha\to\phi$ weak$^*$ in $L^\infty(\mu)$, then 
\[\langle M_{\phi_\alpha}f,g\rangle=\int\phi_\alpha f\bar{g}\,d\mu\to\int\phi f\bar{g}\,d\mu=\langle M_\phi f,g\rangle\]
since $f\bar{g}\in L^1(\mu)$. Conversely, if $M_{\phi_\alpha}\to M_\phi$ weakly and $f\in L^1(\mu)$, then $f=|f|e^{i\theta}$, where $\theta$ is a measurable function. Define
\[g=|f|^{1/2}e^{i\theta},\quad h=|f|^{1/2}.\]
Then $g,h\in L^2(\mu)$ and $f=gh$. Thus we have 
\[\int\phi_\alpha f\,d\mu=\int\phi_\alpha gh\,d\mu=\langle M_{\phi_\alpha}g,\bar{h}\rangle\to\langle M_{\phi}g,\bar{h}\rangle=\int\phi f\,d\mu,\]
which implies that $\phi_\alpha$ converges weak$^*$ to $\phi$ .
\end{example}
\subsection{Spectral measure and representations of abelian \boldmath$C^*$-algebras}
In this part we want to focus our attention on representations of abelian $C^*$-algebras. The reason for this is that the spectral theorem and its generalizations can be obtained as a special case of such a theory. The idea is the following. Let $N$ be a normal operator on $H$. Then $C^*(N)$ is an abelian $C^*$-algebra and the functional calculus $f\mapsto f(N)$ is a $*$-isomorphism of $C(\sigma(N))$ onto $C^*(N)$. Thus $f\mapsto f(N)$ is a representation $C(\sigma(N))\to\mathcal{B}(H)$ of the abelian $C^*$-algebra $C(\sigma(N))$. A diagnosis of such representations yields the spectral theorem.\par
A representation $\pi:C(X)\to\mathcal{B}(H)$ is a $*$-homomorphism with $\pi(1)=I$. Also, $\|\pi\|=1$. If $f\in C(X)^+$, then $f=g^2$ where $g\in C(X)^+$; hence $\pi(f)=\pi(g)^2=\pi(g)^*\pi(g)\geq 0$. So $\pi$ is a positive map. One might expect, by analogy with the Riesz representation theorem, that $\pi(f)=\int f\,dE$ for some type of measure $E$ whose values are operators rather than scalars. This is indeed the case. We begin by introducing these measures and defining the integral of a scalar-valued function with respect to one of them.
\begin{definition}
If $X$ is a set, $\mathcal{A}$ is a $\sigma$-algebra of subsets of $X$, and $H$ is a Hilbert space, a spectral measure for $(X,\mathcal{A},H)$ is a function $E:\mathcal{A}\to\mathcal{B}(H)$ such that:
\begin{itemize}
\item[(a)] for each $\Delta\in\mathcal{A}$, $E(\Delta)$ is a projection;
\item[(b)] $E(\emp)=0$ and $E(X)=1$;
\item[(c)] $E(\Delta_1\cap\Delta_2)=E(\Delta_1)E(\Delta_2)$ for $\Delta_1,\Delta_2\in\mathfrak{A}$;
\item[(d)] if $\{\Delta_n\}$ are pairwise disjoint sets from $\mathcal{A}$, then
\[E\Big(\bigcup_{n=1}^{\infty}\Delta_n\Big)=\sum_{n=1}^{\infty}E(\Delta_n).\] 
\end{itemize}
\end{definition}
A word or two concerning condition (d) in the preceding definition. If $\{E_n\}$ is a sequence of pairwise orthogonal projections on $H$, then it was shown in Proposition~\ref{Hilbert space union of orthogonal projections} that for each $x\in H$, $\sum_nE_nx$ converges in $H$ to $Ex$, where $E$ is the orthogonal projection of $H$ onto $\bigvee\{E_n(H)\}$. Thus it is legitimate to write $E=\sum_nE_n$. Now if $\Delta_1\cap\Delta_2=\emp$, then (b) and (c) above imply that $E(\Delta_1)E(\Delta_2)=E(\Delta_2)E(\Delta_1)=0$ that is, $E(\Delta_1)$ and $E(\Delta_2)$ have orthogonal ranges. So if $\{\Delta_n\}$ is a sequence of pairwise disjoint sets in $\mathcal{A}$, the ranges of $\{E(\Delta_n)\}$ are pairwise orthogonal. Thus the equation in (d) has the precise meaning just discussed.
\begin{example}
If $\{E_n\}$ is a sequence of pairwise orthogonal projections on $H$, then $\sum_nE_n$ converges strongly to the projection of $H$ onto $\bigvee\{E_n(H)\}$. In light of this, a spectral measure for $(X,\mathcal{A},H)$ could be defined as a strongly countably additive projection-valued measure.
\end{example}
\begin{example}
Let $X$ be a compact topological space, $\mathcal{A}=\mathcal{B}(X)$, $\mu$ be a measure on $X$ and $H=L^2(\mu)$. For $\Delta\in\mathcal{A}$, let $\nu(\Delta)=M_{\chi_\Delta}$. Then $\nu$ is a spectral measure for $(X,\mathcal{A},L^2(\mu))$.
\end{example}
The next lemma is useful in studying spectral measures as it allows us to prove things about spectral measures from known facts about complex-valued measures.
\begin{lemma}\label{Hilbert space spectral measure to measure}
If $E$ is a spectral measure for $(X,\mathcal{A},\mu)$ and $x,y\in H$, then
\[E_{x,y}(\Delta)=\langle E(\Delta)x,y\rangle\]
defines a measure on $\mathcal{A}$ with $\|E_{x,y}\|\leq\|x\|\|y\|$.
\end{lemma}
\begin{proof}
It is easy to see $\mu=E_{x,y}$ is a measure on $X$. If $\Delta_1,\dots,\Delta_n$ are pairwise disjoint sets in $\mathcal{A}$, let $\alpha_i\in\C$ such that $|\alpha_i|=1$ and $|\langle E(\Delta_i)x,y\rangle|=\alpha_i\langle E(\Delta_i)x,y\rangle$. Then
\[\sum_i|\mu(\Delta_i)|=\sum_i|\langle E(\Delta_i)x,y\rangle|=\langle\sum_i\alpha_iE(\Delta_i)x,y\rangle\leq\|\sum_i\alpha_iE(\Delta_i)x\|\|y\|.\]
Now $\{\alpha_iE(\Delta_i)x:1\leq i\leq n\}$ is a finite sequence of pairwise orthogonal vectors so that
\[\|\sum_i\alpha_iE(\Delta_i)x\|^2=\sum_i\|E(\Delta_i)x\|^2=\|E(\bigcup_{i=1}^{n}\Delta_i)x\|^2\leq\|x\|^2.\]
This implies $|\sum_i\mu_i(\Delta_i)|\leq\|x\|\|y\|$, so that $\|\mu\|\leq\|x\|\|y\|$.
\end{proof}
Given a spectral measure $E$ on $(X,\mathcal{A})$, we want to define integrals for bounded measurable functions on $X$. Let $f:X\to\C$ be a bounded $\mathcal{A}$-measurable function, and let $\{\phi_n\}$ be a sequence of simple functions such that $\phi_n\to f$. For $x,y\in H$, we define $B(x,y)=\int f\,dE_{x,y}$. By the precedding lemma, $|B(x,y)|\leq\|f\|_\infty\|x\|\|y\|$, so there is a unique operator $A$ on $H$ such that $B(x,y)=\langle Ax,y\rangle$. We set $\int_Xf\,dE:=A$. Therefore if $x,y\in H$ and $f$ is a bounded $\mathcal{A}$-measurable function on $X$, this definition implies that
\[\langle\Big(\int_Xf\,dE\Big)x,y\rangle=\int_Xf\,dE_{x,y}.\]
Now let $\{\phi_n\}$ be a sequence of simple functions that converges to $f$ uniformly on $X$. Then since $E_{x,y}$ is a measure on $X$, we have
\[\Big|\int_Xf\,dE_{x,y}-\int_X\phi_n\,dE_{x,y}\Big|\to 0.\]
It then follows that $\int_X\phi_n\,dE$ converges to $\int_Xf\,dE$ weakly in $\mathcal{B}(H)$. But $\int_X\phi_n$ and $\int_Xf\,dE$ are Hermitian operator (Proposition~\ref{Hilbert space Hermitian operator norm by inner product}), so this implies $\int_X\phi_n\to\int_Xf$ uniformly on $H$, as we may expected.\par
Let $B(X,\mathcal{A})$ denote the set of bounded $\mathcal{A}$-measurable functions on $X$ with supremum norm. It is easy to see that $B(X,\mathcal{A})$ is a Banach algebra with identity. In fact, if $f^*(x):=\widebar{f(x)}$, then $B(X,\mathcal{A})$ is an abelian $C^*$-algebra. The properties of the integral $\int f\,dE$ are summarized by the following result.
\begin{proposition}\label{Hilbert space spectral integration prop}
If $E$ is a spectral measure for $(X,\mathcal{A},H)$ and $\pi:B(X,\mathcal{A})\to\mathcal{B}(H)$ is defined by $\pi(f)=\int_Xf\,dE$, then $\pi$ is representation of $B(X,\mathcal{A})$ and $\pi(f)$ is a normal operator for every $f\in\mathcal{B}(X,\mathcal{A})$.
\end{proposition}
\begin{proof}
It will only be shown that $\pi$ is multiplicative. Let $\Delta_1,\Delta_2\in\mathcal{A}$. Then the propoties of $E$ yields
\begin{align*}
\Big(\int_X\chi_{\Delta_1}\,dE\big)\Big(\int_X\chi_{\Delta_2}\,dE\Big)&=E(\Delta_1)E(\Delta_2)=E(\Delta_1\cap\Delta_2)\\
&=\int_X\chi_{\Delta_1\cap\Delta_2}\,dE=\int_X\chi_{\Delta_1}\chi_{\Delta_2}\,dE.
\end{align*}
The general case can be obtained by taking limits.
\end{proof}
\begin{corollary}
If $X$ is a compact Hausdroff space and $E$ is a spectral measure defined on the Borel subsets of $X$, then $\pi:C(X)\to\mathcal{B}(H)$ defined by $\pi(f)=\int f\,dE$ is a representation of $C(X)$.
\end{corollary}
The next result is the main result of this part and it states that the converse to the preceding corollary holds.
\begin{theorem}\label{Riesz representation on Hilbert space for C(X)}
Let $X$ be a compact Hausdorff space. If $\pi:C(X)\to\mathcal{B}(H)$ is a representation, there is a unique spectral measure $E$ defined on the Borel subsets of $X$ such that for all $x,y\in H$, $E_{x,y}$ is a Radon measure and
\[\pi(f)=\int_Xf\,dE\]
for every $f\in C(X)$.
\end{theorem}
\begin{proof}
The idea of the proof is similar to the idea of the proof of the Riesz representation theorem for linear functionals on $C(X)$. We wish to extend $\pi$ to a representation $\widetilde{\pi}:B(X)\to\mathcal{B}(H)$, where $B(X)$ is the $C^*$-algebra of bounded Borel functions. The measure $E$ of a Borel set $\Delta$ is then defined by letting $E(\Delta)=\widetilde{\pi}(\chi_\Delta)$. In fact, it is possible to give a proof of the theorem patterned on the proof of the Riesz representation theorem. Here, however, the proof will use the Riesz representation theorem to simplify the technical details.\par
If $x,y\in H$, then $f\mapsto\langle\pi(f)x,y\rangle$ is a linear functional on $C(X)$ with norm smaller than $\|x\|\|y\|$. Hence there is a unique measure $\mu_{x,y}$ in $M(X)$ such that
\[\langle\pi(f)x,y\rangle=\int_Xf\,d\mu_{x,y}.\]
for all $f\in C(X)$. It is easy to verify that the map $(x,y)\mapsto\mu_{x,y}$ is sesquilinear (use uniqueness) and $\|\mu_{x,y}\|\leq\|x\|\|y\|$. Now fix $f\in B(X)$ and define
\[\langle x,y\rangle_f=\int_Xf\,d\mu_{x,y}.\]
Then $\langle\cdot,\cdot\rangle_f$ is a sesquilinear form and $|\langle x,y\rangle_f|\leq\|f\|\|x\|\|y\|$. Hence there is a unique bounded operator $A$ such that $\langle x,y\rangle_f=\langle Ax,y\rangle$ and $\|A\|\leq\|f\|$. Denote the operator $A$ by $\widetilde{\pi}(f)$. Then $\widetilde{\pi}$ is a well-defined function, $\|\widetilde{\pi}(f)\|\leq\|f\|$, and for all $x,y\in H$,
\begin{align}\label{Hilbert space representation for C(X)-1}
\langle\widetilde{\pi}(f)x,y\rangle=\int f\,d\mu_{x,y}.
\end{align}
We now claim that $\widetilde{\pi}$ is a representation extending $\pi$. The second claim is clear from definition. If $f\in B(X)$, consider $f$ as an element of $M(X)^*$; that is, $f$ corresponds to the linear functional $\mu\mapsto\int f\,d\mu$. We may assume that $\|f\|=1$. By Proposition~\ref{NVS weak topo dense in bidual}, the set $B_{C(X)}$ is weak$^*$ dense in $B_{M(X)^*}$. Thus there is a net $\{\phi_\alpha\}$ in $C(X)$ such that $\|\phi_\alpha\|\leq 1$ and $\int\phi_\alpha\,d\mu\to\int f\,d\mu$ for every $\mu$ in $M(X)$. If $g\in B(X)$, then the measure $\nu$ defined by $d\nu=g\,d\mu$ is in $M(X)$ whenever $\mu\in M(X)$, thus
\[\int\phi_\alpha g\,d\mu\to\int fg\,d\mu\]
for every $g\in B(X)$ and $\mu\in M(X)$. By $(\ref{Hilbert space representation for C(X)-1})$, $\widetilde{\pi}(\phi_\alpha g)\to\widetilde{\pi}(fg)$ weakly in $\mathcal{B}(H)$ for every $g\in B(X)$. In particular, if $g\in C(X)$, then in the weak operator topology we have
\[\widetilde{\pi}(fg)=\lim_\alpha\widetilde{\pi}(\phi_\alpha g)=\lim_\alpha\pi(\phi_\alpha)\pi(g)=\widetilde{\pi}(f)\pi(g).\]
That is, $\widetilde{\pi}(fg)=\widetilde{\pi}(f)\widetilde{\pi}(g)$ whenever $f\in B(X)$ and $g\in C(X)$. With a similar process, we see $\widetilde{\pi}$ is a representation.\par
It is claer that $\widetilde{\pi}$ is linear. To see that $\widetilde{\pi}(\bar{f})=\widetilde{\pi}(f)^*$, let $\{\phi_\alpha\}$ be the net obtained in the preceding paragraph. If $\mu\in M(X)$, let $\bar{\mu}$ be the measure defined by $\bar{\mu}(\Delta)=\widebar{\mu(\Delta)}$. Then $\pi(\phi_\alpha)\to\widetilde{\pi}(f)$ weakly and so $\pi(\phi_\alpha)^*\to\widetilde{\pi}(f)^*$. But for every measure $\mu\in M(X)$,
\[\int\bar{\phi}_\alpha\,d\mu=\widebar{\int\phi_\alpha\,d\bar{\mu}}\to\widebar{\int f\,d\bar{\mu}}=\int\bar{\phi}\,d\mu,\]
hence $\pi(\bar{\phi}_\alpha)\to\widetilde{\pi}(\bar{f})$. Since $\pi$ is a $*$-homomorphism, so is $\widetilde{\pi}$.\par
For any Borel subset $\Delta$ of $X$ let $E(\Delta)=\widetilde{\pi}(\chi_\Delta)$. We want to show that $E$ is a spectral measure. Since $\chi_\Delta$ is a Hermitian idempotent in $B(X)$, $E(\Delta)$ is a projection by Proposition~\ref{Hilbert space idempotent is projection iff}. Since $\chi_\emp=0$ and $\chi_X=1$, we have $E(\emp)=0$ and $E(X)=1$. Also,
\[E(\Delta_1)E(\Delta_2)=\widetilde{\pi}(\chi_{\Delta_1})\widetilde{\pi}(\chi_{\Delta_2})=\widetilde{\pi}(\chi_{\Delta_1}\chi_{\Delta_2})=\widetilde{\pi}(\chi_{\Delta_1\cap\Delta_2})=E(\Delta_1\cap\Delta_2).\]
Now let $\{\Delta_n\}$ be a pairwise disjoint sequence of Borel sets and put $\Gamma_n=\bigcup_{k=n+1}^{\infty}\Delta_k$. It is easy to see that $E$ is finitely additive so if $x\in H$, then
\begin{align*}
\Big\|E\Big(\bigcup_{k=1}^{\infty}\Delta_k\Big)x-\sum_{k=1}^{n}E(\Delta_k)x\Big\|^2&=\langle E(\Gamma_n)x,E(\Gamma_n)x\rangle=\langle E(\Gamma_n)x,x\rangle\\
&=\int\widetilde{\pi}(\chi_{\Gamma_n})\,d\mu_{x,x}=\sum_{k=n+1}^{\infty}\mu_{x,x}(\Delta_k)\to 0.
\end{align*}
Therefore $E$ is a spectral measure.\par
It remains to show that $\rho(f)=\int f\,dE$. Let $f$ be a simple function $f=\sum_{i=1}^{n}a_i\chi_{\Delta_i}$, then
\begin{align*}
\int f\,dE=\sum_{i=1}^{n}a_iE(\Delta_i)=\sum_{i=1}^{n}a_i\widetilde{\pi}(\chi_{\Delta_i})=\widetilde{\pi}(f).
\end{align*}
The general case follows from the continuity of $\widetilde{\pi}(f)$ and the integral. Since an operator $A$ in $\mathcal{B}(H)$ is uniquely determined by $\langle Ax,y\rangle$ for all $x,y\in H$, the uniqueness of $E$ follows from that of the measures $\mu_{x,y}$. This completes the proof.
\end{proof}
\subsection{The spectral theorem}
The spectral theorem is a landmark in the theory of operators on a Hilbert space. It provides a complete statement about the nature and structure of normal operators. This accolade will be seen to be deserved when the spectral theorem is used to give a complete set of unitary invariants.
\begin{theorem}[\textbf{Spectral Theorem}]
If $N$ is a normal operator, there is a unique spectral measure $E$ on the Borel subsets of $\sigma(N)$ such that:
\begin{itemize}
\item[(a)] $N=\int z\,dE(z)$;
\item[(b)] if $U$ is a nonempty relatively open subset of $\sigma(N)$, then $E(U)\neq 0$. 
\item[(c)] if $A\in\mathcal{B}(H)$, then $AN=NA$ and $AN^*=N^*A$ if and only if $AE(\Delta)=E(\Delta)A$ for every Borel subset $\Delta$.
\end{itemize}
\end{theorem}
\begin{proof}
Let $\mathfrak{A}=C^*(N)$, the $C^*$-algebra generated by $N$. So $\mathfrak{A}$ is the closure of all polynomials in $N$ and $N^*$. By Theorem~\ref{C^* algebra generator spectrum isomorphic}, there is an isometric isomorphism $\rho:C(\sigma(N))\to\mathfrak{A}\sub\mathcal{B}(H)$ given by $\rho(f)=f(N)$ (the functional calculus). By Theorem~\ref{Riesz representation on Hilbert space for C(X)} there is a unique spectral measure $E$ defined on the Borel subsets of $\sigma(N)$ such that $\rho(f)=\int f\,dE$ for all $f\in C(\sigma(N))$. In particular, (a) holds since $N=\rho(z)$.\par
If $U$ is a nonempty relatively open subset of $\sigma(N)$, there is a nonzero continuous function $f$ on $\sigma(N)$ such that $0\leq f\leq\chi_U$. Using Theorem~\ref{Riesz representation on Hilbert space for C(X)}, one obtains that $E(U)=\widetilde{\rho}(\chi_U)\geq\rho(f)\neq 0$; so (b) holds.\par
Now let $A\in\mathcal{B}(H)$ such that $AN=NA$ and $AN^*=N^*A$. It is not hard to see that this implies, by the Stone-Weierstrass Theorem, that $A\rho(f)=\rho(f)A$ for every $f$ in $C(\sigma(N))$; that is, $Af(N)=f(N)A$ for all $f$ in $C(\sigma(N))$. Set
\[\mathcal{B}=\{A\sub\sigma(N):\text{$A$ is a Borel set and $AE(\Delta)=E(\Delta)A$}\}.\]
It is easy to see that $\mathcal{B}$ is a $\sigma$-algebra. If $U$ is an open set in $\sigma(N)$, there is a sequence $\{\phi_n\}$ of positive continuous functions on $\sigma(N)$ such that $\phi_n(z)$ increases to $\chi_U(z)$ for all $z$. Thus
\begin{align*}
\langle AE(U)x,y\rangle&=\langle E(U)x,A^*y\rangle=E_{x,A^*y}(U)\\
&=\lim_{n\to+\infty}\int\phi_n\,dE_{x,A^*y}=\lim_{n\to+\infty}\langle\phi_n(N)x,A^*y\rangle\\
&=\lim_{n\to+\infty}\langle A\phi_n(N)x,y\rangle=\lim_{n\to+\infty}\langle\phi_n(N)Ax,y\rangle=\langle E(U)Ax,y\rangle.
\end{align*}
So $\mathcal{B}$ contains every open set and, hence, it must be the collection of Borel sets. Conversely, if $AE(\Delta)=E(\Delta)A$ for every $\Delta$, then by approximating measruable functions by simple functions, we see $A(\int f\,dE)=(\int f\,dE)A$ for all $f\in B(\sigma(N))$. In particular, $AN=NA$ and $AN^*=N^*A$.
\end{proof}
The unique spectral measure $E$ obtained in the spectral theorem is called the \textbf{spectral measure for $\bm{N}$}. An abbreviation for the spectral theorem is to say, "Let $N=\int zdE(z)$ be the \textbf{spectral decomposition} of $N$". If $f$ is a bounded Borel function on $\sigma(N)$, define $f(N)$ by
\[f(N)=\int f\,dE,\]
where $E$ is the spectral measure for $N$. By Theorem~\ref{C^* algebra generator spectrum isomorphic}, we have $\|f(N)\|=\|f\|_\infty$ for each $f\in C(\sigma(N))$.
\begin{proposition}\label{Hilbert space Borel function calculus unique}
If $N$ is a normal operator on $H$ with spectral measure $E$ and $B(\sigma(N))$ is the $C^*$-algebra of bounded Borel functions on $\sigma(N)$, then the map
\[f\mapsto f(N)\]
is a representation of the $C^*$-algebra $B(\sigma(N))$. If $\{\phi_\alpha\}$ is a net in $B(\sigma(N))$ such that $\int\phi_\alpha\,d\mu\to 0$ for every $\mu\in M(\sigma(N))$, then $\phi_\alpha(N)\to 0$ weakly. Moreover, the map $f\mapsto f(N)$ is unique with respect to the conditions above.
\end{proposition}
\begin{proof}
The fact that $f\mapsto f(N)$ is a representation is a consequence of Proposition~\ref{Riesz representation on Hilbert space for C(X)}. If $\{\phi_\alpha\}$ is as in the statement, then the fact that $E_{x,y}\in M(\sigma(N))$ implies that $\phi_\alpha(N)\to 0$ weakly.\par
To prove uniqueness, let $\tau:B(\sigma(N))\to\mathcal{B}(H)$ be a representation with the appropriate properties. Then $\tau(f)=f(N)$ if $f\in C(\sigma(N))$ by the uniqueness of the functional calculus for normal elements of a $C^*$-algebra. If $\phi\in\mathcal{B}(\sigma(N))$, then Proposition~\ref{NVS weak topo dense in bidual} implies that there is a net $\{\phi_\alpha\}$ in $C(\sigma(N))$ such that $\|\phi_\alpha\|\leq\|f\|$ for all $\alpha$ and $\int\phi_\alpha\,d\mu\to\int f\,d\mu$ for every $\mu\in M(\sigma(N))$. Thus $\phi_\alpha(N)\to f(N)$ weakly. But $\tau(\phi_\alpha)\to\tau(f)$ weakly, so it follows that $\tau(f)=f(N)$.
\end{proof}
It it now worthwhile to rewrite $(\ref{Hilbert space representation for C(X)-1})$ as
\begin{align}\label{Hilbert space Borel function calculus prop}
\langle f(N)x,y\rangle=\int f\,dE_{x,y}
\end{align}
for $f\in B(\sigma(N))$ and $x,y\in H$. If $f\in B(\C)$, then the restriction of $f$ to $\sigma(N)$ belongs to $B(\sigma(N))$. Since the support of each measure $E_{x,y}$ is contained in $\sigma(N)$, $(\ref{Hilbert space Borel function calculus prop})$ holds for every bounded Borel function $f$ on $\C$. This has certain technical advantages that will become apparent when we begin to apply $(\ref{Hilbert space Borel function calculus prop})$.\par
Proposition~\ref{Hilbert space Borel function calculus unique} thus extends the functional calculus for normal operators.
\begin{proposition}\label{Hilbert space spectral subspace prop}
Let $N$ be a normal operator on a Hilber space $H$ and $E$ be the spectra measure. For each Borel set $\Delta\sub\sigma(N)$, the \textbf{spectral subspace} $H_\Delta$ is defined by
\[H_\Delta=E(\Delta)(H).\]
Also, we set $N_\Delta=N|_{H_\Delta}$. Then
\begin{itemize}
\item[(a)] $H_\emp=\{0\}$, $H_{\sigma(N)}=H$, and $H_{\Delta_1}\bot H_{\Delta_2}$ if $\Delta_1\cap\Delta_2=\emp$;
\item[(b)] each $H_\Delta$ is an invariant subspace for $N$, and $\sigma(N_{\Delta})\sub\widebar{\Delta}$;
\item[(c)] if $\lambda\in\Delta$, then $\|N_\Delta-\lambda I\|=\sup_{z\in\Delta}|z-\lambda|$;
\item[(e)] if $\lambda\in\sigma(N)$, then for every neighborhod $U$ of $\lambda$ we have $H_U\neq\{0\}$.
\end{itemize}
\end{proposition}
\begin{proof}
Observe that for any $f,g\in B(\sigma(N))$, the operators $f(N)$ and $g(N)$ commute. In particular, $A$, which is the integral of $f(z)=z$, commutes with $E(\Delta)$, which is the integral of $\chi_\Delta$. Thus $H_\Delta=E_\Delta(H)$ is invariant under $N$. To see $\sigma(N_\Delta)\sub\widebar{\Delta}$, suppose that $\lambda\notin\widebar{\Delta}$. Then the function $g(z)=\chi_\Delta(z)(z-\lambda)^{-1}$ is bounded. Thus $g(N)$ is a bounded operator and
\[g(N)(N-\lambda I)=(N-\lambda I)g(N)=\chi_\Delta(N).\]
Thus the restriction of $g(N)$ to $H_\Delta$ is the inverse of $N_\Delta$, which shows $\lambda\notin\sigma(N_\Delta)$.\par
Let $x\in H_\Delta$. Then since $E(\Delta)$ is a projection,
\[(N-\lambda I)x=(N-\lambda I)E(\Delta)x=f(N)x\]
where $f(z)=(z-\lambda)\chi_\Delta(z)$. Thus part (c) follows from the fact that $f\mapsto f(N)$ is a $*$-homomorphism and $f$ is continuous.\par
Finally, fix $\lambda\in\sigma(N)$ and let $U$ be a neighborhod of $\lambda$ such that $E(U)=0$. Consider the bounded function $f$ defined by $f(z)=(z-\lambda)\chi_{U^c}(z)$. Since $f(z)(z-\lambda)=1$ except in $U$, the equation $f(z)(z-\lambda)=1$ holds $E$-almost everywhere, so its integral coincides with that of $1$. This implies that the inverse of $(N-\lambda I)$ is given by $f(N)$, which contradicts that $\lambda\in\sigma(N)$.
\end{proof}
\begin{example}\label{Hilbert space normal operator eigenvalue iff spectral measure}
Let $N$ be a normal operator on $H$ with spectral measure $E$. Then by Proposition~\ref{Hilbert space spectral subspace prop}, $H_{\{\lambda\}}=N(A-\lambda I)$. Thus $E(\{\lambda\})\neq 0$ iff $\lambda\in\sigma_p(N)$. 
\end{example}
\begin{example}\label{spectral measure for multiplication by identity}
If $\mu$ is a Radon measure on $\C$ with compact support $K$, define $N_\mu$ on $L^2(\mu)$ by $N_\mu f=zf$ for each $f\in L^2(\mu)$. It is easy to check that $N_\mu^*f=\bar{z}f$, and, hence, $N_\mu$ is normal. Similar to Example~\ref{L^2([0,1]) multiplication by identity spectrum}, we have $\sigma(N_\mu)=K=\supp(\mu)$. Now for $\phi$ a bounded Borel function, let $M_\phi$ be the multiplication operator on $L^2(\mu)$. Then the map $\phi\mapsto M_\phi$ is a representation from $B(\sigma(N_\mu))$ to $\mathcal{B}(L^2(\mu))$ such that $M_z=N_\mu$. Moreover, if $\phi_\alpha\to 0$ weakly, then
\[\langle M_{\phi_\alpha}(f),g\rangle=\int\phi_\alpha f\bar{g}\,d\mu\to\int\phi f\bar{g}\,d\mu=\langle M_\phi(f),g\rangle.\]
Thus $M_{\phi_\alpha}\to M_\phi$ weakly. By Proposition~\ref{Hilbert space Borel function calculus unique}, we have $M_\phi=\phi(N_\mu)$. Therefore, if $E$ is the spectral measure of $N_\mu$ then $E(\Delta)=M_{\chi_\Delta}$ and $H_\Delta=\{f\chi_\Delta:f\in L^2(\mu)\}$.
\end{example}
\begin{example}\label{spectral measure for multiplication operator}
Let $(X,\mathcal{A},\mu)$ be any $\sigma$-finite measure space and put $H=L^2(\mu)$. For $\phi\in L^\infty(\mu)$, define $M_\phi$ on $H$ by $M_\phi=\phi f$. Then $M_\phi^*=M_{\bar{\phi}}$ so $M_\phi$ is normal, and $\phi\mapsto M_\phi$ is a representation of $L^\infty(\mu)$. By Proposition~\ref{L^2 space multiplication map} with $\|M_\phi\|=\|\phi\|_\infty$. Define the essential range of $\phi$ by
\[\mathrm{ess.ran}(\phi)=\bigcap\{\widebar{\phi(\Delta)}:\Delta\in\mathcal{A},\mu(X\setminus\Delta)=0\}.\]
Then we claim that $\sigma(M_\phi)=\mathrm{ess.ran}(\phi)$. First assume that $\lambda\notin\mathrm{ess.ran}(\phi)$. So there is a set $\Delta$ in $\mathcal{A}$ with $\mu(X\setminus\Delta)=0$ and $\lambda\notin\widebar{\phi(\Delta)}$; thus there is a $\delta>0$ with $|\phi(x)-\lambda|>\delta$ for all $x\in\Delta$. If $\psi=(\phi-\lambda)^{-1}$, then $\psi\in L^\infty(\mu)$ and $M_\psi=(M_\phi-\lambda I)^{-1}$.\par
Conversely, assume $\lambda\in\mathrm{ess.ran}(\phi) $. It follows that for every integer $n$ there is a set $\Delta_n\in\mathcal{A}$ such that $0<\mu(\Delta_n)<+\infty$ and $|\phi(x)-\lambda|<1/n$ for all $x\in\Delta_n$. Put $f_n=(\mu(\Delta_n))^{-1/2}\chi_{\Delta_n}$; so $f_n\in L^\infty(\mu)$ and $\|f_n\|_2=1$. However,
\[\|(M_\phi-\lambda I)f_n\|_2^2=(\mu(\Delta_n))^{-1/2}\int|\phi-\lambda|^2\,d\mu\leq 1/n^2,\]
showing that $\lambda\in\sigma_{ap}(M_\phi)\sub\sigma(M_\phi)$.\par
Now for every Bounded Borel function $f$ on $\sigma(M_\phi)$, define $\tau(f)=M_{f\circ\phi}$. Then it is easy to see $\tau$ is a representation and satisfies Proposition~\ref{Hilbert space Borel function calculus unique}. Thus $f(M_\phi)=M_{f\circ\phi}$. In particular, for any Borel subset $\Delta\sub\sigma(M_\phi)$, we have $E(\delta)=M_{\chi_\Delta\circ\phi}=M_{\chi_{\phi^{-1}(\Delta)}}$.
\end{example}
\subsection{Star-cyclic normal operators}
\begin{definition}
A vector $x_0$ in $H$ is a \textbf{star-cyclic vector} for $A$ if $H$ is the smallest \textit{reducing} subspace for $A$ that contains $x_0$. The operator $A$ is \textbf{star cyclic} if it has a star-cyclic vector. A vector $x_0$ is \textbf{cyclic} for $A$ if $H$ is the smallest \textit{invariant} subspace for $A$ that contains $x_0$; $A$ is \textbf{cyclic} if it has a cyclic vector.
\end{definition}
From the characterization of invariant and reducing subspaces for $A$ generated by $x_0$, the following proposition is immediate.
\begin{proposition}
Let $H$ be a Hilbert space and $A\in\mathcal{B}(H)$.
\begin{itemize}
\item[(a)] A vector $x_0$ is a star-cyclic vector for $A$ if and only if $H=\widebar{\{Tx_0:T\in C^*(A)\}}$.
\item[(b)] A vector $x_0$ is a cyclic vector for $A$ if and only if $H=\widebar{\{p(A)x_0:\text{$p$ is a polynomial}\}}$.
\end{itemize}
\end{proposition}
Note that if $x_0$ is a star-cyclic vector for $A$, then it is a cyclic vector for the algebra $C^*(A)$.
\begin{proposition}
If $A$ has either a cyclic or a star-cyclic vector, then $H$ is separable.
\end{proposition}
\begin{proof}
It is easy to see that $C^*(A)$ and $\{p(A):\text{$p$ is a polynomial}\}$ are separable subalgebras of $\mathcal{B}(H)$.
\end{proof}
Let $\mu$ be a compactly supported measure on $\C$ and let $N_\mu$ be defined on $L^2(\mu)$ as in Example~\ref{spectral measure for multiplication by identity}. If $K=\supp(\mu)$, then $C^*(N_\mu)=\{M_\phi:\phi\in C(K)\}$. Since $C(K)$ is dense in $L^2(\mu)$, it follows that $1$ is a star-cyclic vector for $N_\mu$. The converse of this is also true.
\begin{theorem}\label{Hilbert space normal operator star-cyclic iff}
A normal operator $N$ is star-cyclic if and only if $N$ is unitarily equivalent to $N_\mu$ for some compactly supported measure $\mu$ on $\C$. If $x_0$ is a star-cyclic vector for $N$, then $\mu$ can be chosen such that there is an isomorphism $U:H\to L^2(\mu)$ with $Ux_0=1$ and $UNU^*=N_\mu$. Under these conditions, $U$ is unique.
\end{theorem}
\begin{proof}
If $N\cong N_\mu$, then we have already seen that $N$ is star-cyclic. So suppose that $N$ has a star-cyclic vector $x_0$. If $E$ is the spectral measure for $N$, put
\[\mu(\Delta)=\|E(\Delta)x_0\|^2=\langle E(\Delta)x_0,x_0\rangle=E_{x_0,x_0}(\Delta)\]
for every Borel subset $\Delta$ of $\C$. Let $K=\supp(\mu)$.\par
If $\phi\in B(K)$, then
\begin{align*}
\|\phi(N)x_0\|^2=\langle\phi(N)x_0,\phi(N)x_0\rangle=\langle|\phi|^2(N)x_0,x_0\rangle=\int|\phi|^2\,dE_{x_0,x_0}=\int|\phi|^2\,d\mu.
\end{align*}
So if $B(K)$ is considered as a subspace of $L^2(\mu)$, $U(\phi(N)x_0)=\phi$ defines an isometry from $\{\phi(N)x_0:\phi\in B(K)\}$ onto $B(K)$. But $x_0$ is a star-cyclic vector, so the range and domain of $U$ are dense in $L^2(\mu)$ or $H$, respectively. Hence $U$ extends to an isomorphism $U:H\to L^2(\mu)$.\par
If $\phi\in B(K)$, then
\[UNU^{-1}(\phi)=UN(\phi(N)x_0)=U((z\phi)(N)x_0)=N_\mu\phi.\]
Hence $UNU^{-1}=N_\mu$ on $B(K)$, which is dense in $L^2(\mu)$. So $UNU^{-1}=N_\mu$. Since $x_0$ generates $H$, the uniqueness of $U$ is clear.
\end{proof}
Any theorem about the operators $N_\mu$ is a theorem about star-cyclic normal operators. With this in mind, the next theorem gives a complete unitary invariant for star-cyclic normal operators.
\begin{definition}
Let $(X,\mathcal{A})$ be a measurable space. Two measures $\mu_1$ and $\mu_2$ on $X$ are called \textbf{mutually absolutely continuous} if they have the same sets of measure zero; that is, $\mu_1(\Delta)=0$ if and ony if $\mu_2(\Delta)=0$. This will be denoted by $[\mu_1]=[\mu_2]$. If $[\mu_1]=[\mu_2]$, then the Radon-Nikodym derivatives $d\mu_1/d\mu_2$ and $d\mu_2/d\mu_1$ are well defined. We say that $\mu_1$ and $\mu_2$ are \textbf{boundedly mutually absolutely continuous} if $[\mu_1]=[\mu_2]$ and the Radon-Nikodym derivatives are essentially bounded functions.
\end{definition}
\begin{theorem}\label{L^2 space multiplication by identity equivalent iff}
Let $\mu_1$ and $\mu_2$ be compactly supported measures on $\C$. Then $N_{\mu_1}\cong N_{\mu_2}$ iff $[\mu_1]=[\mu_2]$.
\end{theorem}
\begin{proof}
Suppose $[\mu_1]=[\mu_2]$ and put $\phi=d\mu_1/d\mu_2$. So if $f\in L^2(\mu_1)$, then $\sqrt[]{\phi}f\in L^2(\mu_2)$ and $\|\sqrt{\phi}f\|_2=\|f\|_2$. That is, the map $U:L^2(\mu_1)\to L^2(\mu_2)$ defined by $Uf=\sqrt{\phi}f$ is an isometry. Since $\phi^{-1}=d\mu_2/d\mu_1$, it is easy to see $U$ is surjective and $U^{-1}g=\phi^{-1/2}g$ for $g\in L^2(\mu_2)$. If $g\in L^2(\mu_2)$, then
\[UN_{\mu_1}U^{-1}(g)=UN_{\mu_1}(\phi^{-1/2}g)=U(z\phi^{-1/2}g)=zg=N_{\mu_2}g.\]
Thus $UN_{\mu_1}U^{-1}=N_{\mu_2}$.\par
Now assume that $N_{\mu_1}$ and $N_{\mu_2}$ are unitarily equivalent via an isomorphism $U:L^2(\mu_1)\to L^2(\mu_2)$. It is easy to see that $Up(N_{\mu_1},N_{\mu_1}^*)U^{-1}=p(N_{\mu_2},N_{\mu_2}^*)$ for any polynomial $p$ in $z$ and $\bar{z}$. Since $N_{\mu_1}\cong N_{\mu_2}$, $\sigma(N_{\mu_1})=\sigma(N_{\mu_2})$, hence $\supp(\mu_1)=\supp(\mu_2)=K$. By taking uniform limits of polynomials in $z$ and $\bar{z}$, we get $Uf(N_{\mu_1})U^{-1}=f(N_{\mu_2})$ for $f\in C(K)$. Recall that $f(N_{\mu})=M_f$, so for $f\in C(K)$ we have
\[U(f)=Uf(N_{\mu_1})(1)=f(N_{\mu_2})U(1)=f\psi,\]
where $\psi:=U(1)$. Because $U$ is an isometry, this implies that $\int|f|^2\,d\mu_1=\int|f|^2|\psi|^2\,d\mu_2$ for every $f\in C(K)$. Hence $\int f\,d\mu_1=\int f|\psi|^2\,d\mu_2$ for $f$ in $C(K)$ with $f\geq 0$. By the uniqueness part of the Riesz representation theorem, $d\mu_1=|\psi|^2d\mu_2$, so $\mu_1\ll\mu_2$. The same process proves the converse, so we get $[\mu_1]=[\mu_2]$.
\end{proof}
\subsection{Applications of the spectral theorem}
If $N$ is a normal operator and $N=\int z\,dE(z)$ is its spectral representation, then $f\mapsto f(N)$ is a $*$-homomorphism of $B(\C)$ into $\mathcal{B}(H)$.
\begin{proposition}\label{Hilbert space normal operator compact iff}
If $N$ is a normal operator and $N=\int z\,dE(z)$, then $N$ is compact if and only if for every $\eps>0$, $E(\{z:|z|>\eps\})$ has finite rank.
\end{proposition}
\begin{proof}
If $\eps>0$, let $\Delta_\eps=\{z:|z|>\eps\}$ and $E_\eps=E(\Delta_\eps)$. Then
\[N-NE_\eps=\int z\,dE(z)-\int z\chi_{\Delta_\eps}(z)\,dE(z)=\int_{|z|\leq\eps}z\,dE(z)=f(N)\]
where $f(z)=z\chi_{\C\setminus\Delta_\eps}(z)$. Thus $\|N-NE_\eps\|\leq\eps$. If $E_\eps$ has finite rank for every $\eps$, then so does $NE_\eps$, hence $N$ is compact.\par
Now assume that $N$ is compact and let $\eps>0$. Put $f(z)=z^{-1}\chi_{\Delta_\eps}(z)$; so $f\in B(\C)$. Since $N$ is compact, so is $Nf(N)$. But $Nf(N)=\int zz^{-1}\chi_{\Delta_\eps}(z)\,dE(z)=E_\eps$. Since $E_\eps$ is a compact projection, $E_\eps(B_H)$ is compact in $H$, so $E_\eps$ must have finite rank.
\end{proof}
The preceding result could have been proved by using the fact that compact normal operators are diagonalizable and the eigenvalues must converge to $0$.
\begin{lemma}\label{Hilbert space A compact iff A^*A compact}
Let $A\in\mathcal{B}(H)$. Then $A$ is compact iff $A^*A$ is compact.
\end{lemma}
\begin{proof}
One dierction is clear. Now assume that $N:=A^*A$ is compact. Then $p(N)$ is compact for each polynomial $p$ such that $p(0)=0$. By taking a limit, we see $\sqrt{N}=|A|$ is compact. But by the polar decomposition, $A=W|A|$, so $A$ is compact.
\end{proof}
\begin{proposition}
If $H$ is separable and $\mathscr{I}$ is an ideal of $\mathcal{B}(H)$ that contains a noncompact operator, then $\mathscr{I}=\mathcal{B}(H)$.
\end{proposition}
\begin{proof}
If $A\in\mathscr{I}$ and $A$ is not compact. Consider $N=A^*A\in\mathscr{I}$; so that $N$ is noncompact by the previous lemma. Let $N=\int t\,dE(t)$ (note that $N$ is positive, so $\sigma(N)\sub\R^+$). By the preceding proposition, there is an $\eps>0$ such that $P=E(\eps,+\infty)$ has infinite rank. But $P=(\int t^{-1}\chi_{(\eps,+\infty)}(t)\,dE(t))N\in\mathscr{I}$. Since $H$ is separable, $\dim P(H)=\dim H=\aleph_0$. Let $U:H\to P(H)$ be an isomorphism. It is easy to check that $1=U^{-1}PU$. But $P\in\mathscr{I}$, so $I\in\mathscr{I}$. Hence $\mathscr{I}=\mathcal{B}(H)$.
\end{proof}
In Proposition~\ref{Hilbert space nonzero closed ideal}, it was shown that every nonzero closed ideal of $\mathcal{B}(H)$ contains the finite-rank operators. When combined with the preceding result, this yields the following.
\begin{corollary}
If $H$ is separable, then the only nontrivial closed ideal of $\mathcal{B}(H)$ is the ideal of compact operators.
\end{corollary}
Let $N$ be a normal operator on $H$ and for every vector $e\in H$ let $H_e=\bigvee\{N^{*i}N^je:i,j\geq 0\}$. So $H_e$ is the smallest subspace of $H$ that contains $e$ and reduces $N$. Also, $N|_{H_e}$ is a star-cyclic normal operator.
\begin{proposition}
If $N$ is a normal operator on $H$, then there are reducing subspaces $\{H_s:s\in S\}$ for $N$ such that $H=\bigoplus_sH_s$; and $N|_{H_s}$ is star cyclic.
\end{proposition}
\begin{proof}
Like the proof of Proposition~\ref{C^* algebra representation is sum of cyclic}, using Zorn's Lemma we can find a maximal set of vectors $E$ in $H$ such that if $e,f\in E$ and $e\neq f$, then $H_e\bot H_f$. It follows as in Proposition~\ref{C^* algebra representation is sum of cyclic} that $H=\bigoplus_{e\in E}H_e$, so the claim follows.
\end{proof}
\begin{corollary}
Every normal operator is unitarily equivalent to the direct sum of star-cyclic normal operators.
\end{corollary}
By combining the preceding proposttlon with Theorem~\ref{Hilbert space normal operator star-cyclic iff} on the representation of star-cyclic normal operators we can obtain the following theorem.
\begin{theorem}\label{Hilbert space normal operator equivalent to multiplication}
If $N$ is a normal operator on $H$, then there is a measure space $(X,\mathcal{A},\mu)$ and a function $\phi\in L^\infty(X,\mathcal{A},\mu)$ such that $N$ is unitarily equivalent to $M_\phi$ on $L^2(X,\mathcal{A},\mu)$.
\end{theorem}
\begin{proof}
If $M$ is a reducing subspace for $N$, then $N\cong N|_M\oplus N|_{M^\bot}$ thus $\sigma(N|_M)\sub\sigma(N)$. So if $\{N_s\}$ is a collection of star-cyclic normal operators such that $N\cong\bigoplus_sN_s$, then $\sigma(N_s)\sub\sigma(N)$ for every $N_s$. By Theorem\ref{Hilbert space normal operator star-cyclic iff} there is a measure $\mu_s$ supported on $\sigma(N)$ such that $N_s\cong N_{\mu_s}$. Let $X_s=\supp(\mu_s)$, $\mathcal{A}_s$ the Borel subsets of $X_s$, and define the disjoint union measure space $(X,\mathcal{A},,\mu)$ as in Example~\ref{L^2 space disjoint union}. As proved in that example, the map $U:L^2(\mu)\to\bigoplus_sL^2(\mu_s)$ defined by $Uf=\bigoplus_sf_s$ is an isomorphism. Define $\phi:X\to\C$ by letting $\phi(z)=z$ if $z\in X_s$; since $X_s\sub\sigma(N)$ for every $s$, $\phi$ is a bounded function. If $U$ is an open subset of $\C$, then $\phi^{-1}(U)\cap X_s=U\cap X_s\in\mathcal{A}_s$; hence $\phi$ is $\mathcal{A}$-measurable. Therefore $\phi\in L^\infty(\mu)$. For $\bigoplus_sf_s\in\bigoplus_sL^2(\mu_s)$, we have
\[UM_\phi U^{-1}(\bigoplus_sf_s)=U(\phi f)=\bigoplus_s(\phi|_{X_s}f_s)=\bigoplus_s(N_{\mu_s}f_s).\]
Thus $UM_\phi U^{-1}=\bigoplus_sN_{\mu_s}\cong N$.
\end{proof}
\begin{proposition}
If $H$ is separable, then the measure space in Theorem~\ref{Hilbert space normal operator equivalent to multiplication} is $\sigma$-finite.
\end{proposition}
\begin{proof}
First note that the measure space $(X,\mathcal{A},\mu)$ constructed in the preceding theorem has no infinite atoms. Now let $\mathcal{E}$ be a collection of pairwise disjoint sets from $\mathcal{A}$ having non-zero finite measure. A computation shows that $\{\mu(\Delta)^{-1/2}\chi_\Delta:\Delta\in\mathscr{E}\}$ are pairwise orthogonal vectors in $L^2(\mu)$. If $L^2(\mu)$ is separable, then $\mathscr{E}$ must be countable. Therefore $(X,\mathcal{A},\mu)$ is $\sigma$-finite.
\end{proof}
\begin{theorem}\label{Hilbert space closed range iff spectrum}
Let $A\in\mathcal{B}(H)$. Then $R(A)$ is closed iff $0$ is not a limit point of $\sigma(A^*A)$.
\end{theorem}
\begin{proof}
Recall that $N(A)^\bot=N(A^*A)^\bot=\widebar{R(A^*A)}$ and it is invariant under $A^*A$. consider the operator
\[T:=A^*A|_{N(A)^\bot}:N(A)^\bot\to N(A)^\bot.\]
Clearly, $T$ is injective, and its range $R(A^*A)$ is dense in $N(A)^\bot$. Now since $T$ is positive, $r(T)=\|A^*A\|=\|A\|^2$, so we have
\begin{align*}
\text{$R(A)$ is closed}&\iff\text{$R(A^*A)$ is closed}\iff\text{$T$ is bijective}\\
&\iff 0\notin\sigma(T)\iff\exists\delta>0\text{ s.t. }\sigma(T)\sub[\delta,\|A\|^2].
\end{align*}
Also, in this case, $\sigma(A^*A)\sub\{0\}\cup[\delta,\|A\|^2]$, so $0$ is not a limit point of $\sigma(A^*A)$.\par
Conversely, assume that there exists $\delta>0$ such that $\sigma(A^*A)\sub\{0\}\cup[\delta,\|A\|^2]$. Then we claim that $0\notin\sigma(T)$. Otherwise, it follows that $0$ is isolated in $\sigma(T)$. Since $T$ is self-adjoint, by Proposition~\ref{Hilbert space normal operator eigenvalue iff spectral measure} $0$ is an eigenvalue of $T$, which is a contradiction.
\end{proof}
\begin{corollary}
If $N\in\mathcal{B}(H)$ is a normal operator, then $R(N)$ is closed iff $0$ is not a limit point of $\sigma(N)$.
\end{corollary}
\begin{proof}
Since $N$ is normal, $\sigma(N^*N)\sub\sigma(N^*)\sigma(N)=\sigma(N)^2$, so the claim follows from the previous theorem.
\end{proof}
\begin{proposition}\label{Hilbert space strongly closed subalgebra span of projection}
If $\mathfrak{A}$ is a strongly closed $C^*$-subalgebra of $\mathcal{B}(H)$, then $\mathfrak{A}$ is the norm closed linear span of the projections in $\mathfrak{A}$.
\end{proposition}
\begin{proof}
If $A\in\mathfrak{A}$, then $A+A^*$ and $A-A^*\in\mathfrak{A}$; hence $\mathfrak{A}$ is the linear span of $\Re(\mathfrak{A})$. Suppose $A\in\Re(\mathfrak{A})$ and $A=\int t\,dE(t)$. If $[a,b]\sub\R$, then there is a sequence $\{\phi_n\}$ in $C(\R)$ such that $\phi_n\to\chi_{[a,b)}$. If $x\in H$, then by the dominated convergence theorem,
\[\|[\phi_n(A)-E([a,b))]x\|^2=\int|\phi_n(t)-\chi_{[a,b)}(t)|^2\,dE_{x,x}\to 0.\]
That is, $\phi_n(A)\to E([a,b))$ strongly. Since $\mathfrak{A}$ is strongly closed, $E([a,b))\in\mathfrak{A}$. Now if $[a,b)$ contains $\sigma(A)$, then for each $\eps>0$, there is a partition $a=t_0<\cdots<t_n=b$ such that $|t-\sum_{i=1}^{n}t_i\chi_{[t_{i-1},t_i)}(t)|<\eps$ for $t\in\sigma(A)$; hence $\|A-\sum_{i=1}^{n}t_iE([t_{i-1},t_i))\|<\eps$. Thus every self-adjoint operator in $\mathfrak{A}$ belongs to the closed linear span of the projections in $\mathfrak{A}$.
\end{proof}
\subsection{Commuting operators}
If $\mathscr{S}$ is a subset of $\mathcal{B}(H)$, we set
\[\mathscr{S}'=\{A\in\mathcal{B}(H):AB=BA\text{ for all $B\in\mathscr{S}$}\}.\]
The set $\mathcal{S}'$ is called the \textbf{commutant} of $\mathcal{S}$. It is not difficult to see that $\mathcal{S}'$ is always an algebra. Similarly, $\mathcal{S}''=(\mathscr{S}')'$ is called the \textbf{double commutant} of $\mathscr{S}$. The problem of determining the commutant or double commutant of a single operator or a collection of operators leads to some exciting and interesting mathematics. The commutant is an algebraic object and the idea is to bring the force of analysis to bear in the characterization of this algebra.\par
We begin by examining the commutant of a direct sum of operators. Recall that if $H=\bigoplus_sH_s$ and $A_s\in\mathcal{B}(H_s)$ for each $s$, then $A=\bigoplus_sA_s$ defines a bounded operator on $H$ if and only if $\sup_s\|A_s\|<+\infty$ and in this case $\|A\|=\sup_s\|A_s\|$. Also, each operator $B$ on $H$ has a matrix representation $[B_{st}]$ where $B_{st}\in\mathcal{B}(H_t,H_s)$. The following two propositions follows from matrix manipulations.
\begin{proposition}
Let $H=\bigoplus_sH_s$ be a Hilbert space. If $A=\bigoplus_sA_s$ and $B=[B_{st}]$ are in $\mathcal{B}(H)$, then $AB=BA$ iff $B_{st}A_t=A_sB_{st}$ for all $s,t$.
\end{proposition}
\begin{proposition}
Let $H$ be a Hilbert space. If $A\in\mathcal{B}(H)$ and $B=[B_{ij}]\in\mathcal{B}(H^{(n)})$, then $BA^{(n)}=A^{(n)}B$ iff $B_{ij}A=AB_{ij}$ for all $i,j$.
\end{proposition}

\begin{proposition}
If $A\in\mathcal{B}(H)$ and $1\leq n\leq+\infty$, then
\[\{A^{(n)}\}''=\{B^{(n)}:B\in\{A\}''\}=\{\{A\}''\}^{(n)}.\]
\end{proposition}
\begin{proof}
The second equality in the statement is a tautology and it is the first equality that forms the substance of the proposition. If $B\in\{A\}''$, then the preceding proposition implies that $B^{(n)}\in\{A^{(n)}\}''$. Now let $B\in\{A^{(n)}\}''$. To simplify the notation, assume $n=2$, so $B\in\{A\oplus A\}''$. Let $B=[B_{ij}]$, then since $(\begin{smallmatrix}0&I\\0&0\end{smallmatrix})\in\{A\oplus A\}'$, matrix multiplication shows $B_{11}=B_{22}$ and $B_{21}=0$. Similarly, the fact that $(\begin{smallmatrix}0&0\\I&0\end{smallmatrix})\in\{A\oplus A\}'$ implies $B_{12}=0$. If $C=B_{11}=B_{22}$ and $T\in\{A\}'$, then $T\oplus T\in\{A\oplus A\}'$, so $B(T\oplus T)=(T\oplus T)B$. This shows $C\in\{A\}'$, so $B\in\{\{A\}'\}^{(2)}$.
\end{proof}
\begin{corollary}\label{Hilbert space commutant of direct sum}
If $\mathscr{S}\sub\mathcal{B}(H)$, then $\{\mathcal{S}^{(n)}\}''=\{\mathscr{S}''\}^{(n)}$
\end{corollary}
We say that a subspace $M$ of $H$ reduces a collection $\mathscr{S}$ of operators if it reduces each operator in $\mathscr{S}$. Then $M$ reduces $\mathscr{S}$ if and only if the projection of $H$ onto $M$ belongs to $\mathscr{S}'$. This is important in the next theorem, due to von Neumann.
\begin{theorem}[\textbf{The Double Commutant Theorem}]\label{Hilbert space bicommutant}
Let $\mathfrak{A}$ be a $C^*$-subalgebra of $\mathcal{B}(H)$ containing $I$. Then $\mathfrak{A}''=\mathrm{cl}_w\mathfrak{A}=\mathrm{cl}_s\mathfrak{A}$.
\end{theorem}
\begin{proof}
It is easy to see $\mathfrak{A}'$ is strongly closed, so it remains to show that $\mathfrak{A}''\sub\mathrm{cl}_s\mathfrak{A}$. To do this Proposition~\ref{Hilbert space subalgebra closure by invariant space} will be used. Let $B\in\mathfrak{A}''$ and let $M\in\Lat(\mathfrak{A}^{(n)})$. It must be shown that $B^{(n)}M\sub M$. Because $\mathfrak{A}$ is a $C^*$-algebra, so is $\mathfrak{A}^{(n)}$. So the fact that $M\in\Lat(\mathfrak{A}^{(n)})$ and $A^{*(n)}\in\mathfrak{A}$ whenever $A\in\mathfrak{A}$ implies that $M$ reduces $A^{(n)}$ for each $A\in\mathfrak{A}$. So if $P$ is the projection of $H^{(n)}$ onto $M$, then $P\in\mathfrak{A}'$. But $B\in\mathfrak{A}'$, so by Corollary~\ref{Hilbert space commutant of direct sum}, $B^{(n)}\in\{\mathfrak{A}^{(n)}\}''$. Hence $B^{(n)}P=PN^{(n)}$ and $M\in\Lat(B^{(n)})$.
\end{proof}
\begin{corollary}
If $\mathfrak{A}$ is a strongly closed $C^*$-subalgebra of $\mathcal{B}(H)$ containing $I$ and $A\in\mathcal{B}(H)$ such that $R(AP)\sub R(P)$ for every projection $P$ in $\mathfrak{A}$, then $A\in\mathfrak{A}$.
\end{corollary}
\begin{proof}
This uses, in addition to the double commutant theorem, Proposition~\ref{Hilbert space strongly closed subalgebra span of projection} as applied to $\mathfrak{A}'$. Indeed, $\mathfrak{A}'$ is a strongly closed $C^*$-algebra and hence it is the norm-closed linear span of its projections. So if $A\in\mathfrak{A}$ and $R(AP)\sub R(P)$ for every projection $P$ in $\mathfrak{A}'$, then $R(A(I-P))\sub R(I-P)$ for every projection $P$ in $\mathfrak{A}$. Thus $P(H)$ reduces $A$ and hence $AP=PA$. Then by Proposition~\ref{Hilbert space strongly closed subalgebra span of projection} $A\in\mathfrak{A}''=\mathfrak{A}$.
\end{proof}
\begin{proposition}\label{L^2 space commutant of multiplication operator}
If $(X,\mathfrak{A},\mu)$ is a $\sigma$-finite measure space and $\phi\in L^\infty(\mu)$, define $M_\phi$ on $L^2(\mu)$ by $M_\phi=\phi f$ on $L^2(\mu)$. If $\mathfrak{A}_\mu=\{M_\phi:\phi\in L^\infty(\mu)\}$, then $\mathfrak{A}_\mu=\mathfrak{A}_\mu'=\mathfrak{A}_\mu''$. 
\end{proposition}
\begin{proof}
It is easy to see that if $\mathfrak{A}=\mathfrak{A}'$, then $\mathfrak{A}=\mathfrak{A}''$. Since $\mathfrak{A}_\mu\sub\mathfrak{A}_\mu'$, it suffices to show that $\mathfrak{A}_\mu'\sub\mathfrak{A}$. So fix $A$ in $\mathfrak{A}_\mu'$; it must be shown that $A=M_\phi$ for some $\phi\in L^\infty(\mu)$.\par
First assume that $\mu(X)<+\infty$. Hence $1\in L^2(\mu)$; put $\phi=A(1)$, so $\phi\in L^2(\mu)$. If $\psi\in L^\infty(\mu)$, then $\psi\in L^2(\mu)$ and
\[A(\psi)=AM_\psi 1=M_\psi A1=M_\psi(\phi)=\psi\phi.\]
Also, $\|\phi\psi\|_2=\|A\psi\|_2\leq\|A\|\|\psi\|_2$.\par
Let $\Delta_n=\{x\in X:|\phi(x)|\geq n\}$. Putting $\psi_n=\chi_{\Delta_n}$ in the preceding argument gives 
\[\|A\|^2\mu(\Delta_n)=\|A\|^2\|\psi_n\|^2\geq\|\phi\psi_n\|^2=\int_{\Delta_n}|\phi|^2\,d\mu\geq n^2\mu(\Delta_n).\]
So if $\mu(\Delta_n)\neq 0$ then $\|A\|\geq n$. Since $A$ is bounded, $\mu(\Delta_n)=0$ for some $n$; equivalently, $\phi\in L^\infty(\mu)$. But $A=M_\phi$ on $L^\infty(\mu)$, which is dense in $L^2(\mu)$, so $A=M_\phi$ on $L^2(\mu)$.\par
Now assume that $\mu(X)=+\infty$. If $\mu(\Delta)<+\infty$, let $L^2(\mu|_{\Delta})=\{f\in L^2(\mu):\text{$f=0$ off $\Delta$}\}$. For $f\in L^2(\mu|_{\Delta})$, $Af=A\chi_\Delta f=\chi_\Delta Af\in L^2(\mu|_{\Delta})$. Let $A_\Delta$ be the restriction of $L^2(\mu|_{\Delta})$. By the preceding argument, there is a $\phi_\Delta$ in $L^\infty(\mu_{\Delta})$ such that $A_\Delta=M_{\phi_\Delta}$. Now if $\mu(\Delta_1)<+\infty$ and $\mu(\Delta_2)<+\infty$, then since $M_{\phi_{\Delta_1}}$ coincide with $M_{\phi_{\Delta_2}}$ on $\Delta_1\cap\Delta_2$, we see $\phi_{\Delta_1}|_{\Delta_1\cap\Delta_2}=\phi_{\Delta_2}|_{\Delta_1\cap\Delta_2}$ $\mu$-almost everywhere.\par
Write $X=\bigcup_n\Delta_n$ where $\mu(\Delta_n)<+\infty$. From the argument above, if $\phi(x)=\phi_{\Delta_n}(x)$ when $x\in\Delta_n$, then $\phi$ is a well-defined measurable function on $X$. Now $\|\phi_\Delta\|_\infty=\|M_{\phi_{\Delta}}\|=\|A_\Delta\|\leq\|A\|$; hence $\|\phi\|\leq\|A\|$. It is easy to check that $A=M_\phi$.
\end{proof}
The next result will enable us to solve a number of problems concerning normal operators. It can be considered as a result that removes a technicality, but it is much more than that.
\begin{theorem}[\textbf{Fuglede-Putnam Theorem}]
If $N$ and $M$ are normal operators on $H$ and $K$, and $T:H\to K$ is an operator such that $NT=TM$, then $N^*T=TM^*$.
\end{theorem}
\begin{proof}
Note that it follows from the hypothesis that $N^kT=TM^k$ for all $k\geq 0$. So if $p(z)$ is a polynomial, then $p(N)T=Tp(M)$. Since for a fixed $z$ in $\C$, $\exp(izN)$ and $\exp(izM)$ are limits of polynomials in $N$ and $M$, respectively, it follows that $\exp(izN)T=T\exp(izM)$ for all $z\in\C$. Equivalently, $T=e^{-izN}Te^{izM}$ for all $z\in\C$. Because $\exp(X+Y)=(\exp X)(\exp Y)$ when $X$ and $Y$ commute, the fact that $N$ and $M$ are normal implies that
\[f(z)=e^{-izN^*}Te^{izM^*}=e^{-i(zN^*+\bar{z}N)}Te^{i(\bar{z}M+zM^*)}.\]But for every $z\in\C$, $zN^*+\bar{z}N$ and $zM^*+\bar{z}M$ are hermitian operators. Hence $\exp[-i(zN^*+\bar{z}N)]$ and $\exp[i(zM^*+\bar{z}M)]$ are unitary. Therefore $\|f(z)\|\leq\|T\|$. But $f:\C\to\mathcal{B}(H,K)$ is an entire function. By Liouville's Theorem, $f$ is constant. Thus, taking derivative gives 
\[0=f'(z)=-iN^*e^{-izN^*}Te^{izM^*}+ie^{-izN^*}TM^*e^{izM^*}.\]
Putting $z=0$ gives $0=-iN^*T+iTM^*$, whence the theorem.
\end{proof}
From the spectral theorem, the following corollary is immediate.
\begin{corollary}
Let $N$ be a normal operator on $H$. If $N=\int z\,dE(z)$ and $TN=NT$, then $TE(\Delta)=E(\Delta)T$ for every
Borel set $\Delta$.
\end{corollary}
\begin{corollary}\label{L^2 space commutant of multiplication by identity}
If $\mu$ is a compactly supported measure on $\C$, then
\[\{N_\mu\}'=\mathfrak{A}_\mu=\{M_\phi:\phi\in L^\infty(\mu)\}.\]
\end{corollary}
\begin{proof}
Clearly $\mathfrak{A}_\mu'\sub\{N_\mu\}'$. If $A\in\{N_\mu\}'$, then Fuglede-Putnam Theorem implies $AN^*=N^*A$. By an easy algebraic argument, $AM_\phi=M_\phi A$ whenever $\phi$ is a polynomial in $z$ and $\bar{z}$. By taking weak$*$ limits of such polynomials, it follows that $A\in\mathfrak{A}'$. By Proposition~\ref{L^2 space commutant of multiplication operator}, $A\in\mathfrak{A}'$.
\end{proof}
Putnam applied his generalization of Fuglede's Theorem to show that similar normal operators must be unitarily equivalent. This has a formal generalization which is useful.
\begin{proposition}
Let $N$ and $M$ be normal operators on $H$ and $K$. If $T:H\to K$ is an operator such that $TN=MT$, then:
\begin{itemize}
\item[(a)] $N(T)$ reduces $N$ and $\widebar{R(T)}$ reduces $M$. 
\item[(b)] If $N_1=N|_{N(T)^\bot}$ and $M_1=M|_{\widebar{R(T)}}$, then $N_1\cong M_1$.
\end{itemize}
\end{proposition}
\begin{proof}
If $x\in H$, then $MTx=TNx\in R(T)$; so $\widebar{R(T)}$ is invariant for $M$. By the Fuglede-Putnam Theorem, $TN^*=M^*T$, so $\widebar{R(T)}$ is invariant for $M^*$. The second claim can be proved similarly.\par
Since $T(N(T)^\bot)\sub\widebar{R(T)}$, part (c) will be proved if it can be shown that $N\cong M$ when $N(T)=\{0\}$ and $R(T)$ is dense. So make these assumptions and consider the polar decomposition of $T$, $T=U|T|$. Because $N(T)=\{0\}$ and $R(T)$ is dense, $|T|$ is a positive operator on $H$ and $U:H\to K$ is a surjective isometry, hence an isomorphism. Now $T^*M^*=N^*T^*$, so $T^*M=NT^*$. A calculation shows that $|T|^2=T^*T\in\{N\}'$, so $|T|\in\{N\}'$ (by taking limit to approximate $\sqrt{z}$). Hence
\[MU|T|=MT=TN=U|T|N=UN|T|;\]
that is, $MU=UN$ on the range of $|T|$. But $N(T)=0$, so $R(|T|)=R(T^*T)$ is dense in $H$. Therefore $MU=UN$, so $M\cong N$.
\end{proof}
\begin{corollary}
If two normal operators are similar, then they are unitarily equivalent.
\end{corollary}
\subsection{Abelian von Neumann algebras}
\begin{definition}
A \textbf{von Neumann algebra} $\mathfrak{A}$ is a strongly $C^*$-subalgebra of $\mathcal{B}(H)$.
\end{definition}
Note that if $\mathfrak{A}$ is a von Neumann algebra, then $I\in\mathfrak{A}$ and $\mathfrak{A}''=\mathfrak{A}$. The converse also holds by the Double Commutant Theorem.
\begin{example}[\textbf{Examples of von Neuman Algebras}]
\mbox{}
\begin{itemize}
\item[(a)] $\mathcal{B}(H)$ and $\C$ are von Neumann algebras.
\item[(b)] If $(X,\mathcal{A},\mu)$ is a $\sigma$-finite measure space, then $\mathfrak{A}_\mu=\{M_\phi:\phi\in L^\infty(\mu)\}$ is an abelian von Neumann algebra by Proposition~\ref{L^2 space commutant of multiplication operator}. In fact, it is a maximal abelian von Neumann algebra.
\end{itemize}
\end{example}
Let $\mathfrak{A}_i\sub\mathcal{B}(H_i)$ be a family of von Neumann algebras. Then $\bigoplus_i\mathfrak{A}_i$ is used to denote the $\ell^\infty$ direct sum of $\mathfrak{A}_i$. That is,
\[\bigoplus_i\mathfrak{A}_i=\{\bigoplus_iA_i:\sup_i\|A_i\|<+\infty\}.\]
Note that $\bigoplus A_i\in\mathcal{B}(\bigoplus_iH_i)$ with $\|\bigoplus_iA_i\|=\sup_i\|A_i\|$. From the definition of $\ell^\infty$ norm, the following result is immediate.
\begin{proposition}
If $\mathfrak{A}_i$ are von Neumann, algebras, then so is $\bigoplus_i\mathfrak{A}_i$.
\end{proposition}
The following proposition is also easy to see.
\begin{proposition}
Let $\mathfrak{A}_i$ be a von Neumann algebra on $H_i$, $i=1,2$. If $U:H_1\to H_2$ is an isomorphism such that $U\mathfrak{A}_1U^{-1}=\mathfrak{A}_2$, then $U\mathfrak{A}_1'U^{-1}=\mathfrak{A}_2'$.
\end{proposition}
Now let $(X,\mathcal{A},\mu)$ be a $\sigma$-finite measure space and define $\rho:\mathfrak{A}_\mu\to\mathfrak{A}_\mu^{(2)}$ by $\rho(T)=T\oplus T$. Then $\rho$ is a $*$-isomorphism. However, $\mathfrak{A}_\mu$ and $\mathfrak{A}_{\mu}^{(2)}$ are not spatially isomorphic. That is, there is no Hilbert space isomorphism $U:L^2(\mu)\to L^2(\mu)\oplus L^2(\mu)$ such that $U\mathfrak{A}_\mu U^{-1}=\mathfrak{A}_\mu^{(2)}$. Why? One way to see that no such $U$ exists is to note that $\mathfrak{A}_\mu$ has a cyclic vector (give an example). However,  does not have a cyclic vector as shall be seen presently.
\begin{definition}
If $\mathfrak{A}\sub\mathcal{B}(H)$ and $e_0\in H$, then $e_0$ is a \textbf{separating vector} for $\mathfrak{A}$ if the only operator $A$ in $\mathfrak{A}$ such that $Ae_0=0$ is the operator $A=0$.
\end{definition}
If $(X,\mathcal{A},\mu)$ is a $\sigma$-finite measure space and $f\in L^2(\mu)$ such that $\mu(\{x\in X:f(x)=0\})=0$, then $f$ is a separating vector for $\mathfrak{A}_\mu$ as well as a cyclic vector. If $\mathfrak{A}=\mathcal{B}(H)$, then no vector in $H$ is separating for $\mathfrak{A}$ while every nonzero vector is a cyclic vector. If $\mathfrak{A}=\C$ and $\dim H>1$, then $\mathfrak{A}$ has no cyclic vectors but every nonzero vector is separating for $\mathfrak{A}$.
\begin{proposition}\label{Hilbert space cyclic is separating for commutant}
If $e_0$ is a cyclic vector for $\mathfrak{A}$, then $e_0$ is a separating vector for $\mathfrak{A}'$.
\end{proposition}
\begin{proof}
If $T\in\mathfrak{A}'$ and $Te_0=0$, then for every $A$ in $\mathfrak{A}$, $TAe_0=ATe_0=0$. Since $\bigvee\mathfrak{A}e_0=H$, we get $T=0$.
\end{proof}
\begin{corollary}
If $\mathfrak{A}$ is an abelian subalgebra of $\mathcal{B}(H)$, then every cyclic vector for $\mathfrak{A}$ is a separating vector for $\mathfrak{A}$.
\end{corollary}
\begin{proof}
Because $\mathfrak{A}$ is abelian, $\mathfrak{A}\sub\mathfrak{A}'$.
\end{proof}
Since $\mathcal{B}(H)'=\C$, Proposition~\ref{Hilbert space cyclic is separating for commutant} explains some of the duality exhibited prior to that. Also note that if $(X,\mathcal{A},\mu)$ is a finite measure space, $1\oplus 0$, $0\oplus 1$, and $1\oplus 1$ are all separating vectors for $\mathfrak{A}^{(2)}_\mu$. Because $(\mathfrak{A}^{(2)}_\mu)'\neq\mathfrak{A}^{(2)}_\mu$, the next theorem says that $\mathfrak{A}^{(2)}_\mu$ has no cyclic vector.
\begin{theorem}\label{Hilbert space maximal abelian von Neumann algebra iff}
Assume that $H$ is separable and $\mathfrak{A}$ is an abelian $C^*$-subalgebra of $\mathcal{B}(H)$. The following statements are equivalent.
\begin{itemize}
\item[(\rmnum{1})] $\mathfrak{A}$ is a maximal abelian von Neuman algebra.
\item[(\rmnum{2})] $\mathfrak{A}=\mathfrak{A}'$.
\item[(\rmnum{3})] $\mathfrak{A}$ has a cyclic vector, contains $I$, and is strongly closed.
\item[(\rmnum{4})] There is a compact metric space $X$, a positive Borel measure $\mu$ with support $X$, and an isomorphism $U:L^2(\mu)\to H$ such that $U\mathfrak{A}_\mu U^{-1}=\mathfrak{A}$.
\end{itemize}
\end{theorem}
\begin{proof}
Since $\mathfrak{A}'$ is strongly closed (note that $\mathfrak{A}'''=\mathfrak{A}'$) and abelian, if $\mathfrak{A}$ is a maximal abelian von Neuman algebra then $\mathfrak{A}=\mathfrak{A}'$. Conversely, if $\mathfrak{A}=\mathfrak{A}'$, then since any abelian von Neuman algebra containing $\mathfrak{A}$ is contained in $\mathfrak{A}'$, we see $\mathfrak{A}$ is maximal.\par
Now assume that $\mathfrak{A}'=\mathfrak{A}$. By Zorn's Lemma and the separability of $H$, there is a maximal sequence of unit vectors $\{e_n\}$ such that for $n\neq m$, we have $[\mathfrak{A}e_n]\bot[\mathfrak{A}e_m]$. It follows from the maximality of $\{e_n\}$ that $H=\bigoplus_n[\mathfrak{A}e_n]$.\par
Let $e_0=\sum_ne_n/\sqrt{2^n}$. Since $e_n\bot e_m$ for $n\neq m$, $\|e_0\|^2=\sum_n2^{-n}=1$. Let $P$ be the projection of $H$ onto $H_n=[\mathfrak{A}e_n]$. Clearly $\mathfrak{A}$ leaves $H_n$ invariant and so, since $\mathfrak{A}$ is a $*$-algebra, $H_n$ reduces $\mathfrak{A}$. Thus $P_n\in\mathfrak{A}'=\mathfrak{A}$ and $[\mathfrak{A}e_0]\sups[\mathfrak{A}P_ne_0]=[\mathfrak{A}e_n]=H_n$. Therefore $H=[\mathfrak{A}e_0]$ and $e_0$ is a cyclic vector for $\mathfrak{A}$.\par
Now assume (\rmnum{3}). Since $H$ is separable, the unit ball $B_{\mathfrak{A}}$ of $\mathfrak{A}$ with weak operator topology is metrizable and compact. By picking a countable dense subset of $B_{\mathfrak{A}}$ and letting $\mathfrak{A}_1$ be the $C^*$-algebra generated by this countable dense subset, it follows that $\mathfrak{A}_1$ is a separable $C^*$-algebra whose strong closure is $\mathfrak{A}$. Let $X$ be the maximal ideal space of $\mathfrak{A}_1$ and let $\rho:C(X)\to\mathfrak{A}_1\sub\mathfrak{A}$ be the inverse of the Gelfand map. By Theorem~\ref{Riesz representation on Hilbert space for C(X)} there is a spectral measure $E$ defined on the Borel subsets of $X$ such that $\rho(f)=\int f\,dE$ for $f$ in $C(X)$. If $\phi\in B(X)$ and $\{\phi_\alpha\}$ is a net in $C(X)$ such that $\int\phi_\alpha\,d\nu\to\int\phi\,d\nu$ for every $\nu$ in $M(X)$, then $\rho(\phi_\alpha)=\int\phi_\alpha\,dE\to\int\phi\,dE$ strongly. Thus $\{\int\phi\,dE:\phi\in B(X)\}\sub\mathfrak{A}$ since $\mathfrak{A}$ is strongly closed.\par
Let $e_0$ be a cyclic vector for $\mathfrak{A}$ and put $\mu(\Delta)=\|E(\Delta)e_0\|^2=\langle E(\Delta)e_0,e_0\rangle$. Thus
\[\langle(\int\phi\,dE)e_0,e_0\rangle=\int\phi\,d\mu\]
for every $\phi$ in $B(X)$. Consider $B(X)$ as a subspace in $L^2(\mu)$ by identifying functions that agree a.e.. If $\phi\in B(X)$, then
\[\Big\|\Big(\int\phi\,dE\Big)e_0\Big\|^2=\langle\Big(\int\phi\,dE\Big)^*\Big(\int\phi\,dE\Big)e_0,e_0\rangle=\int|\phi|^2\,d\mu=\|\phi\|_{L^2(\mu)}.\]
This says two things. First, if $\phi=0$ a.e., then $(\int\phi\,dE)e_0=0$. Hence $U:B(X)\to H$ defined by $U\phi=(\int\phi\,dE)e_0$ is a well-defined map from the dense subspace $B(X)$ in $L^2(\mu)$ into $H$. Second, $U$ is an isometry. Since the domain and range of $U$ are dense, $U$ extends to an isomorphism $U:L^2(\mu)\to H$.\par
If $\phi\in B(X)$ and $\psi\in L^\infty(\mu)$, then 
\[UM_\psi\phi=U(\psi\phi)=\Big(\int\psi\phi\,dE\Big)e_0=\Big(\int\psi\,dE\Big)\Big(\int\phi\,dE\Big)e_0=\Big(\int\psi\,dE\Big)U\phi.\]
Hence $UM_\psi U^{-1}=\int\psi\,dE$ and $U\mathfrak{A}_\mu U^{-1}\sub\mathfrak{A}$. On the other hand, $U\mathfrak{A}_\mu U^{-1}$ is a strongly closed $C^*$-subalgebra of $\mathcal{B}(H)$ that contains $UC(X)U^{-1}=\mathfrak{A}_1$, so $U\mathfrak{A}U^{-1}=\mathfrak{A}$. Because $\mathfrak{A}_1$ is separable, $X$ is metrizable.\par
Finally, if $\mathfrak{A}$ is unitarily equivalent to $\mathfrak{A}_\mu$ then since $\mathfrak{A}_\mu=\mathfrak{A}_\mu'$, we see $\mathfrak{A}$ satisfies (\rmnum{2}). Hence the proof is finished.
\end{proof}
\begin{corollary}\label{Hilbert space abelian subalgebra separating vector if seperable}
If $\mathfrak{A}$ is an abelian $C^*$-subalgebra of $\mathcal{B}(H)$ and $H$ is separable, then $\mathfrak{A}$ has a separating vector.
\end{corollary}
\begin{proof}
By Zorn's Lemma, $\mathfrak{A}$ is contained in a maximal abelian $C^*$-algbera, $\mathfrak{M}$. It is easy to see that $\mathfrak{M}$ must be strongly closed, so $\mathfrak{M}$ is a maximal abelian von Neumann algebra. By the preceding theorem, there is a cyclic vector $e_0$ for $\mathfrak{M}$. Then by Proposition~\ref{Hilbert space cyclic is separating for commutant} $e_0$ is separating for $\mathfrak{M}'=\mathfrak{M}$ and hence for any subset of $\mathfrak{M}$.
\end{proof}
\subsection{The functional calculus for normal operators}
In this part all Hilbert spaces will be assumed to be separable. This assumption is necessary for the validity of some of the results and minimizes the technical details in others.\par
If $N$ is a normal operator on $H$, let $W^*(N)$ be the von Neumann algebra generated by $N$. That is, $W^*(N)$ is the intersection of all of the von Neumann algebras containing $N$. Hence $W^*(N)$ is the strong closure of $\{p(N,N^*):\text{$p$ is a polynomial in $z$ and $\bar{z}$}\}$.
\begin{proposition}\label{Hilbert space normal opearator generate von Neumann}
If $N$ is a normal operator, then $W^*(N)=\{N\}''\sups\{\phi(N):\phi\in B(\sigma(N))\}$.
\end{proposition}
\begin{proof}
The equality results from the Double Commutant Theorem and the Fuglede-Putnam Theorem. If $\phi\in B(\sigma(N))$, $N=\int zdE(z)$, and $T\in\{N\}'$, then $T\in\{N,N^*\}'$ by the Fuglede-Putnam Theorem and $TE(\Delta)=E(\Delta)T$ for every Borel set $A$ by the Spectral Theorem. Hence $T\phi(N)=\phi(N)T$ and $\phi(N)\in\{N\}''$.
\end{proof}
The purpose of this part is to prove that the containment in the preceding proposition is an equality. In fact, more will be proved. A measure $\mu$ whose support is $\sigma(N)$ will be found such that $\phi(N)$ is well defined if $\phi\in L^\infty(\mu)$ and the map $\phi\to\phi(N)$ is a $*$-isomorphism of $L^\infty(\mu)$ onto $W^*(N)$. To find $\mu$, Corollary~\ref{Hilbert space abelian subalgebra separating vector if seperable} (which requires the separability of $H$) is used.\par
By Corollary~\ref{Hilbert space abelian subalgebra separating vector if seperable}, $W^*(N)$, being an abelian von Neumann algebra, has a separating vector $e_0$. Define a measure $\mu$ on $\sigma(N)$ by
\begin{align}\label{Hilbert space scalar spectral measure def}
\mu(\Delta)=\langle E(\Delta)e_0,e_0\rangle=\|E(\Delta)e_0\|^2.
\end{align}
(Note that this measure has already appeared in the proof of Theorem~\ref{Hilbert space maximal abelian von Neumann algebra iff}.) Note that, since $e_0$ is separating, $\mu(\Delta)=0$ iff $E(\Delta)=0$.
\begin{definition}
A \textbf{scalar-valued spectral measure} for $N$ is a positive Borel measure $\mu$ on $\sigma(N)$ such that $\mu(\Delta)=0$ if and only if $E(\Delta)=0$; that is, $\mu$ and $E$ are mutually absolutely continuous.
\end{definition}
So by our construction, scalar-valued spectral measures always exist. It will be shown that every scalar-valued spectral measure is defined by $(\ref{Hilbert space scalar spectral measure def})$ where $e_0$ is a separating vector for $W^*(N)$. In the process additional information is obtained about a normal operator and its functional calculus.\par
If $x\in H$, let $\mu_x=E_{x,x}$ and let $H_x=[W^*(N)x]$, the smallest reducing subspace for $N$ that contains $x$. Let $N_x=N|_{H_x}$. Thus $N_x$ is a $*$-cyclic normal operator with $*$-cyclic vector $x$. The uniqueness of the spectral measure for a normal operator implies that the spectral measure for $N_x$ is $E(\Delta)|_{H_x}$, and so $\mu_x$ is the measure in the proof of Theorem~\ref{Hilbert space normal operator star-cyclic iff}. By the claim of that theorem, there is a unique isomorphism $U_x:H_x\to L^2(\mu_x)$ such that $U_xx=1$ and $U_xN_xU_x^{-1}f=zf$ for all $f$ in $L^2(H_x)$. This notation will be used repreatedly in this part.\par
The way to understand what is going on is to consider each $N_x$ as a localization of $N$. Since $N_x$ is unitarily equivalent to $M_z$ on $L^2(H_x)$ we can agree that we thoroughly understand the local behavior of $N$. Can we put together this local behavior of $N$ to understand the global behavior of $N$? This will be done later.\par
In the present part the objective is to show that if $x$ is a separating vector for $W^*(N)$, then the functional calculus for $N$ is completely determined by the functional calculus for $N_x$. The sense in which this "determination" is made is the following. If $A\in W^*(N)$, then the definition of $H_x$ shows that $A(H_x)\sub H_x$. Since $A^*\in W^*(N)$, $H_x$ reduces each operator in $W^*(N)$; thus $A|_{H_x}$ is meaningful. It will be shown that the map $A\mapsto A|_{H_x}$ is a $*$-isomorphism of $W^*(N)$ onto $W^*(N_x)$ if $x$ is a separating vector for $W^*(N)$. Since $N_x$ is $*$-cyclic, Theorem~\ref{Hilbert space normal operator star-cyclic iff} and Corollary~\ref{L^2 space commutant of multiplication operator} show how to determine $W^*(N_x)$.\par
We begin with a modest lemma.
\begin{lemma}\label{Hilbert space restriction on von Neumann algebra}
If $x\in H$ and $\rho_x:W^*(N)\to W^*(N_x)$ is defined by $\rho_x(A)=A|_{H_x}$. Then $\rho_x$ is a $*$-epimorphism that is weakly continuous. Moreover, if $\phi\in B(\sigma(N))$ then $\rho_x(\phi(N))=\phi(N_x)$ and if $A\in W^*(N)$, then there is a $\phi$ in $B(\sigma(N_x))$ such that $\rho_x(A)=\phi(N_x)$.
\end{lemma}
\begin{proof}
First let us see that $\rho_x$ maps $W^*(N)$ into $W^*(N_x)$. If $p(z,\bar{z})$ is a polynomial in $z$ and $\bar{z}$ then $\rho_x[p(N,N^*)]=p(N_x,N_x^*)$ as an algebraic manipulation shows. If $\{p_\alpha\}$ is a net of such polynomials such that $p_\alpha(N,N^*)\to A$ weakly, then for $u,v\in H_x$, we have
\[\langle p_\alpha(N,N^*)u,v\rangle\to\langle Au,v\rangle\]
thus $p_\alpha(N_x,N_x^*)\to\rho_x(A)$ weakly and so $\rho_x(A)\in W^*(N_x)$. It is easy to see $\rho_x$ is a $*$-homomorphism. Also, the preceding argument can be used to show that $\rho_x$ is weakly continuous.\par
If $\phi\in B(\sigma(N))$, there is a net $\{p_\alpha(z,\bar{z})\}$ of polynomials such that $p_\alpha(z,\bar{z})\to\phi$ in the weak topology of $B(\sigma(N))$. Since $\sigma(N_x)\sub\sigma(N)$, we have $M(\sigma(N_x))\sub M(\sigma(N))$, so $p_\alpha$ also converges to $\phi$ in the weak topology of $B(\sigma(N_x))$. This proves
\[\rho_x(\phi(N))=\lim_{\alpha}\rho_x(p_\alpha(N,N^*))=\lim_\alpha p_\alpha(N_x,N_x^*)=\phi(N_x).\]

Let $U_x:H_x\to L^2(\mu_x)$ be the isomorphism such that $U_xx=1$ and $U_xN_xU_x^{-1}=N_{\mu_x}$. If $A\in W^*(N)$ and $A_x=\rho_x(A)$, then $A_xN_x=N_xA_x$; thus $U_xA_xU_x^{-1}\in\{N_{\mu_x}\}'$. By Corollary~\ref{L^2 space commutant of multiplication by identity}, there is a $\phi$ in $B(\sigma(N_x))$ such that $U_xA_xU_x^{-1}=M_\phi=\phi(N_{\mu_x})$; it follows that $A_x=\phi(N_x)$.\par
Finally, to show that $\rho_x$ is surjective note that if $B\in W^*(N_x)$, then (use the argument in the preceding paragraph) $B=\phi(N_x)$ for some $\phi$ in $B(\sigma(N_x))$. Extend $\phi$ to $\sigma(N)$ by letting $\phi=0$ outside $\sigma(N_x)$, then $\phi(N)\in W^*(N)$ and $\rho_x(\phi(N))=\phi(N_x)=B$.
\end{proof}
\begin{lemma}\label{Hilbert space scalar spectral measure char}
If $e\in H$ is such that $\mu_e$ is a scalar-valued spectral measure for $N$ and if $\nu$ is a positive measure on $\sigma(N)$ such that $\nu\ll\mu_e$, then there is an $x\in H_e$ such that $\nu=\mu_x$.
\end{lemma}
\begin{proof}
This proof is just an application of the Radon-Nikodym Theorem once certain identifications are made; namely, if $f=[d\nu/d\mu_e]^{1/2}\in L^2(\mu_e)$, then put $x=U_{e}^{-1}f$, so $x\in H_e$. For any Borel set $\Delta$, we have
\begin{align*}
\nu(\Delta)&=\int\chi_\Delta\,d\nu=\int\chi_\Delta f^2\,d\mu_e=\langle M_{\chi_\Delta}f,f\rangle_{L^2(\mu_e)}=\langle \chi_\Delta(N_{\mu_e}) f,f\rangle_{L^2(\mu_e)}\\
&=\langle U_e^{-1}\chi_\Delta(N_{\mu_e})f,U_e^{-1}f\rangle_{L^2(\mu_e)}=\langle\chi_\Delta(N_e)U_e^{-1}f,U_e^{-1}f\rangle_H\\
&=\langle E(\Delta)x,x\rangle_H=\mu_x(\Delta).
\end{align*}
Thus the lemma is proved.
\end{proof}
\begin{lemma}
$W^*(N)=\{\phi(N):\phi\in B(\sigma(N))\}$.
\end{lemma}
\begin{proof}
Let $\mathfrak{A}=\{\phi(N):\phi\in B(\sigma(N))\}$. Hence $\mathfrak{A}$ is a $*$-algebra and $\mathfrak{A}\sub W^*(N)$. Since $N\in\mathfrak{A}$ it suffices to prove that $\mathfrak{A}$ is strongly closed. Let $\{\phi_\alpha\}$ be a net in $B(\sigma(N))$ such that $\phi_\alpha(N)\to A$ strongly; so $A\in W^*(N)$. By Lemma~\ref{Hilbert space restriction on von Neumann algebra} we see $\phi_\alpha(N_x)\to A|_{H_x}$ for any $x\in H$. Also, by Lemma~\ref{Hilbert space restriction on von Neumann algebra}, for every $x\in H$ there is a $\phi_x$ in $B(\C)$ such that $A|_{H_x}=\phi_x(N_x)$. Fix a separating vector $e$ for $W^*(N)$; so $\mu_e$ is a scalar-valued spectral measure for $N$.\par
Now for any $x\in H$, then the fact that $\phi_\alpha(N)\to A$ implies $\phi_\alpha\to\phi_x$ weak$^*$ in $L^\infty(\mu_x)$. But $\mu_x\ll\mu_e$ so that $d\mu_x/d\mu_e\in L^1(\mu_e)$; hence for any Borel set $\Delta$,
\[\int_\Delta\phi_\alpha\,d\mu_x=\int_\Delta\phi_\alpha\frac{d\mu_x}{d\mu_e}\,d\mu_e\to\int_\Delta\phi_e\frac{d\mu_x}{d\mu_e}\,d\mu_e=\int_\Delta\phi_e\,d\mu_x.\]
But $\int_\Delta\phi_\alpha\,d\mu_x$ also tends to $\int_\Delta\phi_x\,d\mu_x$, so this implies $\phi_x=\phi_e$ $\mu_e$-a.e. But if $y\in H_x$, then
\[\langle\phi_x(N_x)y,y\rangle=\langle\phi_x(N)y,y\rangle=\int\phi_x\,d\mu_y=\int\phi_e\,d\mu_y\]
since $\mu_y\ll\mu_e$. Thus $\phi_x(N_x)=\phi_e(N_x)$. In particular, $Ax=\phi_x(N_x)x=\phi_e(N_x)x=\phi_e(N)$, so $A=\phi_e(N)$.
\end{proof}
\begin{corollary}
If $\rho_x:W^*(N)\to W^*(N_x)$ is the $*$-epimorphism of Lemma~\ref{Hilbert space restriction on von Neumann algebra}, then
\[\ker\rho_x=\{\phi(N):\text{$\phi=0$ $\mu_x$-almost everywhere }\}.\]
\end{corollary}
The following theorem is now easy to prove.
\begin{theorem}\label{Hilbert space normal operator separating vector iff}
If $N$ is a normal operator and $e\in H$, the following statements are equivalent.
\begin{itemize}
\item[(\rmnum{1})] $e$ is a separating vector for $W^*(N)$.
\item[(\rmnum{2})] $\mu_e$ is a scalar-valued spectral measure for $N$.
\item[(\rmnum{3})] The map $\rho_e:W^*(N)\to W^*(N_e)$ defined in Lemma~\ref{Hilbert space restriction on von Neumann algebra} is a $*$-isomorphism.
\item[(\rmnum{4})] For $\phi\in B(\sigma(N))$, $\phi(N)=0$ iff $\phi=0$ $\mu_e$-a.e. 
\end{itemize}
\end{theorem}
\begin{proof}
We have already seen the equivalence of (\rmnum{1}) and (\rmnum{2}). Also, the map $\rho_e$ in (\rmnum{3}) is a $*$-epimorphism with kernel $\{\phi(N):\text{$\phi=0$ $\mu_e$-a.e.}\}$. But if $\phi=0$ $\mu_e$-a.e., then (\rmnum{2}) implies that $\phi=0$ off a set $\Delta$ such that $E(\Delta)=0$. Thus $\phi(N)=\int\phi\,dE=0$. This proves $(\rmnum{2})\Rightarrow(\rmnum{3})$.\par
Finally, Suppose $A\in W^*(N)$ and $Ae=0$. By Lemma 8.7, there is a $\phi$ in $B(\sigma(N))$ such that $\phi(N)=A$. Thus, $0=\|Ae\|^2=\int|\phi|^2\,d\mu_e$. This implies $\phi=0$ $\mu_e$-a.e.. Thus (\rmnum{4}) implies (\rmnum{1}). 
\end{proof}
These results can now be combined to yield the final statement of the functional calculus for normal operators.
\begin{theorem}\label{Hilbert space normal operator functional calculus prop}
If $N$ is a normal operator on the separable Hilbert space $H$ and $\mu$ is a scalar-valued spectral measure for $N$, then there is a well-defined map $\rho:L^\infty(\mu)\to W^*(N)$ given by the formula $\rho(\phi)=\phi(N)$ such that
\begin{itemize}
\item[(a)] $\rho$ is a $*$-isomorphism and an isometry;
\item[(b)] $\rho$ is a homeomorphism if both $L^\infty(\mu)$ and $W^*(N)$ are endowed with weak topologies.
\end{itemize}
\end{theorem}
\begin{proof}
Let $e$ be a separating vector for $W^*(N)$. Then $\mu_e$ is a scalar-valued spectral measure, so $\mu$ and $\mu_e$ are mutually absolutely continuous. By Lemma~\ref{Hilbert space scalar spectral measure char}, there exists $x\in H_e$ such that $\mu=\mu_x$. By Theorem~\ref{Hilbert space normal operator separating vector iff}, $x$ is also separating. Therefore we may assume that $\mu=\mu_e$ for some separating vector $e$.\par
If $\phi\in B(\sigma(N))$, then $\phi(N)=0$ iff $\phi=0$ $\mu$-a.e. by Theorem~\ref{Hilbert space normal operator separating vector iff}, so $\rho$ is well-defined and injective. Since $W^*(N)=\{\phi(N):\phi\in B(\sigma(N))\}$, $\rho$ is also surjective, hence a $*$-isomorphism. By Theorem~\ref{C^* algebra homomorphism prop}, $\rho$ is an isometry.\par
Let $\{\phi_\alpha\}$ be a net in $L^\infty(\mu)$ and suppose that $\phi_\alpha(N)\to 0$ weakly. If $f\in L^1(\mu)$ and $f\geq 0$, then defined $\mu_f$ by $d\mu_f=fd\mu$. Since $\mu_f\ll\mu$ and is positive, there is a vector $x$ such that $\mu_f=\mu_x$. Then
\[\int\phi_\alpha f\,d\mu=\int\phi_\alpha\,d\mu_x=\langle\phi_\alpha(N)x,x\rangle\to 0.\]
Thus $\phi_\alpha\to 0$ weakly in $L^\infty(\mu)$. Conversely, if $\phi_\alpha\to 0$ weakly in $L^\infty(\mu)$, then for each $x\in H$, since $\mu_x\ll\mu$, we have $\langle\phi_\alpha(N)x,x\rangle\to 0$, hence $\phi_\alpha(N)\to 0$. These together prove (b).
\end{proof}
Recall that the spectrum of $\phi$ as an element in $L^\infty(\mu)$ is the essentially range of $\phi$, so we get the following spectral mapping theorem.
\begin{theorem}[\textbf{Spectral Mapping Theorem}]
If $N$ is a normal operator on a separable space and $\mu$ is a scalar-valued spectral measure for $N$ and if $\phi\in L^\infty(\mu)$, then $\sigma(\phi(N))=\mathrm{ess.ran}(\phi)$.
\end{theorem}
\section{Unbounded operators}
\subsection{Basic properties}
The first relaxation in the concept of operator is not to assume that the operators are defined everywhere on the Hilbert space.
\begin{definition}
If $H$, $K$ are Hilbert spaces, a \textbf{linear operator} $A:H\to K$ is a function whose domain of definition is a linear subspace, $D(A)$, in $H$ and such that $A(\alpha x+\beta y)=\alpha Ax+\beta Ay$ for $x,y\in D(A)$ and $\alpha,\beta\in\C$. $A$ is \textbf{bounded} if there is a constant $c>0$ such that $\|Ax\|\leq c\|x\|$ for all $x\in D(A)$.
\end{definition}
Note that if $A$ is bounded, then $A$ can be extended to a bounded linear operator on $\widebar{D(A)}$ and then extended to $H$ by letting $A$ be $0$ on $D(A)^\bot$. So unless it is specified to the contrary, a bounded operator will always be assumed to be defined on all of $H$.\par
If $A$ is a linear operator from $H$ into $K$, then $A$ is also a linear operator from $\widebar{D(A)}$ into $K$. So we will often only consider those $A$ such that $D(A)$ is dense in $H$; such an operator $A$ is said to be \textbf{densely defined}.\par
If $A,B$ are linear operators from $H$ into $K$, then $A+B$ is defined with $D(A+B)=D(A)\cap D(B)$. If $A:H\to K$ and $B:K\to L$, then $BA$ is a linear operator from $H$ to $L$ with $D(BA)=A^{-1}(D(B))$.
\begin{definition}
If $A,B$ are operators from $H$ into $K$, then $A$ is an \textbf{extension} of $B$ if $D(B)\sub D(A)$ and $Ax=Bx$ whenever $x\in D(B)$. In symbols this is denoted by $B\sub A$. Note that if $A\in\mathcal{B}(H)$, then the only extension of $A$ is itself. So this concept is only of value for unbounded operators.
\end{definition}
If $A:H\to K$, the \textbf{graph} of $A$ is defined by
\[\Gamma(A)=\{x\oplus Ax\in H\oplus K:x\in D(A)\}.\]
It is easy to see that $B\sub A$ if and only if $\Gamma(B)\sub\Gamma(A)$.
\begin{definition}
An operator $A:H\to K$ is \textbf{closed} if its graph is closed in $H\oplus K$. An operator is \textbf{closable} if it has a closed extension. Let $\mathcal{C}(H,K)$ denote the collection of all closed densely defined operators from $H$ into $K$, and $\mathcal{C}(H)=\mathcal{C}(H,H)$.
\end{definition}
When is a subset of $H\oplus K$ a graph of an operator from $H$ into $K$? If $G=\Gamma(A)$ for some $A:H\to K$, then $G$ is a subspace of $H\oplus K$ such that if $0\oplus k\in G$ then $k=0$. The converse is also true. That is, suppose that $G$ is a subspace of $H\oplus K$ such that if $0\oplus k\in G$ then $k=0$. Let $D=\pi_1(G)$. If $x\in D$ and $y_1,y_2\in K$ are such that $x\oplus y_1,x\oplus y_2\in G$, then $y_1=y_2$. That is, for every $x\in D$ there is a unique $y\in K$ such that $x\oplus y\in G$; denote $y$ by $y=Ax$. It is easy to check that $A$ is a linear map and $G=\Gamma(A)$. This gives an internal characterization of graphs that will be useful in the next proposition.
\begin{proposition}\label{Hilbert space operator closable iff graph}
An operator $A:H\to K$ is closable if and only if $\widebar{\Gamma(A)}$ is a graph.
\end{proposition}
\begin{proof}
If $\widebar{\Gamma(A)}$ is a graph, then there is an operator $B:H\to K$ such that $\Gamma(B)=\widebar{\Gamma(A)}$. Clearly $\Gamma(A)\sub\Gamma(B)$, so $A$ is closable.\par
Now assume that $A$ is closable; that is, there is a closed operator $B:H\to K$ with $A\sub B$. If $0\oplus y\in\widebar{\Gamma(A)}$, then $0\oplus y\in\Gamma(B)$ and hence $y=0$. By the remarks preceding this proposition, $\widebar{\Gamma(A)}$ is a graph.
\end{proof}
If $A$ is closable, we call the operator whose graph is $\widebar{\Gamma(A)}$ the \textbf{closure} of $A$, and denoted by $\bar{A}$.\par
Now we define the adjoint of a densely defined operator $A:H\to K$. Since $A$ is not defined on the whole space $H$, we need some modifications.
\begin{definition}
If $A:H\to K$ is densely defined, let
\[D(A^*):=\{y\in K:x\mapsto\langle Ax,y\rangle\text{ is a bounded linear functional on $D(A)$}\}.\]
Because $D(A)$ is dense in $H$, if $y\in D(A^*)$, then there is a unique vector $w\in H$ such that $\langle Ax,y\rangle=\langle x,w\rangle$ for all $x\in D(A)$. Denote this unique vector $w$ by $w=A^*y$. Thus
\[\langle Ax,y\rangle=\langle x,A^*y\rangle\]
holds for $x\in D(A)$ and $y\in D(A^*)$. The operator $A^*:K\to H$ is clealry linear. It is called the \textbf{adjoint} of $A$.
\end{definition}
\begin{proposition}\label{Hilbert space unbounded sum composition and adjoint}
Let $A$ and $B$ be densely defined operators.
\begin{itemize}
\item[(a)] If $BA$ is densely defined then $(BA)^*\sups A^*B^*$. 
\item[(b)] If $A+B$ is densely defined then $(A+B)^*\sups A^*+B^*$, and the equality holds if one of $A$ and $B$ is defined on $H$.
\end{itemize}
\end{proposition}
\begin{proof}
Let $A:H\to K$ and $B:K\to L$. If $z\in D(A^*B^*)$, then for every $x\in D(BA)$, we have
\[\langle BAx,z\rangle=\langle Ax,B^*z\rangle=\langle x,A^*B^*z\rangle,\]
so $z\in D((BA)^*)$ and $(BA)^*z=(A^*B^*)z$. This proves $(BA)^*\sups A^*B^*$.\par
Similarly, assume $A:H\to K$ and $B:H\to K$. If $y\in D(A^*+B^*)$ then we have
\[\langle (A+B)x,y\rangle=\langle Ax,y\rangle+\langle Bx,y\rangle=\langle x,A^*y\rangle+\langle x,B^*y\rangle=\langle x,(A^*+B^*)y\rangle.\]
Thus $y\in D((A+B)^*)$ and $(A+B)^*y=A^*y+B^*y$, which proves $(A+B)^*\sups A^*+B^*$.\par
Now assume that $A$ is defined on $H$ and $A+B$ is densely defined. Let $y\in(A+B)^*$, then for $x\in D(A+B)=D(B)$,
\[\langle x,(A+B)^*y\rangle=\langle(A+B)x,y\rangle=\langle Ax,y\rangle+\langle Bx,y\rangle=\langle x,A^*y\rangle+\langle Bx,y\rangle.\]
Thus $\langle Bx,y\rangle=\langle x,(A+B)^*y-A^*y\rangle$, which implies $y\in D(B^*)$. This shows $D((A+B)^*)=D(B^*)=D(A^*+B^*)$, so $(A+B)^*=A^*+B^*$.
\end{proof}
\begin{proposition}\label{Hilbert space closable and adjoint}
If $A:H\to K$ is a densely defined operator, then:
\begin{itemize}
\item[(a)] $A^*$ is a closed operator;
\item[(b)] $A^*$ is densely defined if and only if $A$ is closable;
\item[(c)] if $A$ is closable then $A^*=(\bar{A})^*$. 
\item[(c)] if $A$ is closable, then its closure is given by $\bar{A}=A^{**}$.
\end{itemize}
\end{proposition}
Before proving this, a lemma is needed which will also be useful later.
\begin{lemma}\label{Hilbert space char of graph of adjoint}
If $A:H\to K$ is densely defined and $J:H\oplus K\to K\oplus H$ is defined by $J(x\oplus y)=(-y)\oplus x$, then $J$ is an isomorphism and
\[\Gamma(A^*)=J(\Gamma(A))^\bot.\]
\end{lemma}
\begin{proof}
It is clear that $J$ is an isomorphism. To prove the formula for $\Gamma(A^*)$, note that $\Gamma(A^*)=\{x\oplus A^*x:x\in D(A^*)\}$. So if $x\in D(A^*)$ and $y\in D(A)$,
\[\langle x\oplus A^*x,J(y\oplus Ay)\rangle=\langle x\oplus A^*x,(-Ay)\oplus y\rangle=\langle x,-Ay\rangle+\langle A^*x,y\rangle=0.\]
Thus $\Gamma(A^*)\sub J(\Gamma(A))^\bot$. Conversely, if $x\oplus y\in J(\Gamma(A))^\bot$, then for every $w\in D(A)$, we have
\[0=\langle x\oplus y,J(w\oplus Aw)\rangle=\langle x\oplus y,(-Aw)\oplus w\rangle=\langle x,-Aw\rangle+\langle y,w\rangle,\]
whence $\langle Aw,x\rangle=\langle w,y\rangle$. By definition $x\in D(A^*)$ and $y=A^*x$.
\end{proof}
\begin{proof}[Proof of Proposition~\ref{Hilbert space closable and adjoint}]
The proof of (a) is clear from Lemma~\ref{Hilbert space char of graph of adjoint}. For the remainder of the proof notice that because the map $J$ in Lemma~\ref{Hilbert space char of graph of adjoint} is an isomorphism, $J^*=J^{-1}$ and so $J^*(x\oplus y)=y\oplus(-x)$.\par
Let $y_0\in D(A^*)^\bot$, then we observe that
\[y_0\oplus 0\in\Gamma(A^*)^\bot=J(\Gamma(A))^{\bot\bot}=\widebar{J(\Gamma(A))}=J(\widebar{\Gamma(A)}),\]
so $0\oplus(-y_0)\in\widebar{\Gamma(A)}$. Since $\widebar{\Gamma(A)}$ is a graph iff $0\oplus y_0\in\widebar{\Gamma(A)}$ implies $y_0=0$ and $A^*$ is densely defined iff $y_0\in D(A^*)^\bot$ implies $y_0=0$, we see the equivalence in (b).\par
Note that by Lemma~\ref{Hilbert space char of graph of adjoint} we have
\[\Gamma(A^*)=J(\Gamma(A))^\bot=J(\widebar{\Gamma(A)})^\bot=J(\Gamma(\bar{A}))^\bot=\Gamma(\bar{A}^*).\]
Thus $A^*=(\bar{A})^*$. Similarly, we have
\[\Gamma(A^{**})=J^*(\Gamma(A^*))^\bot=J^*(J(\Gamma(A))^\bot)^\bot.\]
But for any subspace $M$ and an isomorphism $J$, $J(M)^\bot=J(M^\bot)$, so it follows that
\[\Gamma(A^{**})=J^*(J(\Gamma(A))^\bot)^\bot=J^*J(\Gamma(A)^{\bot\bot})=\widebar{\Gamma(A)}.\]
This shows that $\bar{A}=\Gamma(A^{**})$.
\end{proof}
\begin{corollary}
If $A\in\mathcal{C}(H,K)$, then $A^*\in\mathcal{C}(H,K)$ and $A^{**}=A$.
\end{corollary}
\begin{example}\label{Hilbert space diagonal unbounded operator}
Let $\{e_\alpha\}$ be an orthonormal basis for a Hilbert space $H$ and let $\{\lambda_\alpha\}$ be complex numbers. Define $D=\{x\in H:\sum_n|\lambda_\alpha\langle x,e_\alpha\rangle|^2<+\infty\}$ and defined $A:H\to K$ by
\[Ax=\sum_\alpha\lambda_\alpha\langle x,e_\alpha\rangle e_\alpha.\]
Then $A$ is a linear operator with $D(A)=D$. Since $D$ contains each $e_n$, it follows that $A\in\mathcal{C}(H)$. Also, it is easy to see
\[A^*x=\sum_\alpha\bar{\lambda}_\alpha\langle x,e_\alpha\rangle e_\alpha\]
and $D(A^*)=D(A)$.
\end{example}
\begin{example}\label{L^2 unbounded multiplication operator}
Let $(X,\mathcal{A},\mu)$ be a $\sigma$-finite measure space and let $\phi:X\to\C$ be a $\mathcal{A}$-measurable function. Let $D=\{f\in L^2(\mu):\phi f\in L^2(\mu)\}$ and define $Af=\phi f$ for all $f\in L^2(\mu)$. Then $A\in\mathcal{C}(L^2(\mu))$, $D(A)=D(A^*)=D$, and $A^*f=\bar{\phi}f$ for $f\in L^2(\mu)$.
\end{example}
\begin{example}
If $H$ is a separable Hilbert space with orthonormal basis $\{e_n\}$ and $A$ is defined by $Ae_n=ne_1$, then $A$ extends linearly to the (dense) linear subspace $D_0$ of finite linear combinations of basis vectors $e_n$. If we denote this extension by $A$ again (so that $D(A)=D_0$), then $A$ is densely defined, unbounded, and not closable. To see this, it suffices to note that $n^{-1}e_n\to 0$ but $A(n^{-1}e_n)=e_1$, so $0\oplus e_1\in\widebar{\Gamma(A)}$.
\end{example}
\begin{example}\label{L^2([0,1]) differentiation map eg-1}
Let $H=L^2([0,1])$ and define
\[D=\{f\in L^2([0,1]):\text{$f$ is absolutely
continuous, $f'\in L^2([0,1])$, and $f(0)=f(1)=0$}\}.\]
Then $D$ contains polynomials $p$ with $p(0)=p(1)=0$, so $D$ is dense in $H$. Define $A:H\to H$ by $Af=if'$ for $f\in D$. If $\{f_n\}\sub D$ is a sequence such that $f_n\to f$ and $Af_n=if_n'\to g$ in $L^2$. Let $h(x)=-i\int_0^xg(t)dt$, so $h$ is absolutely continuous with $h'=-g$. Now using the Cauchy-Schwa~z inequality we get that
\[|f_n(x)-h(x)|=\Big|\int_0^x[f_n'(t)+ig(t)]\,dt\Big|\leq\|f_n'+ig\|_2=\|if_n'-g\|_2\]
Thus $f_n(x)\to h(x)$ uniformly on $[0,1]$. Since $f_n\to f$ in $L^2$, $f=h$ a.e. So we may assume that $f(x)=-i\int_0^xg(t)dt$ for all $x$. Therefore $f$ is absolutely continuous and $f_n(x)\to f(x)$ uniformly on $[0,1]$; thus $f(0)=f(1)=0$ and $g=if'$. This proves $A\in\mathcal{C}(H)$. Note that
\[R(A)=\{f':f\in D\}=\{h\in L^2([0,1]):\int_0^1h(x)\,dx=0\}=\{1\}^\bot.\]
Now we consider the adjoint $A^*$. We claim that
\[D(A^*)=\{g\in L^2([0,1]):\text{$g$ is absolutely
continuous, $g'\in L^2([0,1])$}\}\]
and $A^*g=ig'$ for $g\in D(A^*)$. To see this, suppose $g\in D(A^*)$ and let $h=A^*g$. Put $H(x)=\int_0^xh(t)\,dt$. Using integration by parts, for every $f\in D$, we have
\[\int_0^1if'\bar{g}=\langle Af,g\rangle=\langle f,h\rangle=\int_0^1f\bar{h}=-\int_0^1f'\bar{H}.\]
That is, $\langle f',-ig\rangle=\langle f',-H\rangle$ for all $f\in D$. Thus $H-ig\in D(A)^\bot=\{1\}^{\bot\bot}$. Hence $H-ig=c$ is a constant function. Thus $g=ic-iH$ so that $g$ is absolutely continuous and $g'=-ih\in L^2([0,1])$. Also, note that $A^*g=h=ig'$. Conversely, if $g\in L^2([0,1])$ and $g'\in L^2$, then by integration by parts,
\[\langle if',g\rangle=i\int_0^1f'\bar{g}=-i\int_0^1 f\bar{g}'=\langle f,ig'\rangle.\]
Thus $g\in D(A^*)$ with $A^*g=ig'$.
\end{example}
\begin{example}\label{L^2([0,1]) differentiation map eg-2}
Again let $H=L^2([0,1])$, but consider $Bf=if'$ where
\[D(B)=\{f\in L^2([0,1]):\text{$f$ is absolutely
continuous, $f'\in L^2([0,1])$, and $f(0)=f(1)$}\}.\]
Then as in the previous example, $B\in\mathcal{C}(H)$ and $R(B)=\{1\}^\bot$. We claim that $D(B^*)=D(B)$ in this case, and $B^*g=ig'$ for $g\in D(B)$. For one direction, if $g\in D(B)$ then integration by parts implies that $g\in D(B^*)$ and $B^*g=ig'$. Conversely, let $g\in D(B^*)$. Put $h=B^*g$ and $H(x)=\int_0^xh(t)\,dt$. As in Example~\ref{L^2([0,1]) differentiation map eg-1}, $H(0)=H(1)=0$ and $H-ig\in\{1\}^{\bot\bot}$ and so is a constant $c$. Thus $g=ic-iH$, which proves $g\in D(B)$, with $h=ig'$.
\end{example}
The preceding two examples illustrate the fact that the calculation of the adjoint depends on the domain of the operator, not just the formal definition of the operator.
\begin{proposition}\label{Hilbert space unbounded kernel and adjoint}
If $A:H\to K$ is densely defined, then $N(A^*)=R(A)^\bot$. If $A$ is also closed, then $N(A)=R(A^*)^\bot$. 
\end{proposition}
\begin{proof}
If $A$ is closed then $A=A^{**}$, so the second claim follows from the first one. Let $y\in N(A^*)$, then for $x\in D(A)$,
\[\langle Ax,y\rangle=\langle x,A^*y\rangle=0.\]
Thus $y\in R(A)^\bot$. Conversely, if $y\in R(A)^\bot$, then for every $x\in D(A)$, $\langle Ax,y\rangle=0$. Hence $y\in D(A^*)$ and $A^*y=0$.
\end{proof}
\begin{proposition}\label{Hilbert space unbounded inverse and adjoint}
Let $A:H\to K$ be densely defined, closed, injective with dense range. Then
\begin{itemize}
\item[(a)] $A^{-1}$ is densely defined, closed, injective and with a dense range.
\item[(b)] $A^*$ is densely defined, closed, injective and with a dense range.
\item[(c)] $(A^{-1})^*=(A^*)^{-1}$.
\end{itemize}
\end{proposition}
\begin{proof}
Since $A$ is injective with dense range, it follows that $A^{-1}$ is densely defined and injective. Let $\tau:H\oplus K\to K\oplus H$ be the reflection map: $\tau(x\oplus y)=y\oplus x$. Then $\Gamma(A)=\tau(\Gamma(A^{-1}))$, so $A^{-1}$ is closed.\par
Since $A$ is closed, we have $A^*$ is densely defined and $N(A)=R(A^*)^\bot$ and $N(A^*)=R(A)^\bot$, so $A^*$ is injective with dense range. $A^*$ is closed by Proposition~\ref{Hilbert space closable and adjoint}.\par
Finally, recall that $\Gamma(A^*)=J(\Gamma(A))$ and $\Gamma(A^{-1})=\tau(\Gamma(A))$, so
\[\Gamma((A^{-1})^*)=J(\Gamma(A^{-1}))=J(\tau(\Gamma(A))),\quad\Gamma((A^*)^{-1})=\tau(\Gamma(A^*))=\tau(J(\Gamma(A))).\]
It is easy to see $J\tau=\tau J$, so the last claim follows.
\end{proof}
\begin{definition}
If $A:H\to K$ is a linear operator, we say $A$ is \textbf{bounded invertible} if there is a bounded linear operator $B:K\to H$ such that $AB=I$ and $BA=I$.
\end{definition}
Note that if $B:K\to H$ is bounded and $BA\sub I$, then $BA$ is bounded on its domain. We say $B$ is a \textbf{(bounded) inverse} of $A$ in this case.
\begin{proposition}\label{Hilbert space unbounded bounded invertible iff}
Let $A:H\to K$ be a linear operator.
\begin{itemize}
\item[(a)] $A$ is boundedly invertible if and only if $A$ is closed and bijective on its domain.
\item[(b)] If $A$ is boundedly invertible, its inverse is unique and denoted by $A^{-1}$.
\end{itemize}
\end{proposition}
\begin{proof}
Let $B$ be a bounded inverse of $A$. So $D(B)=K$. Since $BA=I$, $N(A)=\{0\}$; since $AB=I$, $R(A)=K$. Also, $\Gamma(A)=\{x\oplus Ax:x\in D(A)\}=\{By\oplus y:y\in K\}$. Since $B$ is bounded, $\Gamma(A)$ is closed. Conversely, if $A$ has the stated properties, then $By=A^{-1}y$ for $y\in K$ is a well-defined operator on $K$. Because $\Gamma(A)$ is closed, $\Gamma(B)$ is closed. By the closed graph theorem, $B$ is bounded. The second claim is clear.
\end{proof}
\begin{proposition}\label{Hilbert space unbounded invertible iff adjoint is}
Let $A:H\to K$ be densely defined and closed. Then the following conditions are equivalent.
\begin{itemize}
\item[(\rmnum{1})] $A$ is boundedly invertible.
\item[(\rmnum{2})] $A^*$ is boundedly invertible.
\item[(\rmnum{3})] There exists $c>0$ such that $\|Ax\|\geq c\|x\|$ for $x\in D(A)$ and $\|A^*y\|\geq c\|y\|$ for $y\in D(A^*)$.
\end{itemize}
\end{proposition}
\begin{proof}
If $A$ is bounded invertible then $A^{-1}$ is bounded, so $(A^{-1})^*$ is bounded. By Proposition~\ref{Hilbert space unbounded inverse and adjoint} we have $(A^*)^{-1}=(A^{-1})^*$, so $A^*$ is bounded invertible. Since $A^{**}=A$, we also have $(\rmnum{2})\Rightarrow(\rmnum{1})$.\par
It is obvious that (\rmnum{1}) and (\rmnum{2}) imply (\rmnum{3}). Let us prove that $(\rmnum{3})\Rightarrow(\rmnum{1})$. If (\rmnum{3}) holds then $A$ and $A^*$ are injective with closed image, hence by Proposition~\ref{Hilbert space unbounded kernel and adjoint}, $A$ and $A^*$ are bijective. This proves they are boundedly invertible.
\end{proof}
\begin{definition}
If $A:H\to K$ is a linear operator, $\rho(A)$, the \textbf{resolvent set} for $A$, is defined by
\[\rho(A)=\{\lambda\in\C:\text{$A-\lambda I$ is boundedly invertible}\}.\] The \textbf{spectrum} of $A$ is the set $\sigma(A)=\C\setminus\rho(A)$.
\end{definition}
It is easy to see that if $A:H\to K$ is a linear operator and $\lambda\in\C$, then $A-\lambda I$ is closed if and only if $A$ is closed. So if $A$ does not have closed graph, $\sigma(A)=\C$. Even if $A$ has closed graph, it is possible that $\sigma(A)$ is empty.
\begin{example}
Consider the operator $Af=f'$ defined on the subspace
\[D=\{f\in L^2([0,1]):\text{$f$ is absolutely continuous, $f'\in L^2([0,1])$ and $f(0)=0$}\}.\]
Then as in Example~\ref{L^2([0,1]) differentiation map eg-1}, $A\in\mathcal{B}(H)$. To show that $A$ has no spectrum, it is enough to prove that the resolvent $R(\lambda)=(A-\lambda I)^{-1}$ exists everywhere. To do this, given $g\in L^2$, we want to solve the equation
\[f'-\lambda f=g,\quad f(0)=0.\]
Solving this ODE, we get
\[f(x)=e^{\lambda x}\int_0^xe^{-\lambda t}g(t)\,dt.\]
It is easy to see $A-\lambda I$ is closed and injective, thus $\sigma(A)=\emp$.
\end{example}
The spectrum of an unbounded operator, however, does enjoy some of the properties possessed by the spectrum of an element of a Banach algebra. The following results can be proved using Proposition~\ref{Hilbert space unbounded bounded invertible iff} and \ref{Hilbert space unbounded invertible iff adjoint is}.
\begin{proposition}
If $A:H\to K$ is a linear operator, then $\sigma(A)$ is closed and $f(z)=(zI-\lambda)^{-1}$ is an analytic function on $\sigma(A)$.
\end{proposition}
\begin{proposition}
Let $A\in\mathcal{C}(H)$.
\begin{itemize}
\item[(a)] $\lambda\in\rho(A)$ if and only if $N(A-\lambda I)=\{0\}$ and $R(A-\lambda I)=H$.
\item[(b)] $\sigma(A^*)=\sigma(A)^*$ and for $\lambda\in\rho(A)$, $(A-\lambda I)^{*-1}=[(A-\lambda I)^{-1}]^*$.
\end{itemize}
\end{proposition}
\subsection{Symmetric and self-adjoint operators}
An appropriate introduction to this part consists in a careful examination
of Examples~\ref{L^2([0,1]) differentiation map eg-1} and \ref{L^2([0,1]) differentiation map eg-2} in the preceding section. In Examples~\ref{L^2([0,1]) differentiation map eg-1} we saw that the operator $A$ seemed to be inclined to be self-adjoint, but $D(A^*)$ was different from $D(A)$ so we could not truly say that $A=A^*$. In Examples~\ref{L^2([0,1]) differentiation map eg-2}, $B=B^*$ in any sense of the concept of equality. This points out the distinction between symmetric and self-adjoint operators that it is necessary to make in the theory of unbounded operators.
\begin{definition}
A densely defined operator $A:H\to H$ is \textbf{symmetric} if $\langle Ax,y\rangle=\langle x,Ay\rangle$ for all $x,y\in D(A)$.
\end{definition}
\begin{proposition}\label{Hilbert space unbounded symmetric iff}
If $A$ is densely defined, the following statements are equivalent.
\begin{itemize}
\item[(a)] $A$ is symmetric.
\item[(b)] $\langle Ax,x\rangle\in \R$ for all $x\in D(A)$.
\item[(c)] $A\sub A^*$.
\end{itemize}
Moreover, if $A$ is symmetric, then $A$ is closable and $\bar{A}$ is symmetric.
\end{proposition}
\begin{proof}
It is clear that (\rmnum{1}) is equivalent to (\rmnum{3}) and implies (\rmnum{2}). The implication $(\rmnum{2})\Rightarrow(\rmnum{1})$ follows as in Proposition~\ref{Hilbert space Hermitian iff}.\par
If $A$ is symmetric, then the fact that $A\sub A^*$ implies $D(A^*)$ is dense. Hence $A$ is closable by Proposition~\ref{Hilbert space closable and adjoint}. Now assume that $x,y\in D(\bar{A})$, so there are sequences $\{x_n\}$ and $\{y_n\}$ in $D(A)$ such that $x_n\oplus Ax_n\to x\oplus\bar{A}x$ and $y_n\oplus Ay_n\to y\oplus\bar{A}y$. Then we see that
\[\langle \bar{A}x,y\rangle=\lim_{n\to+\infty}\langle Ax_n,y_n\rangle=\lim_{n\to+\infty}\langle x_n,Ay_n\rangle=\langle x,\bar{A}y\rangle.\]
Therefore $\bar{A}$ is also symmetric.
\end{proof}
\begin{definition}
A densely defined operator $A:H\to H$ is \textbf{self-adjoint} if $A=A^*$; it is \textbf{essentially self-adjoint} if $A$ is symmetric and $\bar{A}$ is slef-adjoint.
\end{definition}
Let us emphasize that the condition that $A=A^*$ in the preceding definition carries with it the requirement that $D(A)=D(A^*)$. Now clearly every self-adjoint operator is symmetric, but the operator $A$ in Example~\ref{L^2([0,1]) differentiation map eg-1} shows that there are symmetric operators that are not self-adjoint. If, however, an operator is bounded, then it is self-adjoint if and only if it is symmetric. The operator $B$ in Example~\ref{L^2([0,1]) differentiation map eg-2} is an unbounded self-adjoint operator.\par
The following properties for (essentially) slef-adjoint operators are immediate.
\begin{proposition}
A self-adjoint operator is closed, and is bounded if $D(A)=H$.
\end{proposition}
\begin{proof}
Assume that $A$ is self-adjoint. Since $A^*$ is a closed operator, $A$ is closed. Now assume that $D(A)=H$. Then the closed graph theorem implies $A$ is bounded.
\end{proof}
\begin{proposition}\label{Hilbert space symmetric essentially self-adjoint iff}
Let $A$ be a symmetric operator. Then the following are equivalent.
\begin{itemize}
\item[(\rmnum{1})] $A$ is essentially self-adjoint.
\item[(\rmnum{2})] $\bar{A}=A^*$.
\item[(\rmnum{3})] $A^*$ is symmetric.
\end{itemize}
\end{proposition}
\begin{proof}
By Proposition~\ref{Hilbert space unbounded symmetric iff} $A$ is closable, so $A^*$ is densely defined and $(\bar{A})^*=A^*$. Also, we have
\[A\sub\bar{A}=A^{**}\sub A^*.\]
Thus $\bar{A}$ is self-adjoint iff $\bar{A}=A^*$, iff $A^*\sub A^{**}$, iff $A^*$ is symmetric. 
\end{proof}
\begin{example}
Let $Af=if'$ where $D(A)$ is defined by
\[D(A)=\{f\in L^2([0,1]):\text{$f$ is absolutely
continuous, $f'\in L^2([0,1])$, and $f(0)=f(1)=0$}\}.\]
In Example~\ref{L^2([0,1]) differentiation map eg-1} we have proved that $A^*f=if'$ where
\[D(A^*)=\{f\in L^2([0,1]):\text{$f$ is absolutely
continuous and $f'\in L^2([0,1])$}\}.\]
We now claim that $D(\bar{A})\subsetneq D(A^*)$. Let $f\in D(\bar{A})$, so there exists $f_n\in D(A)$ such that $f_n\oplus(if_n')\to f\oplus\bar{A}f$. Since $f_n'\to\bar{A}f$ in $L^2([0,1])$, it follows that, by writing each $f_n$ as the integral of $f_n'$, that $f_n$ converges to $f$ uniformly on $[0,1]$. Thus $f$ is continuous and $f(0)=f(1)=0$. On the other hand, $D(A^*)$ contains all smooth functions on $[0,1]$, which may not vanishes on the boundary of $[0,1]$. Thus $D(\bar{A})\subsetneq D(A^*)$. This implies $A$ is not essentially self-adjoint, though it is symmetric.\par
The reason that $A$ fails to be essentially self-adjoint is that we impose to many boundary conditions on $D(A)$, which results in there being too few boundary conditions on $D(A^*)$. If we consider the operator $B$ in Example~\ref{L^2([0,1]) differentiation map eg-2}, then 
\end{example}
\begin{proposition}\label{Hilbert space symmetric operator prop}
Suppose $A$ is a symmetric operator on $H$.
\begin{itemize}
\item[(a)] If $R(A)$ is dense, then $A$ is injective.
\item[(b)] If $A=A^*$ and $A$ is injective, then $R(A)$ is dense and $A^{-1}$ is self-adjoint.
\item[(c)] If $D(A)=H$, then $A=A^*$ and $A$ is bounded.
\item[(d)] If $R(A)=H$, then $A=A^*$ and $A^{-1}\in\mathcal{B}(H)$.
\end{itemize}
\end{proposition}
\begin{proof}
Since $x\in N(A)$ implies $x\in R(A)^\bot$, claim (a) is immediate. Now if $A=A^*$ and $A$ is injective, then by Proposition~\ref{Hilbert space unbounded kernel and adjoint} we see $R(A)$ is dense, so by Proposition~\ref{Hilbert space unbounded inverse and adjoint}, we have $(A^{-1})^*=(A^*)^{-1}=A^{-1}$, so $A^{-1}$ is self-adjoint.
If $D(A)=H$, then $A$ is bounded by closed graph theorem, hence $A=A^*$. If $R(A)=H$, then $A$ is injective by (a). Let $B=A^{-1}$, so that $D(B)=R(A)=H$. It is easy to see $B$ is symmetric, so by (c) we have $B=B^*$ and $B$ is bounded.
\end{proof}
We now will turn our attention to the spectral properties of symmetric and self-adjoint operators. In particular, it will be seen that symmetric operators can have nonreal numbers in their spectra, though the nature of the spectrum can be completely diagnosed. Self-adjoint operators, however, must have real spectra. The next result begins this spectral discussion.
\begin{proposition}\label{Hilbert space symmetric operator A-lambda I prop}
Let $A$ be a symmetric operator and let $\lambda=a+ib$.
\begin{itemize}
\item[(a)] For each $x\in D(A)$, $\|(A-\lambda I)x\|^2=\|(A-aI)x\|^2+b^2\|x\|^2$.
\item[(b)] If $b\neq 0$, then $N(A-\lambda I)=\{0\}$.
\item[(c)] If $A$ is closed and $b\neq 0$, then $R(A-\lambda I)$ is closed.
\end{itemize}
\end{proposition}
\begin{proof}
Note that
\[\|(A-\lambda I)x\|^2=\|(A-aI)x-ibx\|^2=\|(A-aI)x\|^2+2\Re i\langle(A-aI)x,bx\rangle+b^2\|x\|^2.\]
But $\langle(A-aI)x,bx\rangle=b\langle Ax,x\rangle-a\|x\|^2\in\R$, so (a) follows. Part (b) follows immediate from (a). To prove (c), just note that $\|(A-\lambda I)x\|^2\geq b^2\|x\|^2$. Let $\{x_n\}\sub D(A)$ be such that $(A-\lambda I)x_n\to y$. The preceding inequality implies that $\{x_n\}$ is a Cauchy sequence in $H$, so has a limit $x$. But $x_n\oplus(A-\lambda I)x_n\in\Gamma(A)$ and $x_n\oplus(A-\lambda I)x_n\to x\oplus y$. Hence $x\oplus y\in\Gamma(A)$. This means $x\in D(A)$ and $y=Ax$, hence $R(A-\lambda I)$ is closed.
\end{proof}
\begin{lemma}\label{Hilbert space dim of closed subspace if orthonormal}
If $M,N$ are closed subspaces of $H$ and $M\cap N^\bot=\{0\}$, then $\dim M\leq\dim N$.
\end{lemma}
\begin{proof}
Let $P$ be the orthogonal projection of $H$ onto $N$ and define $T:M\to N$ by $Tx=Px$ for $x\in M$. Since $M\cap N^\bot=\{0\}$, $T$ is injective. If $L$ is a finite dimensional subspace of $M$, then $\dim L=\dim T(L)\leq\dim N$. Since $L$ was arbitrary, $\dim M\leq\dim N$.
\end{proof}
\begin{proposition}\label{Hilbert space closed symmetric operator dim of eigenspace}
If $A$ is a closed symmetric operator, then $\dim N(A^*-\lambda)$ is constant for $\Im\lambda>0$ and constant for $\Im\lambda<0$.
\end{proposition}
\begin{proof}
Let $\lambda=a+bi$ with $b\neq 0$. We claim that if $|\lambda-\mu|<|b|$, then $N(A^*-\mu I)\cap N(A^*-\lambda I)^\bot=\{0\}$. Assume the contrary, then there is an $x$ in $N(A^*-\mu I)\cap N(A^*-\lambda I)^\bot$ with $\|x\|=1$. By Proposition~\ref{Hilbert space symmetric operator A-lambda I prop}, $R(A-\bar{\lambda}I)$ is closed, hence $x\in N(A^*-\lambda I)^\bot=R(A-\bar{\lambda}I)$. Let $y\in D(A)$ be such that $(A-\bar{\lambda I})y=x$. Since $x\in N(A^*-\mu I)$,
\begin{align*}
0=\langle(A^*-\mu I)x,y\rangle=\langle x,(A-\bar{\mu}I)y\rangle=\langle x,(A-\bar{\lambda}I+\bar{\lambda}I-\bar{\mu}I)y\rangle=\|x\|^2+(\lambda-\mu)\langle x,y\rangle.
\end{align*}
Hence $|\lambda-\mu|\|y\|\geq 1$. But Proposition~\ref{Hilbert space symmetric operator A-lambda I prop} implies that $1=\|x\|=\|(A-\bar{\lambda}I)y\|\geq|b|\|y\|$; so $\|y\|\leq|b|^{-1}$. Hence $|\lambda-\mu|\geq|b|$, which is a contradiction.\par
By Lemma~\ref{Hilbert space dim of closed subspace if orthonormal}, we get $\dim N(A^*-\mu I)\leq\dim N(A^*-\lambda I)$ whenever $|\lambda-\mu|<|b|=|\Im\lambda|$. Note that if $|\lambda-\mu|<|b|/2$, then $|\lambda-\mu|<|\Im\mu|$, so that the other inequality also holds. This shows that the function $\dim N(A^*-\lambda I)$ is locally constant on $\C\setminus\R$. A simple topological argument demonstrates the theorem. 
\end{proof}
\begin{theorem}\label{Hilbert space closed symmetric operator spectrum char}
If $A$ is a closed symmetric operator, then one and only one of the following possibilities occurs:
\begin{itemize}
\item[(a)] $\sigma(A)=\C$.
\item[(b)] $\sigma(A)=\{\lambda\in\C:\Im\lambda\geq 0\}$.
\item[(c)] $\sigma(A)=\{\lambda\in\C:\Im\lambda\leq 0\}$.
\item[(d)] $\sigma(A)\sub\R$. 
\end{itemize}
\end{theorem}
\begin{proof}
Let $\mathbb{H}_{\pm}=\{\lambda\in\C:\pm\Im\lambda>0\}$. By Proposition~\ref{Hilbert space symmetric operator A-lambda I prop}, for $\lambda\in\mathbb{H}_{\pm}$, $A-\lambda I$ is injective and has closed range. So if $A-\lambda I$ is surjective, $\lambda\in\rho(A)$. But $R(A-\lambda I)=N(A^*-\bar{\lambda}I)^\bot$, so the preceding theorem implies that either $\mathbb{H}_{\pm}\sub\sigma(A)$ or $\mathbb{H}_{\pm}\cap\sigma(A)=\emp$. Since $\sigma(A)$ is closed, if $\mathbb{H}_{\pm}\sub\sigma(A)$, then either $\sigma(A)=\C$ or $\sigma(A)=\mathbb{H}_{\pm}$. If $\mathbb{H}_{\pm}\cap\sigma(A)=\emp$, then $\sigma(A)\sub\R$.
\end{proof}
\begin{corollary}\label{Hilbert space closed symmetric is self-adjoint iff real spectrum}
If $A$ is a closed symmetric operator, the following statements are equivalent.
\begin{itemize}
\item[(\rmnum{1})] $A$ is self-adjoint.
\item[(\rmnum{2})] $\sigma(A)\sub\R$.
\item[(\rmnum{3})] $N(A^*\pm iI)=\{0\}$, or equivalently $R(A\pm iI)=H$.
\end{itemize}
\end{corollary}
\begin{proof}
If $A$ is symmetric, it is easy to see every eigenvalue of $A$ is real. So if $A=A^*$ and $\Im\lambda\neq 0$, then $N(A^*-\lambda I)=N(A-\lambda I)=\{0\}$. Thus $A-\lambda I$ is injective and has dense range. By Proposition~\ref{Hilbert space symmetric operator A-lambda I prop} $A-\lambda I$ has closed range and so $A-\lambda I$ has a bounded inverse whenever $\Im\lambda\neq 0$. That is, $\sigma(A)\sub\R$. and so (\rmnum{1}) implies (\rmnum{2}). If $\sigma(A)\sub\R$, then $N(A^*\pm iI)=N(A\mp iI)^\bot=H^\bot=\{0\}$, so (\rmnum{2}) implies (\rmnum{3}).\par
If (\rmnum{3}) holds, then $N(A^*-iI)=\{0\}$, combined with Proposition~\ref{Hilbert space unbounded kernel and adjoint} and Proposition~\ref{Hilbert space symmetric operator A-lambda I prop}, implies $A+iI$ is surjective. Let $y\in D(A^*)$. Then there is an $x\in D(A)$ such that $(A+iI)x=(A^*+iI)y$. But $A+iI\sub A^*+iI$, so $(A^*+iI)x=(A^*+iI)y$. But $A^*+iI$ is injective, so $x=y\in D(A)$. Thus $A=A^*$.
\end{proof}
\begin{corollary}\label{Hilbert space closed symmetric R not in spectrum}
If $A$ is a closed symmetric operator and $\R\not\subseteq\sigma(A)$, then $A$ is slef-adjoint.
\end{corollary}
\begin{example}
Consider the operator $A$ in Example~\ref{L^2([0,1]) differentiation map eg-1}. We have shown that $A^*f=if'$ and
\[D(A^*)=\{f\in L^2([0,1]):\text{$f$ is absolutely
continuous and $f'\in L^2([0,1])$}\}.\]
Now let $\lambda\in\C$. Then $f(x)=e^{-i\lambda x}$ satisfies the equation $if'=\lambda f$, so $A^*f=\lambda f$. This shows $\sigma(A^*)=\C$, whence $\sigma(\bar{A})=\C$.
\end{example}
Note that the adjoint of $\bar{A}$ equals to that of $A$, so we also get some criterions for a symmetric operator to be essentially self-adjoint.
\begin{proposition}\label{Hilbert space symmetric operator iff N(A^* pm iI)}
Let $A$ be a symmetric operator. Then $A$ is essentially self-adjoint iff $N(A^*\pm iI)=\{0\}$, or equivalently $R(A\pm iI)$ is dense.
\end{proposition}
\begin{proof}
Since $A^*=(\bar{A})^*$ and $\bar{A}$ is symmetric, the claim follows from Corollary~\ref{Hilbert space closed symmetric is self-adjoint iff real spectrum}.
\end{proof}
\begin{example}
Let $\mathscr{D}(\R)$ be the subspace of $L^2(\R)$ consists of smooth functions with compact support on $\R$, and let $P$ be the operator defined on $\mathscr{D}$ by $Pf=if'$. It is easy to see $P$ is symmetric, using integration by parts. We want to show that $P$ is essentially self-adjoint, using Proposition~\ref{Hilbert space symmetric operator iff N(A^* pm iI)}. To see this, let $f\in N(P^*+iI)$, so that $P^*f=-if$. This holds if and only if
\[i\int_\R g'\bar{f}=\langle Pg,f\rangle=\langle g,-if\rangle=i\int_\R g\bar{f}\]
for all $g\in\mathscr{D}(\R)$. For any $\psi\in\mathscr{D}(\R)$, if we take $g(x)=\psi(x)e^x$, then
\[0=\int_\R(g'-g)\bar{f}=\int_\R\Big[\psi'(x)e^x+\psi(x)e^x-\psi(x)e^x\Big]\widebar{f(x)}\,dx=\int_\R\psi'(x)e^{x}\widebar{f(x)}\,dx.\]
This implies the derivative of the distribution $e^xf(x)$ is zero, hence $f(x)e^x=c$ for some constant $c$, by Proposition~\ref{distribution with zero derivative}. This means $f(x)=ce^{-x}$, and $c=0$ because $f\in L^2$.\par
Thus we have shown that $N(P+iI)=0$, and a similarly argument shows that $N(P-iI)=0$. Thus $P$ is essentially self-adjoint, by Proposition~\ref{Hilbert space symmetric operator iff N(A^* pm iI)}.
\end{example}
Fix a symmetric operator $A$ and suppose $B$ is a symmetric extension of $A$. It is easy to verify that $B^*\sub A^*$. Since $B\sub B^*$, we get $A\sub B\sub B^*\sub A^*$. Thus every symmetric extension of $A$ is a restriction of $A^*$. Note that $A^*$ may not be symmetric, unless $A$ is essentially self-adjoint.
\begin{proposition}\label{Hilbert space symmetric operator maximal extension}
\mbox{}
\begin{itemize}
\item[(a)] A symmetric operator has a maximal symmetric extension.
\item[(b)] Maximal symmetric extensions are closed.
\item[(c)] A self-adjoint operator is a maximal symmetric operator. 
\end{itemize}
\end{proposition}
\begin{proof}
Part (a) is an easy application of Zorn's Lemma. If $A$ is symmetric, then $A\sub A^*$ and $A$ is closable. The closure of a symmetric operator is symmetric, so part (b) is immediate. Part (c) is a consequence of the comments preceding this proposition.
\end{proof}
\begin{definition}
Let $A$ be a closed symmetric operator. The \textbf{deficiency subspaces} of $A$ are the spaces
\[\mathscr{L}_{+}=N(A^*-iI)=R(A+iI)^\bot,\quad\mathscr{L}_{-}=N(A^*+iI)=R(A-iI)^\bot.\]
The \textbf{deficiency indices} of $A$ are the numbers $n_{\pm}=\dim\mathscr{L}_{\pm}$.
\end{definition}
In order to study the closed symmetric extensions of a symmetric operator we also introduce the spaces
\[\mathscr{K}_+=\{x\oplus ix:x\in\mathscr{L}_+\},\quad \mathscr{K}_+=\{x\oplus(-ix):x\in\mathscr{L}_-\}.\]
So $\mathscr{K}_{\pm}$ are closed subspaces of $H\oplus H$. Notice that $K_{\pm}$ are contained in $\Gamma(A^*)$ and are the portions of graph of $A^*$ that lie above $\mathscr{L}_{\pm}$. The next lemma will indicate why the deficiency subspaces are so named.
\begin{lemma}\label{Hilbert space closed symmetric graph of dual}
If A is a closed symmetric operator, then
\[\Gamma(A^*)=\Gamma(A)\oplus\mathscr{K}_+\oplus\mathscr{K}_-.\]
\end{lemma}
\begin{proof}
Let $x\in\mathscr{L}_+$ and $y\in D(A)$. Then
\[\langle y\oplus Ay,x\oplus ix\rangle=\langle y,x\rangle-i\langle Ay,x\rangle=-i\langle(A+iI)y,x\rangle=0\]
since $\mathscr{L}_+=R(A+iI)^\bot$. The remainder of the proof that $\Gamma(A)$, $\mathscr{L}_+$, and $\mathscr{L}_-$ are pairwise orthogonal can be done similarly. Since it is clear that $\Gamma(A)\oplus\mathscr{K}_+\oplus\mathscr{K}_-$, it remains to show that this direct sum is dense in $\Gamma(A^*)$.\par
Let $y\in D(A^*)$ be such that $y\oplus A^*y$ is orthogonal to $\Gamma(A)\oplus\mathscr{K}_+\oplus\mathscr{K}_-$. Then for each $x\in D(A)$,
\[0=\langle x\oplus Ax,y\oplus A^*y\rangle=\langle x,y\rangle+\langle Ax,A^*y\rangle,\]
so $\langle Ax,A^*y\rangle=\langle x,-y\rangle$ for every $x\in D(A)$. This implies $A^*y\in D(A^*)$ and $A^*A^*y=-y$. Therefore $(A^*-iI)(A^*+iI)y=0$. Thus $(A^*+iI)y\in\mathscr{L}_+$. Reversing the order of these factors also shows that $(A^*-iI)y\in\mathscr{L}_-$. But if $x\in\mathscr{L}_+$, then
\[0=\langle x\oplus ix,y\oplus A^*y\rangle=\langle x,y\rangle+i\langle x,A^*y\rangle=i\langle x,(A^*+iI)y\rangle.\]
Since g can be taken equal to $(A^*+iI)y$, we get that $(A^*+iI)y=0$, or $y\in\mathscr{L}_-$. Similarly, $y\in\mathscr{L}_+$, so $y=0$.
\end{proof}
\begin{definition}
If $A$ is a closed symmetric operator and $M$ is a subspace of $D(A^*)$, then $M$ is called \textbf{$\bm{A}$-symmetric} if $\langle A^*x,g\rangle=\langle x,A^*y\rangle$ for all $x,y\in M$. Such an $M$ is called \textbf{$\bm{A}$-closed} if $\{x\oplus A^*x:x\in M\}$ is closed in $H\oplus H$.
\end{definition}
So $M$ is both $A$-symmetric and $A$-closed precisely when $A^*|_M$, the restriction of $A^*$ to $M$, is a closed symmetric operator; if $M\sups D(A)$, then $A^*|_M$ is a closed symmetric extension of $A$.
\begin{proposition}\label{Hilbert space symmetric extension graph}
If $A$ is a closed symmetric operator on $H$ and $B$ is a closed symmetric extension of $A$, then there is an $A$-closed, $A$-symmetric subspace $M$ of $\mathscr{L}_++\mathscr{L}_-$ such that
\begin{align}\label{Hilbert space symmetric extension graph-1}
\Gamma(B)=\Gamma(A)+\Gamma(A^*|_{M}).
\end{align}
Conversely, if $M$ is an $A$-closed, $A$-symmetric subspace in $\mathscr{L}_++\mathscr{L}_-$, then there is a closed symmetric extension $B$ of $A$ such that $(\ref{Hilbert space symmetric extension graph-1})$ holds.
\end{proposition}
\begin{proof}
If the $A$-closed, $A$-symmetric subspace $M$ in $\mathscr{L}_++\mathscr{L}_-$ is given, let $D=D(A)+M$. Since $M\sub D(A^*)$, $B=A^*|_{D}$ is well defined. Let $x=x_0+x_1$, $y=y_0+y_1$ where $x_0,y_0$ in $D(A)$ and $x_1,y_1\in M$. Then
\[\langle A^*x,y\rangle=\langle A^*x_0+A^*x_1,y_0+y_1\rangle=\langle Ax_0,y_0\rangle+\langle Ax_0,y_1\rangle+\langle A^*x_1,y_0\rangle+\langle A^*x_1,y_1\rangle.\]
Using the $A$-symmetry of $M$, the symmetry of $A$, and the definition of $A^*$ we get
\[\langle A^*x,y\rangle=\langle x_0,Ay_0\rangle+\langle x_0,A^*y_1\rangle+\langle x_1,Ay_0\rangle+\langle x_1,A^*y_1\rangle=\langle f,A^*y\rangle.\]
So $B=A^*|_D$ is symmetric. Note that $\Gamma(A)\bot\Gamma(A^*|_M)$ in $H\oplus H$, because $M\sub\mathscr{L}_++\mathscr{L}_-$. Since both of these spaces are closed, $\Gamma(B)$, given by $(\ref{Hilbert space symmetric extension graph-1})$, is closed.\par
Now let $B$ be any closed symmetric extension of $A$. As discussed before, $A\sub B\sub A^*$; so
\[\Gamma(A)\sub\Gamma(B)\sub\Gamma(A^*)=\Gamma(A)+\mathscr{K}_++\mathscr{K}_-\]
Let $G=\Gamma(B)\cap(\mathscr{K}_++\mathscr{K}_-)$ and let $M$ be the set of first coordinates of elements in $G$. Clearly, $M$ is a subspace in $\mathscr{L}_++\mathscr{L}_-$ and $M\sub D(B)$. Hence for $x,y\in M$ we have
\[\langle A^*x,y\rangle=\langle Bx,y\rangle=\langle x,By\rangle=\langle x,A^*y\rangle.\]
So $M$ is $A$-symmetric. Clearly, $\Gamma(A^*|_M)=G$, so $M$ is $A$-closed. If $x\oplus Bx\in\Gamma(B)$, then $x\oplus Bx=(y\oplus Ay)+h$ where $y\in D(A)$ and $h\in\mathscr{K}_++\mathscr{K}_-$. Since $A\sub B$, $h\in\Gamma(B)$; so $h\in G$. This shows that $(\ref{Hilbert space symmetric extension graph-1})$ holds.
\end{proof}
\begin{theorem}
Let $A$ be a closed symmetric operator. If $W$ is a partial isometry with initial space in $\mathscr{L}_+$ and final subspace in $\mathscr{L}_-$, let
\[D_W=\{x+y+Wy:x\in D(A),y\in N(W)^\bot\}\]
and define $A_W$ on $D_W$ by
\[A_W(x+y+Wy)=Ax+iy-iWy.\]
Then $A_W$ is a closed symmetric extension of $A$. Conversely, if $B$ is any closed symmetric extension of $A$, then there is a unique partial isometry $W$ such that $B=A_W$. Moreover, if $W$ is such a partial isometry and $W$ has finite rank, then
\[n_\pm(A_W)=n_\pm(A)-\dim(R(W)).\]
\end{theorem}
\begin{proof}
Let $W$ be a partial isometry with initial space $I_+$ in $\mathscr{L}_+$ and final space $I_-$ in $\mathscr{L}_-$. Define $D_W$ and $A_W$ as in the theorem. Let $M=\{y+Wy:y\in I_+\}$; so $M$ is a subspace in $\mathscr{L}_++\mathscr{L}_-$. If $x,y\in I_+$, then $\langle Wx,Wy\rangle=\langle x,y\rangle$, so
\[\langle A^*(x+Wx),y+Wy\rangle=\langle A^*x,y\rangle+\langle A^*x,Wy\rangle+\langle A^*Wx,y\rangle+\langle A^*Wx,Wy\rangle.\]
Since $x\in\mathscr{L}_+=N(A^*-iI)$ and $Wx\in \mathscr{L}_-=N(A^*+iI)$,
\[\langle A^*(x+Wx),y+Wy\rangle=i\langle x,y\rangle+i\langle x,Wy\rangle-i\langle x,y\rangle-i\langle x,Wy\rangle=i\langle x,Wy\rangle-i\langle x,Wy\rangle.\]
Similarly, we can show that $\langle x+Wx,A^*(y+Wy)\rangle=i\langle x,Wy\rangle-i\langle x,Wy\rangle$, so that $M$ is $A$-symmetric. If $\{x_n\}\sub I_+$ and $(x_n+Wx_n)\oplus(ix_n-iWx_n)\to u\oplus v$ in $H\oplus H$, then
\[2ix_n=i(x_n+Wx_n)+(ix_n-Wx_n)\to iu+v,\quad 2iWx_n=i(x_n+Wx_n)-(ix_n-iWx_n)\to iu-v.\]
If $x=(2i)^{-1}(iu+v)$, then $x_n\to x$, so $u=x+Wx$ and $v=ix-iWx$. Since $x\in\mathscr{L}_+$, this means $v=A^*(u)$ and so $M$ is $A$-closed. By Proposition~\ref{Hilbert space symmetric extension graph}, $A_W$ is a closed symmetric extension of $A$.\par
To prove that $n_+(A_W)=n_+(A)-\dim I_+$, let $x\in D(A)$ and $y\in I_+$. Then
\[(A_W+iI)(x+y+Wy)=(A+iI)x+iy-iWy+iy+iWy=(A+iI)x+2iy.\]
Thus $R(A_W+iI)=R(A+iI)\oplus I_+$, and so
\begin{align*}
n_+(A_W)&=\dim R(A_W+iI)^\bot=\dim[R(A+iI)^\bot\cap(I^+)^\bot]\\
&=\dim[\mathscr{L}_+\cap(I_+)^\bot]=\dim\mathscr{L}_+-\dim I_+.
\end{align*}
simialrly, $n_-(A_W)=n_-(A)-\dim I_-=n_-(A)-\dim I_+$, since $W$ is a partial isometry.\par
Now let $B$ be a closed symmetric extension of $A$. By Proposition~\ref{Hilbert space symmetric extension graph} there is an $A$-symmetric, $A$-closed subspace $M$ in $\mathscr{L}_++\mathscr{L}_-$ such that $\Gamma(B)=\Gamma(A)+\Gamma(A^*|_M)$. If $x\in M$, write $x=x^++x^-$, where $x^\pm\in\mathscr{L}_\pm$; put $I^\pm=\{x^\pm:x\in M\}$. Since $M$ is $A$-symmetric,
\begin{align*}
0&=\langle A^*x,x\rangle-\langle x,A^*x\rangle=\langle A^*(x^++x^-),x^++x^-\rangle-\langle x^++x^-,A^*(x^++x^-)\rangle\\
&=\langle ix^+-ix^-,x^++x^-\rangle-\langle x^++x^-,ix^+-ix^-\rangle=2i\langle x^+,x^+\rangle-2i\langle x^-,x^-\rangle.
\end{align*}
Hence $\|x^+\|=\|x^-\|$ for all $x\in M$. So if we define $Wx^+=x^-$ whenever $x=x^++x^-\in M$ and if $I^+$ is closed, $W$ is a partial isometry and the claim $B=A_W$ is easily seen to hold. It remains to show that $I^+$ is closed. Suppose $\{x_n\}\sub M$ and $x_n^+\to x^+$ in $\mathscr{L}_+$. Since $\|x_n^+-x_m^+\|=\|x_n^--x_m^-\|$, there is a $x^-$ in $\mathscr{L}_-$ such that $x_n^-\to x^-$. Clearly $x_n\to x^++x^-=x$ and $A^*x_n^\pm=\pm ix_n^\pm\to\pm ix^\pm$. It follows that $x\oplus A^*x\in\widebar{\Gamma(A^*|_M)}=\Gamma(A^*|_M)$, thus $x^+\in I^+$.
\end{proof}
\begin{theorem}\label{Hilbert space self-adjoint extension char}
Let $A$ be a closed symmetric operator with deficiency indices $n_\pm$.
\begin{itemize}
\item[(a)] $A$ is self-adjoint if and only if $n_+=n_-=0$.
\item[(b)] $A$ has a self-adjoint extension if and only if $n_+=n_-$. In this case the set of self-adjoint extensions is in natural correspondence with the set of isomorphisms of $\mathscr{L}_+$ onto $\mathscr{L}_-$.
\item[(C)] $A$ is a maximal symmetric operator that is not self-adjoint if and only if either $n_+=0$ and $n_->0$ or $n_+>0$ and $n_-=0$.
\end{itemize}
\end{theorem}
\begin{proof}
Part (a) is a rephrasing of Corollary~\ref{Hilbert space closed symmetric is self-adjoint iff real spectrum}. For (b), $n_+=n_-$ if and only if $\mathscr{L}_+$ and $\mathscr{L}_-$ are isomorphic. But this is equivalent to stating that there is a partial isometry on $H$ with initial and final spaces $\mathscr{L}_+$ and $\mathscr{L}_-$, respectively. Part (c) follows easily from the preceding theorem.
\end{proof}
\begin{example}
Let $A$ and $D$ be as in Example~\ref{L^2([0,1]) differentiation map eg-1}; so $A$ is symmetric. The operator $B$ of Example~\ref{L^2([0,1]) differentiation map eg-2} is a self-adjoint extension of $A$. Let us determine all self-adjoint extensions of $A$. To do this it is necessary to determine $\mathscr{L}_\pm$. Now $f\in\mathscr{L}_\pm$ if and only if $f\in D(A^*)$ and $\pm if=A^*f=if'$, so $\mathscr{L}_\pm=\{\alpha e^{\pm x}:\alpha\in\C\}$. Hence $n_\pm=1$. Also, the isomorphisms of $\mathscr{L}_+$ onto $\mathscr{L}_-$ are all of the form $We^x=\lambda e^x$ where $|\lambda|=e$. According to Theorem~\ref{Hilbert space self-adjoint extension char}, the slef-adjoint extensions of $A$ are of the form
\[A_\lambda(f+\alpha e^x+\lambda\alpha e^{-x})=if'+\alpha ie^x-i\lambda\alpha e^{-x},\quad f\in D,\alpha\in\C\]
where $f\in D$ and $|\lambda|=e$. The operator $B$ of Example~\ref{L^2([0,1]) differentiation map eg-2} is the extension $A_e$.
\end{example}
\subsection{The Cayley transform}
Consider the Mobius transformation
\[M(z)=\frac{z-i}{z+i}\]
It is immediate that $M(0)=-1$, $M(1)=-i$, and $M(\infty)=1$. Thus $M$ maps the upper half plane onto $\D$ and $M(\R\cup\{\infty\})=\partial\D$. So if $A$ is self-adjoint, $M(A)$ should be unitary. Suppose $A$ is symmetric; does $M(A)$ make sense? What is $M(A)$?\par
To answer these questions, we should first investigate the meaning of $M(A)$ if $A$ is symmetric. We want to define $M(A)$ as $(A-iI)(A+iI)^{-1}$. As was seen in the last part, however, $R(A+iI)$ is not necessarily all of $H$ if $A$ is not self-adjoint. In fact, $R(A+iI)^\bot=\mathscr{L}_+$, the deficiency spaces for $A$. However, by Proposition~\ref{Hilbert space symmetric operator A-lambda I prop}, if $A$ is closed and symmetric then $R(A\pm iI)$ is closed.
\begin{theorem}\label{Hilbert space Cayley transform}
If $A$ is a closed densely defined symmetric operator with deficiency subspaces $\mathscr{L}_\pm$, and if $U$ is defined by letting $U=0$ on $\mathscr{L}_+$ and
\begin{align}\label{Hilbert space Cayley transform-1}
U=(A-iI)(A+iI)^{-1}.
\end{align}
on $\mathscr{L}_+^\bot$, then $U$ is a partial isometry with initial space $\mathscr{L}_+^\bot$, final space $\mathscr{L}_-^\bot$, and such that $(I-U)(\mathscr{L}_+^\bot)$ is dense in $H$. Moreover, we have
\begin{align}\label{Hilbert space Cayley transform-2}
A=i(I+U)(I-U)^{-1}.
\end{align}
\end{theorem}
\begin{proof}
By Proposition~\ref{Hilbert space symmetric operator A-lambda I prop}, $R(A+iI)$ and $R(A-iI)$ are closed; so we have
\[\mathscr{L}_{+}^\bot=R(A+iI),\quad \mathscr{L}_-^\bot=R(A-iI).\]
Since $A+iI$ is injective by Proposition~\ref{Hilbert space symmetric operator A-lambda I prop}, the operator $U$ is well-defined. If $y=(A+iI)x$ is in $\mathscr{L}_+^\bot$, then by Proposition~\ref{Hilbert space symmetric operator A-lambda I prop},
\[\|Uy\|^2=\|(A-iI)x\|^2=\|Ax\|^2+\|x\|^2=\|(A+iI)x\|^2=\|y\|^2.\]
So $U$ is a partial isometry with $N(U)^\bot=\mathscr{L}_+^\bot$ and $R(U)=\mathscr{L}_-^\bot$. Moreover, note that
\begin{align}\label{Hilbert space Cayley transform-3}
(I-U)y=y-(A-iI)x=(A+iI)x-(A-iI)x=2ix.
\end{align}
So $(I-U)(\mathscr{L}_+^\bot)=D(A)$ and is dense in $H$. Also, from $(\ref{Hilbert space Cayley transform-3})$, we have
\[i(I+U)(I-U)^{-1}(I-U)y=i(I+U)y=i(A+iI)x+i(A-iI)x=2iAx=A(I-U)y,\]
so $(\ref{Hilbert space Cayley transform-2})$ is also satisfied.
\end{proof}
Now we carry on the reverse of the preceding theorem. We start from a partial isometry $U$ to define the operator $A$.
\begin{theorem}
If $U$ is a partial isometry with initial and final spaces $M$ and $N$, respectively, and such that $(I-U)(M)$ is dense in $H$, then the $A$ defined by $(\ref{Hilbert space Cayley transform-2})$ is a densely defined closed symmetric operator with deficiency subspaces $\mathscr{L}_+=M^\bot$ and $\mathscr{L}_-=N^\bot$.
\end{theorem}
\begin{proof}
We first prove that $N(I-U)=\{0\}$. Let $x\in N(I-U)$, so that $Ux=x$. Then since $U$ is a partial isometry, we have $x\in M$, the initial space of $U$. Since $U^*U$ is the projection on $M$ (Proposition~\ref{Hilbert space partial isometry iff}), this implies $U^*Ux=x$, so $x=U^*x$. But since $(I-U)(M)$ is dense, we have $N(I-U^*)=\{0\}$, which implies $x=0$.\par
Let $D=(I-U)(M)$ and define $A$ as in $(\ref{Hilbert space Cayley transform-2})$. Since $I-U$ is bounded, it is easy to see $A$ is closed. If $x,y\in D$ and $x=(I-U)u$, $y=(I-U)v$ with $u,v\in M$, then
\begin{align*}
\langle Ax,y\rangle&=i\langle(I+U)u,(I-U)v\rangle=i[\langle u,v\rangle+\langle Uu,v\rangle-\langle u,Uv\rangle-\langle Uu,Uv\rangle].\\
\langle x,Ay\rangle&=-i\langle(I-U)u,(I+U)v\rangle=-i[\langle u,v\rangle-\langle Uu,v\rangle+\langle u,Uv\rangle-\langle Uu,Uv\rangle].
\end{align*}
Since $u,v\in M$, we have $\langle u,v\rangle=\langle Uu,Uv\rangle$, hence hence $A$ is symmetric.\par
Finally, if $y=(I-U)x$ with $x\in M$, then
\begin{equation}\label{Hilbert space Cayley transform-4}
\begin{aligned}
(A+iI)y&=Ay+iy=i(I+U)x+i(I-U)x=2ix,\\
(A-iI)y&=Ay-iy=i(I+U)x-i(I-U)x=2iUx.
\end{aligned}
\end{equation}
Thus $R(A+iI)=M$ and $R(A-iI)=N$. Also, we note that
\[(A-iI)(A+iI)^{-1}(A+iI)y=(A-iI)y=i(I+U)x-i(I-U)x=2iUx=U(A-iI)y,\]
so $(\ref{Hilbert space Cayley transform-1})$ holds.
\end{proof}
\begin{definition}
If $A$ is a densely defined closed symmetric operator, the partial isometry $U$ defined by $(\ref{Hilbert space Cayley transform-1})$ is called the \textbf{Cayley transform} of $A$.
\end{definition}
\begin{corollary}
If $A$ is a self-adjoint operator and $U$ is its Cayley transform, then $U$ is a unitary operator with $N(I-U)=\{0\}$. Conversely, if $U$ is a unitary with $1\notin\sigma_p(U)$, then the operator $A$ defined by $(\ref{Hilbert space Cayley transform-2})$ is self-adjoint.
\end{corollary}
\begin{proof}
If $A$ is a densely defined symmetric operator, then $A$ is self-adjoint if and only if $\mathscr{L}_{\pm}=\{0\}$. A partial isometry is a unitary operator if and only if its initial and final spaces are all of $H$. This corollary is now seen to follow from Theorem~\ref{Hilbert space Cayley transform}.
\end{proof}
\subsection{Unbounded normal operators and the spectral theorem}
If $A$ is self-adjoint, the classical way to obtain the spectral decomposition of $A$ is to let $U$ be the Cayley transform of $A$, obtain the spectral decomposition of $U$, and then use the inverse Cayley transform to translate this back to a decomposition for $A$. There is a spectral theorem for unbounded normal operators, however, and the Cayley transform is not applicable here.
\begin{definition}
A linear operator $N$ on $H$ is normal if $N$ is closed, densely defined, and $N^*N=NN^*$.
\end{definition}
Note that the equation $N^*N=NN^*$ implicitly carries the condition that $D(N^*N)=D(NN^*)$. The operators in Examples~\ref{Hilbert space diagonal unbounded operator} and \ref{L^2 unbounded multiplication operator} are normal and every self-adjoint operator is normal. Examining Example~\ref{Hilbert space diagonal unbounded operator} it is easy to see that for a normal operator it is not necessarily the case that $D(N^*N)=D(N)$.
\begin{proposition}\label{Hilbert space unbounded operator A^*A}
If $A\in\mathcal{C}(H)$, then
\begin{itemize}
\item[(a)] $I+A^*A$ has a bounded inverse defined on all of $H$.
\item[(b)] If $B=(1+A^*A)^{-1}$, then $\|B\|\leq 1$ and $B\geq 0$.
\item[(c)] The operator $A(I+A^*A)^{-1}$ is a contraction.
\item[(d)] $A^*A$ is self-adjoint.
\item[(e)] $\{x\oplus Ax:x\in D(A^*A)\}$ is dense in $\Gamma(A)$. 
\end{itemize}
\end{proposition}
\begin{proof}
By Lemma~\ref{Hilbert space char of graph of adjoint}, write $H\oplus K=\Gamma(A^*)\oplus J(\Gamma(A))$. Hence, for every $h\in H$, there are unique $x\in D(A)$ and $y\in D(A^*)$ such that
\[h\oplus 0=x\oplus Ax+(-A^*y)\oplus y=(x-A^*y)\oplus(Ax+y).\]
Thus $h=x-A^*y$ and $Ax+y=0$. It follows that $x\in D(A^*A)$ and $(I+A^*A)x=h$, so $I+A^*A$ is surjective on its domain. Also, for $x\in D(A^*A)$, we have
\[\|(I+A^*A)x\|^2=\|x\|^2+2\|Ax\|^2+\|A^*Ax\|^2\geq\|x\|^2\]
so $I+A^*A$ is also injective. Thus $(I+A^*A)^{-1}$ exists and is defined on all of $H$.\par
Since we have shown that $\|(I+A^*A)x\|\geq\|x\|$, this implies $\|B\|\leq 1$. In addition,
\[\langle By,y\rangle=\langle x,(I+A^*A)x\rangle=\|x\|^2+\|Ax\|^2\geq 0,\] so (b) holds.\par
Put $C=A(I+A^*A)^{-1}=AB$; if $x\in D(A^*A)$ and $(I+A^*A)x=y$, then $\|Cy\|^2=\|Ax\|^2\leq\|(I+A^*A)x\|^2=\|y\|^2$ by the argument used to prove (a). Hence $\|C\|\leq 1$, so (c) is proved.\par
Now we prove (e). Since $A$ is closed, it suffices to show that no nonzero vector in $\Gamma(A)$ is orthogonal to $\{x\oplus Ax:x\in D(A^*A)\}$. So let $x\in D(A)$ and suppose that for every $y\in D(A^*A)$,
\[0=\langle x\oplus Ax,y\oplus Ay\rangle=\langle x,y\rangle+\langle Ax,Ay\rangle=\langle x,(I+A^*A)y\rangle.\]
Since $R(I+A^*A)=H$, this implies $x=0$, so (e) is proved.\par
To prove (d), note that (e) implies that $D(A^*A)$ is dense. Now let $x,y\in D(A^*A)$, so $x,y\in D(A)$ and $Ax,Ay\in D(A^*)$. Hence $\langle A^*Ax,y\rangle=\langle Ax,Ay\rangle=\langle x,A^*Ay\rangle$. Thus $A^*A$ is symmetric. Also, $I+A^*A$ has a bounded inverse. This implies two things. First, $I+A^*A$ is closed, and so $A^*A$ is closed. Also, $-1\notin\sigma(A^*A)$ so that by Corollary~\ref{Hilbert space closed symmetric R not in spectrum}, $A^*A$ is self-adjoint.
\end{proof}
\begin{proposition}\label{Hilbert space normal unbounded operator domain of dual}
If $N$ is a normal operator, then $D(N)=D(N^*)$ and $\|Nx\|=\|N^*x\|$ for every $x\in D(N)$.
\end{proposition}
\begin{proof}
First observe that if $x\in D(N^*N)=D(NN^*)$, then $Nx\in D(N^*)$ and $N^*x\in D(N)$. Hence
\begin{align}\label{Hilbert space normal unbounded operator domain of dual-1}
\|Nx\|^2=\langle N^*Nx,x\rangle=\langle NN^*x,x\rangle=\|N^*x\|^2.
\end{align}
Now if $x\in D(N)$, then Proposition~\ref{Hilbert space unbounded operator A^*A}(e) implies that there is a sequence $\{x_n\}$ in $D(N^*N)$ such that $x_n\oplus Nx_n\to x\oplus Nx$, so $\{Nx_n\}$ is Cauchy. But by $(\ref{Hilbert space normal unbounded operator domain of dual-1})$, $\{N^*x_n\}$ is also Cauchy, hence converges to $y\in H$. Since $N^*$ is closed, we must have $y=N^*x$, so $x\in D(N^*)$. This proves $D(N)\sub D(N^*)$, and $\|Nx\|=\|N^*x\|$ since $\|N^*x_n\|=\|Nx_n\|$ for each $n$.\par
On the other hand, since $N$ is closed, $N^*$ is also normal, and so $D(N^*)\sub D(N^{**})=D(N)$.
\end{proof}
\begin{lemma}\label{Hilbert space unbounded sum of operator}
Let $\{H_n\}$ be a sequence of Hilbert spaces and let $A_n\in\mathcal{B}(H_n)$ for all $n$. If $D=\{(x_n):\sum_n\|A_nx_n\|^2<+\infty\}$ and $A$ is defined on $H$ by $A(x_n)=(A_nx_n)$ whenever $(x_n)\in D$, then $A\in\mathcal{C}(H)$ and is a normal operator if and only if each $A_n$ is normal.
\end{lemma}
\begin{proof}
Since $H_n\sub D$ for each $n$, $D$ is dense in $H$. Clearly $A$ is linear. If $\{x^{(j)}\}\sub D$ and $x^{(j)}\oplus Ax^{(j)}\to x\oplus y$ in $H\oplus H$, then for each $n$, $x_n^{(j)}\oplus Ax_n^{(j)}\to x_n\oplus y_n$. Since $A_n$ is bounded, $A_nx_n=y_n$. Hence $\sum_n\|A_nx_n\|^2=\sum\|y_n\|^2<+\infty$; so $x\in D$. Clearly $Ax=y$, so $A\in\mathcal{C}(H)$.\par
By the definition of the inner product in $\bigoplus_nH_n$, it is easy to see $D(A^*)=\{(x_n):\sum_n\|A_n^*x_n\|^2<+\infty\}$, and $A^*(x_n)=(A^*_nx_n)$ for $(x_n)\in D(A^*)$. From this the rest of the lemma easily.
\end{proof}
If $(X,\mathcal{A})$ is a measurable space and $H$ is a Hilbert space, recall the definition of a spectral measure $E$ for $(X,\mathcal{A},H)$. If $x,y\in H$, let $E_{x,y}$ be the complex-valued measure given by $E_{x,y}(\Delta)=\langle E(\Delta)x,y\rangle$ for each $\Delta\in\mathcal{A}$.\par
Let $\phi:X\to\C$ be an $\mathcal{A}$-measurable function and for each n let $\Delta_n=\{x\in X:n-1\leq|\phi(x)|<n\}$. So $\chi_{\Delta_n}\phi$ is a bounded $\mathcal{A}$-measurable function. Put $H_n=E(\Delta_n)(H)$. Since $\bigcup_n\Delta_n=X$ and the sets $\{\Delta_n\}$ are pairwise disjoint, $H=\bigoplus_nH_n$. If $E_n(\Delta)=E(\Delta\cap\Delta_n)$, then $E_n$ is a spectral measure for $(X,\mathcal{A},H_n)$ and we have $E=\sum_nE_n$. Also, $\int\phi\, dE_n$ is a normal operator on $H_n$. Define
\[D_\phi=\{x\in H:\sum_{n=1}^{\infty}\Big\|\Big(\int\phi\,dE_n\Big)E(\Delta_n)x\Big\|^2<+\infty\},\]
then by Lemma~\ref{Hilbert space unbounded sum of operator}, the operator $N_\phi$ given by
\[N_\phi x=\sum_{n=1}^{\infty}\Big(\int\phi\,dE_n\Big)E(\Delta_n)x\]
is normal. The operator $N_\phi$ is also denoted by $N_\phi=\int\phi\,dE$.
\begin{theorem}\label{Hilbert space unbounded multiplication for spectral measure}
If $E$ is a spectral measure for $(X,\mathcal{A},H)$, $\phi:X\to\C$ is an $\mathcal{A}$-measurable function, and $D_\phi$ and $N_\phi$ are defined as above, then:
\begin{itemize}
\item[(a)] $D_\phi=\{x\in H:\int|\phi|^2\,dE_{x,x}<+\infty\}$.
\item[(b)] for $x\in D_\phi$ and $y\in H$, $\phi\in L^1(E_{x,y})$ with
\begin{align}\label{Hilbert space unbounded multiplication for spectral measure-1}
\int|\phi|\,d|E_{x,y}|\leq\|y\|\|\phi\|_{L^2(E_{x,x})},\quad \langle\Big(\int\phi\,dE\Big)x,y\rangle=\int\phi\,dE_{x,y},
\end{align}
and
\begin{align}\label{Hilbert space unbounded multiplication for spectral measure-2}
\Big\|\Big(\int\phi\,dE\Big)x\Big\|^2=\int|\phi|^2\,dE_{x,x}.
\end{align}
\end{itemize}
\end{theorem}
\begin{proof}
Using the $*$-homomorphic properties associated with a spectral measure, one obtains
\[\Big\|\Big(\int\phi\,dE_n)E(\Delta_n)x\Big\|^2=\langle\Big(\int\chi_{\Delta_n}\phi\,dE\Big)^*\Big(\int\chi_{\Delta_n}\phi\,dE\Big)x,x\rangle=\int_{\Delta_n}|\phi|^2\,dE_{x,x}.\]
From this, claim (a) follows. Now let $x\in D_\phi$, $y\in H$. By the Radon-Nikodym Theorem, there is an $\mathcal{A}$-measurable function $f$ such that $|f|\equiv 1$ and $d|E_{x,y}|=f\,dE_{x,y}$. Let $\phi_n=\sum_{k=1}^{n}\chi_{\Delta_k}\phi$; so $\phi_n$ is bounded, as is $f\phi_n$. Thus
\[\int|\phi_n|\,d|E_{x,y}|=\int|\phi_n|f\,dE_{x,y}=\langle\Big(\int|\phi_n|f\,dE\Big)x,y\rangle\leq\|y\|\Big\|\Big(\int|\phi_n|f\,dE\Big)x\Big\|.\]
But note that
\begin{align*}
\Big\|\Big(\int|\phi_n|f\,dE\Big)x\Big\|^2&=\langle\Big(\int|\phi_n|f\,dE\Big)x,\Big(\int|\phi_n|f\,dE\Big)x\rangle\\
&=\langle\Big(\int|\phi_n|^2\,dE\Big)x,x\rangle=\int|\phi_n|^2\,dE_{x,x}\leq\int|\phi|^2\,dE_{x,x}.
\end{align*}
Combining this with the preceding inequality gives that $\int|\phi_n|\,d|E_{x,y}|\leq\|\phi\|_{L^2(E_{x,x})}$ for all $n$. Letting $n\to+\infty$ gives the first part of $(\ref{Hilbert space unbounded multiplication for spectral measure-1})$. Since $\phi_n$ is bounded, $\langle(\int\phi\,dE)x,y\rangle=\int\phi_n\,dE_{x,y}$. If $x\in D_\phi$ and $y\in H$, then the dominated convergence theorem imply that $\int\phi_n\,dE_{x,y}=\int\phi\,dE_{x,y}$. But
\[\Big(\int\phi_n\,dE\Big)x=\Big(\int\phi\,dE\Big)E\Big(\bigcup_{j=1}^{n}\Delta_j\Big)x=E\Big(\bigcup_{j=1}^{n}\Delta_j\Big)\Big(\int\phi\,dE\Big)x.\]
Since $E(\bigcup_{j=1}^{n}\Delta_j)\to E(X)=I$ strongly, this proves $(\ref{Hilbert space unbounded multiplication for spectral measure-2})$.
\end{proof}
Note that as a consequence of Theorem~\ref{Hilbert space unbounded multiplication for spectral measure}, $D(N_\phi)$ and the definition of $N_\phi$ do not depend on the choice of the sets $\{\Delta_n\}$. Also, by Theorem~\ref{Hilbert space unbounded multiplication for spectral measure}(a), for any $\Delta\in\mathcal{A}$, we have $E(\Delta)x\in D(N_\phi)$ if $x\in D(N_\phi)$.
\begin{theorem}
If $(X,\mathcal{A})$ is a measurable space, $H$ is a Hilbert space, and $E$ is a spectral measure for $(X,\mathcal{A},H)$. Define $\rho:L^0(X,\mathcal{A})\to\mathcal{C}(H)$ by $\rho(\phi)=\int\phi\,dE$. Then for $\phi,\psi\in L^0(X,\mathcal{A})$,
\begin{itemize}
\item[(a)] $\rho(\phi)^*=\rho(\bar{\phi})$;
\item[(b)] $\rho(\phi\psi)\sups\rho(\phi)\rho(\psi)$ and $D(\rho(\phi)\rho(\psi))=D_{\psi}\cap D_{\phi\psi}$;
\item[(c)]If $\psi$ is bounded, then $\rho(\phi)\rho(\psi)=\rho(\psi)\rho(\phi)=\rho(\psi\phi)$;
\item[(d)] $\rho(\phi)^*\rho(\phi)=\rho(|\phi|^2)$. 
\end{itemize}
\end{theorem}
\begin{proof}
Part (a) is immediate from Theorem~\ref{Hilbert space unbounded multiplication for spectral measure}. Now it is clear that $D(\rho(\phi)\rho(\psi))=D_{\psi}\cap D_{\phi\psi}$, which is contained in $D(\rho(\phi\psi))$. Moreover, a limit process as in Theorem~\ref{Hilbert space unbounded multiplication for spectral measure} shows $\rho(\phi\psi)\sups\rho(\phi)\rho(\psi)$. If $\psi$ is bounded then $D_\psi=H$, so $D(\rho(\phi\psi))=D(\rho(\phi)\rho(\psi))$, so (c) holds. Since $\rho(\phi)^*=\rho(\bar{\phi})$, part (d) is now clear.
\end{proof}
\begin{theorem}\label{spectral theorem unbounded}
If $N$ is a normal operator on $H$, then there is a unique spectral measure $E$ defined on the Borel subsets of $\C$ such that:
\begin{itemize}
\item[(a)] $N=\int z\,dE(z)$;
\item[(b)] $E(\Delta)=0$ if $\Delta\cap\sigma(N)=\emp$;
\item[(c)] if $U$ is an open subset of $\C$ and $U\cap\sigma(N)\neq\emp$, then $E(U)\neq\emp$;
\item[(d)] if $A\in\mathcal{B}(H)$ such that $AN\sub NA$ and $AN^*\sub N^*A$, then $A(\int\phi\,dE)\sub(\int\phi\,dE)A$ for every Borel function $\phi$ on $\C$. 
\end{itemize}
\end{theorem}
\begin{lemma}\label{Hilbert space unbounded normal (I+N^*N)^-1}
If $N$ is a normal operator, $B=(I+N^*N)^{-1}$, and $C=N(I+N^*N)^{-1}$. Then $BN\sub NB$ and $BC=CB$.
\end{lemma}
\begin{proof}
From Proposition~\ref{Hilbert space unbounded operator A^*A}, $B$ and $C$ are contractions and $B\geq 0$. It will first be shown that $BN\sub NB$. Let $y\in D(BN)$. Recall that $I+N^*N$ is surjective, so we can write $x=(I+N^*N)^{-1}y$, or $y=(I+N^*N)x$ for some $x\in D(N^*N)$. Now $y\in D(N)$, and we have
\[Ny=N(I+N^*N)x=Nx+NN^*Nx=(I+NN^*)Nx.\]
Therefore $BNy=Nx=NBy$, which proves $BN\sub NB$.\par
Note that $B$ and $C$ are both defined on $H$. If $y\in H$, let $y=(I+N^*N)x$ with $x\in D(N^*N)$. Then 
\[BCy=BN(I+N^*N)^{-1}y=BNx=NBx=NBBy=CBy.\]
Hence $BC=CB$.
\end{proof}
\begin{lemma}\label{Hilbert space spectral of (I+N^*N)^-1}
With the same notation as in Lemma~\ref{Hilbert space unbounded normal (I+N^*N)^-1}, if $B=\int t\,dP(t)$ is its spectral representation, $0<\delta<1$, and $\Delta$ is a Borel subset of $[\delta,1]$, then $H_\Delta=P(\Delta)(H)\sub D(N)$ is invariant for both $N$ and $N^*$, and $N_\Delta:=N|_{H_\Delta}$ is a bounded normal operator with $\|N_\Delta\|\leq[(1-\delta)/\delta]^{1/2}$.
\end{lemma}
\begin{proof}
If $x\in H_\Delta$, then because $P(\Delta)=\chi_{\Delta}(B)$, we have
\[\|Bx\|^2=\|BP(\Delta)x\|^2=\langle B^2P(\Delta)x,x\rangle=\int_\Delta t^2\,dP_{x,x}\geq\delta^2\|x\|^2.\]
So $B|_{H_\Delta}$ is invertible and there is a $y\in H_\Delta$ such that $x=By$. But $R(B)=D(I+N^*N)=D(N^*N)\sub D(N)$. Hence $x\in D(N)$; that is $H_\Delta\sub D(N)$.\par
Let $x\in H_\Delta$ and again let $y\in H_\Delta$ such that $x=By$. Then $Nx=NBy=Cy$. By the preceding lemma we have $BC=CB$, so by spectral theorem in the bounded case, $P(\Delta)C=CP(\Delta)$ and hence $H_\Delta$ is invariant under $C$. Since $x\in H_\Delta$, we then get $Nx=Cy\in H_\Delta$. Note that $(I+NN^*)^{-1}=(I+N^*N)^{-1}$, so we also get $N^*(H_\Delta)\sub H_\Delta$. It follows that $N_\Delta^*=N^*|_{H_\Delta}$, so $N_\Delta$ is normal.\par
Finally, if $x\in H_\Delta$, then
\[\|Nx\|^2=\langle N^*Nx,x\rangle=\langle[(N^*N+I)-I]x,x\rangle=\int_a^b(t^{-1}-1)\,dP_{x,x}\leq\|x\|^2(1-\delta)/\delta.\]
Hence $\|N_\Delta\|\leq[(1-\delta)/\delta]^{1/2}$.
\end{proof}
\begin{proof}[Proof of Theorem~\ref{spectral theorem unbounded}]
Let $B=(I+N^*N)^{-1}$ and $C=N(I+N^*N)^{-1}$ as in Lemma~\ref{Hilbert space unbounded normal (I+N^*N)^-1}. Let $B=\int_0^1 t\,dP(t)$ be the spectral decomposition of $B$ and put $P_n=P((1/(n+1),1/n])$. Since $N(B)=\{0\}=P(\{0\})(H)$, we have $\sum_nP_n=P([0,1])=I$. Let $H_n=P_n(H)$. By Lemma~\ref{Hilbert space spectral of (I+N^*N)^-1}, $H_n\sub D(N)$, $H_n$ reduces $N$, and $N_n=N|_{H_n}$ is bounded normal operator with $\|N_n\|\leq n^{1/2}$. Since $D(N^*)=D(N)$ and $H_n$ reduces $N$, it is easy to see $N_n^*=N^*|_{H_n}$, so $B|_{H_n}=(I+N_n^*N_n)^{-1}$. Thus if $\lambda\in\sigma(N_n)$ then $(1+|\lambda|^2)^{-1}\in\sigma(B|_{H_n})\sub[1/(n+1),1/n]$, so $\sigma(N_n)\sub\Delta_n:=\{z:(n-1)^{1/2}\leq|z|\leq n^{1/2}\}$. Let $N_n=\int z\,dE_n(z)$ be the spectral decomposition of $N_n$. For any Borel subset $\Delta$ of $\C$, let $E(\Delta)$ be defined by
\[E(\Delta)=\sum_{n=1}^{\infty}E_n(\Delta\cap\Delta_n).\]
Note that $E_n(\Delta\cap\Delta_n)$ is a projection with range in $H_n$. Since $H_n\bot H_m$ for $n\neq m$, this defines a projection in $\mathcal{B}(H)$. Now we show that $E$ is a spectral measure. Clearly $E(\C)=1$ and $E(\emp)=0$. If $\Lambda_1$ and $\Lambda_2$ are Borel subsets of $\C$, then
\[E(\Lambda_1\cap\Lambda_2)=\sum_{n=1}^{\infty}E_n(\Lambda_1\cap\Lambda_2\cap\Delta_n)=\sum_{n=1}^{\infty}E_n(\Lambda_1\cap\Delta_n)E_n(\Lambda_2\cap\Delta_n).\]
Again, the fact that the spaces $\{H_n\}$ are pairwise orthogonal implies
\begin{align*}
E(\Lambda_1\cap\Lambda_2)=\Big(\sum_{n=1}^{\infty}E_n(\Lambda_1\cap\Delta_n)\Big)\Big(\sum_{n=1}^{\infty}E_n(\Lambda_2\cap\Delta_n)\Big)=E(\Lambda_1)E(\Lambda_2).
\end{align*}
If $x\in H$, then $\langle E(\Delta)x,x\rangle=\sum_{n=1}^{\infty}\langle E_n(\Delta\cap\Delta_n)x,x\rangle$. So if $\{\Lambda_j\}$ are pairwise disjoint Borel sets,
\begin{align*}
\langle E\Big(\bigcup_{j=1}^{\infty}\Lambda_j\Big)x,x\rangle=\sum_{n=1}^{\infty}\langle E_n\Big(\bigcup_{j=1}^{\infty}\Lambda_j\cap\Delta_n\Big)x,x\rangle=\sum_{n=1}^{\infty}\sum_{j=1}^{\infty}\langle E_n(\Lambda_j\cap\Delta_n)x,x\rangle.
\end{align*}
Since each term in this double summation is non-negative, the order of summation can be reversed. Thus
\[\langle E\Big(\bigcup_{j=1}^{\infty}\Lambda_j\Big)x,x\rangle=\sum_{j=1}^{\infty}\sum_{n=1}^{\infty}\langle E_n(\Lambda_j\cap\Delta_n)x,x\rangle=\sum_{j=1}^{\infty}\langle E(\Lambda_j)x,x\rangle.\]
This proves $E(\bigcup_j\Lambda_j)=\sum_jE(\Lambda_j)$, therefore $E$ isa spectral measure.\par
Let $M=\int z\,dE(z)$ be defined as in Theorem~\ref{L^2 unbounded multiplication operator}. Thus $H_n\sub D(M)$ and by the spectral theorem for bounded operators, $Mx=N_nx=Nx$ if $x\in H_n$. If $x$ is any vector in $D(M)$, $x=\sum_nx_n$ and $\sum_n\|Nx_n\|^2<+\infty$. Because $N$ is closed, $x\in D(N)$ and $Nx=Mx$. Thus $M\sub N$. To prove the other inclusion, note that $M$ is a closed operator by Lemma~\ref{Hilbert space unbounded sum of operator}. Thus, by Proposition~\ref{Hilbert space unbounded operator A^*A}, it suffices to show that $\{x\oplus Nx:x\in D(N^*N)\}\sub\Gamma(M)$. Let $x\in D(N^*N)$, then there is a vector $y$ such that $x=By$, so by Lemma~\ref{Hilbert space unbounded normal (I+N^*N)^-1} and the spectral theorem, we have
\[P_nNx=P_nNBy=NBP_ny=NP_nBy=NP_nx.\]
If $x_n=P_nx$, then we get
\[\sum_n\|Nx_n\|^2=\sum_n\|P_nNx\|^2=\|Nx\|^2<+\infty,\]
so $x\in D(M)$ and by the preceding argument, $Nx=Mx$. That is, $x\oplus Nx\in\Gamma(M)$. This proves (a).\par
We now claim that $\sigma(N)=\mathrm{cl}\bigcup_{n=1}^{\infty}\sigma(N_n)$. First, since eahc $N_n$ is a restriction of $N$, we have $\sigma(N_n)\sub\sigma(N)$ for all $n$, hence $\bigcup_n\sigma(N_n)\sub\sigma(N)$. Since $\sigma(N)$ is closed, this proves half of the claim. If $\lambda\not\in\mathrm{cl}\bigcup_{n=1}^{\infty}\sigma(N_n)$, then there is $\delta>0$ such that $d(\lambda,\sigma(N))=\delta>0$. Thus $(N_n-\lambda I)^{-1}$ exists for all $n$. Since each $N_n$ is a bounded normal operator, by Proposition~\ref{C^* algebra spectrum prop} we see $\|N_n-\lambda I\|\geq\delta$, hence $\|(N_n-\lambda I)^{-1}\|\leq\delta^{-1}$ . Thus $A=\bigoplus_n(N_n-\lambda I)^{-1}$ is a bounded operator. It follows that $A=(N -\lambda I)^{-1}$, so $\lambda\notin\sigma(N)$. Once this is proved, if $\Delta\cap\sigma(N)=\emp$, then $\Delta\cap\sigma(N_n)=\emp$ for all $n$. Thus $E_n(\Delta)=0$ for all $n$. Hence $E(\Delta)=0$ and (b) holds. If $U$ is open and $U\cap\sigma(N)\neq\emp$, then $U\cap\sigma(N_n)\neq\emp$ for some $n$. Since $E_n(U)\neq 0$, $E(U)\neq 0$ and (c) is true.\par
Now let $A\in\mathcal{B}(H)$ such that $AN\sub NA$ and $AN^*\sub N^*A$. Thus $A(I+N^*N)\sub(I+N^*N)A$. It follows that $AB=BA$. By the spectral theorem for bounded operators, $A$ commutes with the spectral projections of $B$. In particular, each $H_n$ reduces $A$ and if $A_n=A|_{H_n}$ then $A_nN_n=N_nA_n$. Hence $A_nE_n(\Delta)=E_n(\Delta)A_n$ for every Borel set $\Delta$ contained in $\Delta_n$. It follows that $AE(\Delta)=E(\Delta)A$ for every Borel set $\Delta$. From the definition of $D_\phi$ and the boundedness of $A$, this implies $A(D_\phi)\sub D_\phi$, so $D(A(\int\phi\,dE))\sub D((\int\phi\,dE)A)$ and hence $A(\int\phi\,dE)\sub (\int\phi\,dE)A$.
\end{proof}
\subsection{Stone's Theorem}
If $A$ is a self-adjoint operator on $H$, then as we will show, $\exp(iA)$ is a unitary operator. Hence $U(t)=\exp(itA)$ is unitary for all $t$ in $\R$. The purpose of this part is not to investigate the individual operators $\exp(itA)$, but rather the entire collection of operators $\{\exp(itA):t\in\R\}$. In fact, as the first theorem shows, $U$ is a group homomorphism with certain properties. Stone's Theorem provides a converse to this; every such homomorphism arises in this way.
\begin{theorem}\label{Hilbert space self-adjoint exp(itA)}
If $A$ is self-adjoint and $U(t)=\exp(itA)$ for $t$ in $\R$, then
\begin{itemize}
\item[(a)] $U(t)$ is unitary;
\item[(b)] $U(s+t)=U(s)U(t)$ for all $s$ in $\R$;
\item[(c)] if $x\in H$, then $\lim_{s\to t}U(s)x=U(t)x$;
\item[(d)] if $x\in D(A)$, then $\lim_{t\to 0}t^{-1}[U(t)x-x]=iAx$.
\item[(e)] if $x\in H$ and $\lim_{t\to 0}t^{-1}[U(t)x-x]$ exists, then $x\in D(A)$. Consequently, $D(A)$ is invariant under each $U(t)$.
\end{itemize}
\end{theorem}
\begin{proof}
By the function calculus, since $|e^{its}|=1$, we have $U(t)U(t)^*=U(t)^*U(t)=I$. so $U(t)$ is unitary for each $t$. Part (b) is a consequence of the functional calculus for normal operators. Also note that $U(0)U(t)=U(t)$, so that $U(0)=I$.\par
If $x\in H$, then since $U(s)$ is unitary,
\[\|U(s)x-U(t)x\|=\|U(t-s+s)x-U(t)x\|=\|U(t)[U(t-s)x-x]\|=\|U(t-s)x-x\|.\]
Thus (c) will be shown if it is proved that $\|U(t)x-x\|\to 0$ as $t\to 0$. If $A=\int_\R\lambda\,dE(\lambda)$ is the spectral decomposition of $A$, then
\[\|U(t)x-x\|^2=\int_\R|e^{it\lambda}-1|^2\,dE_{x,x}(\lambda).\]
Since $|e^{it\lambda}-1|^2$ is bounded and $E_{x,x}$ is a finite measure, the claim follows from dominated convergence theorem.\par
Note that $t^{-1}[U(t)-I]-iA=f_t(A)$, where $f_t(\lambda)=t^{-1}[\exp(it\lambda)-I]i\lambda$. So for $x\in D(A)$,
\[\|t^{-1}[U(t)x-x]-iAx\|^2=\int_\R\Big|\frac{e^{it\lambda}-1}{t}-i\lambda\Big|^2\,dE_{x,x}(\lambda).\]
Since $f_t(\lambda)\to 0$ as $t\to 0$ and $|f_t(\lambda)|\leq 2|\lambda|$, which is integrable under $E_{x,x}$, the dominated convergence theorem again gives the claim.\par
Finally, let $D$ be the set described in (e) and define $Bx$ for $x\in D$ by
\[iBx=\lim_{t\to 0}t^{-1}[U(t)x-x].\]
It is easy to see that $D$ is a subspace of $H$ and $B$ is linear on $D$. Also, by (d), $B\sups A$ so that $B$ is densely defined. Moreover, if $x,y\in D$, then
\[\langle Bx,y\rangle=-i\lim_{t\to 0}\langle t^{-1}[U(t)x-x],y\rangle.\]
By (b) and the fact that each $U(t)$ is unitary, it follows that $U(t)^*=U(-t)$ and hence
\[\langle Bx,y\rangle=-i\lim_{t\to 0}\langle t^{-1}[U(t)x-x],y\rangle=\lim_{t\to 0}\langle x,-it^{-1}[U(-t)y-y]\rangle=\langle x,By\rangle.\]
Hence $B$ is a symmetric extension of $A$. Since self-adjoint operators are maximal symmetric operators (Proposition~\ref{Hilbert space symmetric operator maximal extension}), $B=A$ and $D=D(A)$.
\end{proof}
The following definition is inspired by the preceding theorem.
\begin{definition}
A \textbf{strongly continuous one parameter unitary group} is a function $U:\R\to\mathcal{B}(H)$ such that for all $s$ and $t$ in $\R$:
\begin{itemize}
\item[(a)] $U(t)$ is a unitary operator;
\item[(b)] $U(s+t)=U(s)U(t)$;
\item[(c)] if $x\in H$, then $U(s)x\to U(t)x$ as $s\to t$.
\end{itemize}
\end{definition}
Note that by Theorem~\ref{Hilbert space self-adjoint exp(itA)}, if $A$ is self-adjoint, then $U(t)=\exp(itA)$ defines a strongly continuous one parameter unitary group.
\begin{theorem}
If $H$ is separable, $U:\R\to\mathcal{B}(H)$ satisfies conditions (a) and (b) above, and if for all $x,y\in H$ the function $t\mapsto\langle U(t)x,y\rangle$ is Lebesgue measurable, then $U$ is a strongly continuous one-parameter unitary group.
\end{theorem}
\begin{proof}
If $\alpha>0$ and $x,y\in H$, then $t\mapsto\langle U(t)x,y\rangle$ is a bounded measurable function on $[0,\alpha]$ and hence $\int_0^\alpha|\langle U(t)x,y\rangle|\,dt$ is finite. Thus $x\mapsto\int_0^\alpha|\langle U(t)x,y\rangle|\,dt$ is a bounded linear function on $H$, and there is a $y_\alpha$ in $H$ such that
\[\int_0^\alpha|\langle U(t)x,y\rangle|\,dt=\langle x,y_\alpha\rangle\]
and $\|y_\alpha\|\leq\alpha\|y\|$. We claim that $\{y_\alpha:y\in H,\alpha>0\}$ is total in $H$. In fact, suppose $x\in H$ and $x\bot y_a$ for all $y\in H$ and $\alpha>0$. Then for every $\alpha>0$ and every $y\in H$, we have $\int_0^\alpha\langle U(t)x,y\rangle\,dt=0$. Thus for every $y\in H$, $\langle U(t)x,y\rangle=0$ a.e. on $\R$. Because $H$ is separable there is a subset $\Delta$ of $\R$ having measure zero such that if $t\notin\Delta$ then $\langle U(t)x,y\rangle=0$ whenever $y$ belongs to a preselected countable dense subset of $H$. Thus $U(t)x=0$ if $t\notin\Delta$. But $\|x\|=\|U(t)x\|$, so $x=0$ and the claim is established.\par
Now if $s\in\R$, then
\begin{align*}
\langle x,U(s)y_\alpha\rangle=\langle U(-s)x,y_\alpha\rangle=\int_0^a\langle U(t-s)x,y\rangle\,dt=\int_{-s}^{\alpha-s}\langle U(t)x,y\rangle\,dt.
\end{align*}
Thus $\langle x,U(s)y\rangle\to\langle x,y_\alpha\rangle$ as $s\to 0$. By the claim and the fact that the group is uniformly bounded, $U:\R\to\mathcal{B}(H)$ is weakly continuous at $0$, hence weakly continuous. Now since each $U(t)$ is unitary, we have
\begin{align*}
\|U(t)x-x\|^2&=\langle U(t)x-x,U(t)-x\rangle=\langle U(t)x,U(t)x\rangle-2\Re\langle U(t)x,x\rangle+\langle x,x\rangle\\
&=2\|x\|^2-2\Re\langle U(t)x,x\rangle.
\end{align*}
Since $U(t)$ is weakly continuous and $U(0)=I$, $\langle U(t)x,x\rangle\to\|x\|^2$ as $t\to 0$, so it follows that $U$ is strongly continuous.
\end{proof}
We now turn our attention to the principal result of this part, Stone's Theorem, which states that the converse of Theorem~\ref{Hilbert space self-adjoint exp(itA)} is valid. Before we provide the theorem, let's see what we can get from a strongly continuous one parameter unitary group $U$. Note that if $U(t)=\exp(itA)$ for a self-adjoint operator A, then part (d) of Theorem~\ref{Hilbert space self-adjoint exp(itA)} instructs us how to recapture $A$.
\begin{definition}
If $U$ is a strongly continuous one-parameter unitary group, the \textbf{infinitesimal generator} of $U$ is the operator $A$ given by
\[Ax=\lim_{t\to 0}\frac{1}{i}\frac{U(t)x-x}{t}\]
with $D(A)$ consisting of the set of $x\in H$ for which the abovel limit exists in the norm topology on $H$.
\end{definition}
\begin{lemma}\label{Hilbert space 1-parameter group derivative}
Let $U:\R\to\mathcal{B}(H)$ be a strongly continuous one-parameter unitary group and let $A$ be its infinitesimal generator. If $x\in D(A)$, then for all $t\in\R$, the vector $U(t)x$ belongs to $D(A)$ and
\[\lim_{s\to 0}\frac{U(t+s)x-U(t)x}{s}=iU(t)Ax=iAU(t)x.\]
\end{lemma}
\begin{proof}
Since $x\in D(A)$, we compute that
\begin{align}\label{Hilbert space 1-parameter group derivative-1}
\lim_{s\to 0}\frac{U(t+s)x-U(t)x}{s}=\lim_{s\to 0}U(t)\frac{U(s)x-x}{s}=iU(t)Ax
\end{align}
On the other hand, note that
\[\frac{U(t+s)x-U(t)x}{s}=\frac{U(s)U(t)x-U(t)x}{s}\]
so $(\ref{Hilbert space 1-parameter group derivative-1})$ means $U(t)\in D(A)$ and $iAU(t)x=iU(t)Ax$. This proves the claim.
\end{proof}
\begin{lemma}\label{Hilbert space 1-parameter group generated densely defined}
For any strongly continuous one-parameter unitary group $U$, the infinitesimal generator $A$ is densely defined.
\end{lemma}
\begin{proof}
Given any continuous function $f$ of compact support, define an operator $T_f$ by setting
\[T_f x=\int_{-\infty}^{\infty}f(\tau)U(\tau)x\,d\tau.\]
Using the group property of $U$, we see that
\begin{align*}
U(t)T_f x-T_f x&=\int_{-\infty}^{\infty}[f(\tau)U(\tau+t)-f(\tau)U(\tau)]x\,d\tau=\int_{-\infty}^{\infty}[f(\tau-t)-f(\tau)]U(t)x\,d\tau.
\end{align*}
From this, we easily obtain that
\[\lim_{t\to 0}\frac{U(t)T_fx-T_fx}{t}=-\int_{-\infty}^{\infty}f'(\tau)U(\tau)x\,d\tau.\]
This shows that $T_fx$ is in the domain of $A$ for all $x\in H$ and $f\in C^\infty_c(\R)$. Now choose a sequence $f_n\in C^\infty_c(\R)$ such that $f_n$ is non-negative and supported in the interval $[-1/n,1/n]$ and such that $\int_{-\infty}^{\infty}f_n(\tau)\,d\tau=1$. Then for any $x\in H$, we have
\begin{align*}
\|T_{f_n}x-x\|&=\Big\|\int_{-\infty}^{\infty}f_n(\tau)[U(\tau)x-x]\,d\tau\Big\|\leq\int_{-\infty}^{\infty}|f_n(\tau)|\|U(\tau)x-x\|\,d\tau\\
&\leq\sup\{\|U(\tau)x-x\|:\tau\in[-1/n,1/n]\}.
\end{align*}
Since $U$ is strongly continuous, we see that $T_{f_n}x$ converges to $x$. Thus, every element of $H$ can be approximated by vectors in the domain of $A$, which shows $A$ is densely defined.
\end{proof}
\begin{theorem}\label{Stone theorem}
If $U$ is a strongly continuous one-parameter unitary group on $H$ then the infinitesimal generator $A$ of $U$ is densely defined and self-adjoint, and $U(t)=\exp(itA)$ for all $t\in\R$.
\end{theorem}
\begin{proof}
Suppose $U$ is a strongly continuous one-parameter unitary group and $A$ is its infinitesimal generator. By Lemma~\ref{Hilbert space 1-parameter group generated densely defined}, $A$ is densely defined. As shown in the proof of Theorem~\ref{Hilbert space self-adjoint exp(itA)}, $A$ (denoted by $B$ in that proof) is symmetric.\par
Now we want show that $A$ is essentially self-adjoint. Suppose now that $y$ belongs to the kernel of $A^*-iI$, i.e., $A^*y=iy$. Given $x\in D(A)$, set $\phi(t)=\langle U(t)x,y\rangle$, so that $|\phi(t)|\leq\|x\|\|y\|$. On the other hand, we expect that $U(t)=\exp(iAt)$, so that $U(t)^*$ should be $\exp(-iA^*t)$. Thus, $\phi(t)$ should (formally) be equal to $\langle x,e^ty\rangle$. If this is correct, then since $\phi(t)$ is a bounded function of $t$, we must have $\langle x,y\rangle=0$. Thus, $y$ would be orthogonal to every element of a dense subspace of $H$, showing that $x=0$. We could then similarly argue that $N(A^*+iI)=\{0\}$, which would show that $A$ is essentially self-adjoint.\par
To make the argument rigorous, we apply Lemma~\ref{Hilbert space 1-parameter group derivative}, giving
\begin{align*}
\frac{d}{dt}\langle U(t)x,y\rangle&=\langle iAU(t)x,y\rangle=\langle iU(t)x,A^*y\rangle\\
&=\langle iU(t)x,iy\rangle=\langle U(t)x,y\rangle.
\end{align*}
Thus, the function $\phi(t):=\langle U(t)x,y\rangle$ satisfies the ordinary differential equation $d\phi/dt=\phi$. The unique solution to this equation is $\phi(t)=\phi(0)e^t$. Since $\phi$ is bounded, we must have $0=\phi(0)=\langle x,y\rangle$ for all $x\in D(A)$, which implies that $y=0$. Thus, $N(A^*-iI)=\{0\}$, and by a similar argument shows $N(A^*+iI)=\{0\}$, which proves $A$ is essentially self-adjoint.\par
We can now construct a strongly continuous unitary group $V$ by setting $V(t)=\exp(i\bar{A}t)$. To show that $V=U$, take $x\in D(A)\sub D(\bar{A})$ and set $\psi(t)=U(t)x-V(t)x$. By Theorem~\ref{Hilbert space self-adjoint exp(itA)}, the infinitesimal generator of $V$ is $\bar{A}$. Thus, applying Lemma~\ref{Hilbert space 1-parameter group derivative} to both $U$ and $V$, we have
\[\frac{d}{dt}\psi(t)=iAU(t)x-iAV(t)x=iA\psi(t)\]
where the limit defining dw/dt is taken in the norm topology on $H$. Thus
\[\frac{d}{dt}\|\psi(t)\|^2=\langle\frac{d}{dt}\psi(t),\psi(t)\rangle+\langle\psi(t),\frac{d}{dt}\psi(t)\rangle=\langle iA\psi(t),\psi(t)\rangle+\langle\psi(t),iA\psi(t)\rangle=0\]
because $A$ is symmetric. Since also $\psi(0)=0$, we conclude that $\psi(0)=0$ for all $t$. Thus, $U$ and $V$ agree on a dense subspace and hence on all of $H$.\par
We now know that $U(t)=\exp(i\bar{A}t)$. It then follows from Theorem~\ref{Hilbert space self-adjoint exp(itA)} that the infinitesimal generator of $U$ (namely $A$) is precisely $\bar{A}$. That is, $A$ is closed and $U(t)=\exp(iAt)$. Furthermore, we have already shown that $A$ is essentially self-adjoint and we now know that $A=\bar{A}$, so $A$ is actually self-adjoint. Finally, if $B$ is any self-adjoint operator for which $U(t)=\exp(iBt)$, then by Theorem~\ref{Hilbert space self-adjoint exp(itA)}, $B$ must be the infinitesimal generator of $U$, i.e., $B=A$.
\end{proof}
By virtue of Stone's Theorem and Theorem~\ref{Hilbert space self-adjoint exp(itA)}, there is a one-to-one correspondence between self-adjoint operators and strongly continuous one-parameter unitary groups. Thus, it should be possible to characterize certain properties of a group in terms of its infinitesimal generator and vice versa. For example, suppose the infinitesimal generator is bounded; what can be said about the group?
\begin{proposition}\label{Hilbert space 1-parameter group bounded iff}
If $U$ is a strongly continuous one parameter unitary group with infinitesimal generator $A$, then $A$ is bounded if and only if $U$ is norm continuous.
\end{proposition}
\begin{proof}
First assume that $A$ is bounded. Then $\|U(t)-I\|=\|\exp{itA}-I\|=\|e^{it\lambda}-1\|_{\sigma(A)}$. Since $\sigma(A)$ is compact, it follows that $U$ is norm continuous at $0$, hence norm continuous.
Now assume that $U$ is norm continuous. Let $0<\eps<\pi/4$; then there is a $t_0>0$ such that $\|U(t)-I\|<\eps$ for $|t|<t_0$. But
\[U(t)-I=\exp(itA)-I=\int_{\sigma(A)}(e^{it\lambda}-1)\,dE(\lambda),\]
so it follows that $\|e^{itx}-1\|_{\sigma(A)}<\eps$ for $|t|<t_0$. Thus for a small $\delta$, $t\lambda\in \bigcup_{n=-\infty}^{\infty}(2\pi n-\delta,2\pi n+\delta):=U$ whenever $\lambda\in\sigma(A)$ and $|t|<t_0$. In fact, if $\eps$ is chosen sufficiently small, then $\delta$ is small enough so that the intervals $\{(2\pi n-\delta,2\pi n+\delta)\}$ are the components of $U$. If $\lambda\in\sigma(A)$, then $\{t\lambda:0\leq t<t_0\}$ is the interval from $0$ to $t_0\lambda$ and is contained in $U$. Since this interval is connected, it follows that $t\lambda\in(-\delta,\delta)$. In particular, $t_0\in\sigma(A)\sub[-\delta,\delta]$ so $\sigma(A)$ is compact and $A$ is bounded.
\end{proof}

