\chapter{Ergodic Theory}
\section{Recurrence}
\subsection{Invariant measures}
Let $(X,\mathcal{A},\mu)$ be a measure space and $T:X\to X$ be a measurable transformation. We say that the measure $\mu$ is \textbf{invariant under $\bm{T}$} if
\[\mu(E)=\mu(T^{-1}(E))\]
for every measurable set $E\in\mathcal{A}$. We also say that $\mu$ is \textbf{$\bm{T}$-invariant}, or that $T$ \textbf{preserves} $\mu$, to mean just the same.\par
It is possible, and convenient, to extend this definition to other types of dynamical systems, beyond transformations. We are especially interested in \textbf{flows}, that is, families of transformations $\phi^t$, with $t\in\R$, satisfying the following conditions:
\[\phi^0=\id,\quad \phi^{s+t}=\phi^s\circ\phi^t\for s,t\in\R.\]
In particular, each transformation $\phi^t$ is invertible and the inverse is $\phi^{-t}$. We say that a measure $\mu$ is invariant under a flow $(\phi^t)_{t\in\R}$ if it is invariant under each one of the transformations $\phi^t$, that is, if
\[\mu(E)=\mu(\phi^{-t}(E))\for E\in\mathcal{A},t\in\R.\]

According to the definitions, to check whether a transformation is measure preserving, one needs to verify the conditions for all measurable sets. It would be convenient of course if it would be sufficient to check the conditions on a more manageable, smaller collection of subsets of $X$. One possible option is a generating semi-algebra, as the following theorem shows.
\begin{theorem}\label{measure perserving iff on semi-algebra}
Let $(X,\mathcal{A},\mu)$ be a measure space and $T:X\to X$ a map. Let $\mathcal{S}$ be a generating semi-algebra for $\mathcal{A}$ that contains an exhausting sequence $(X_n)$, i.e., an increasing sequence with $X=\bigcup_nX_n$. Suppose that for each $E\in\mathcal{S}$ one has $\mu(E)=\mu(T^{-1}(E))$. If furthermore, $\mu(X_n)=\mu(T^{-1}(X_n))<+\infty$ for all $n$, then $T$ is measure preserving.
\end{theorem}
\begin{proof}
For each $m\in\N$, we consider the collection
\[\mathcal{D}_m=\{E\in\mathcal{A}:\mu(T^{-1}(E\cap X_m))=\mu(E\cap X_m)\}.\]
Then by the hypothesis we have $\mathcal{S}\sub\mathcal{D}_m\sub\mathcal{A}$. We now show that each $\mathcal{D}_m$ is a monotone class.\par
Let $\{E_n\}$ be an increasing sequence in $\mathcal{D}_n$ and $E=\bigcup_nE_n$. Then we have
\[T^{-1}(E\cap X_m)=\bigcup_{n=1}^{\infty}T^{-1}(E_n\cap X_m),\]
and therefore
\begin{align*}
\mu(T^{-1}(E\cap X_m))&=\mu\Big(\bigcup_{n=1}^{\infty}T^{-1}(E_n\cap X_m)\Big)=\lim_nT^{-1}(E_n\cap X_m)\\
&=\lim_n\mu(E_n\cap X_m)=\mu(E\cap X_m).
\end{align*}
Thus, $E\in\mathcal{D}_m$. A similar proof shows that if $\{F_n\}$ is a decreasing sequence in $\mathcal{D}_m$ and $F=\bigcap_nF_n$, then $F\in\mathcal{D}_m$. Thus $\mathcal{D}_m$ is a monotone class containing the algebra $\sigma(\mathcal{S})$. By the Monotone Class Theorem, $\mathcal{A}$ is the monotone class generated by $\mathcal{S}$, so $\mathcal{A}\sub\mathcal{D}_m$. This shows $\mathcal{D}_m=\mathcal{A}$ for each $m$.\par
Now let $E\in\mathcal{A}$, then $E\in\mathcal{D}_m$ for all $m$, hence we have 
\[\mu(T^{-1}(E))=\lim_{m\to+\infty}\mu(T^{-1}(E\cap X_m))=\lim_{m\to+\infty}\mu(E\cap X_m)=\mu(E).\]
This proves $T$ is measure preserving.
\end{proof}
Another way of verifying whether a given measure is invariant is by using the Koopman operator. Let $(X,\mathcal{A},\mu)$ be a measure space and $T:X\to X$ a transformation. The induced \textbf{Koopman operator} $U_T:L^0(\mu)\to L^0(\mu)$ is given by
\[U_T(f)=f\circ T.\]
The next proposition helps to check whether a measure is invariant.
\begin{proposition}\label{measure perserving iff integral of function}
Let $T:X\to X$ be a measurable transformation and $\mu$ be a measure on $X$. Then $T$ preserves $\mu$ if and only if
\begin{align}\label{measure perserving iff integral of function-1}
\int f\circ T\,d\mu=\int f\,d\mu
\end{align}
for every $\mu$-integrable function $f$.
\end{proposition}
\begin{proof}
Suppose that the measure $\mu$ is invariant under $T$. We are going to show that the relation $(\ref{measure perserving iff integral of function-1})$ is valid for increasingly broader classes of functions. Let $\chi_E$ denote the characteristic function of any measurable subset $E$. Then
\[\mu(E)=\int\chi_E\,d\mu,\quad \mu(T^{-1}(E))=\int\chi_{T^{-1}(E)}\,d\mu=\int\chi_E\circ T\,d\mu.\]
Thus, the hypothesis $\mu(E)=\mu(T^{-1}(E))$ means that $(\ref{measure perserving iff integral of function-1})$ is valid for characteristic functions. Then, by linearity of the integral, $(\ref{measure perserving iff integral of function-1})$ is valid for all simple functions. Next, given any integrable $f:X\to\C$, consider a sequence $\{\phi_n\}$ of simple functions, converging to $f$ and such that $|\phi_n|\leq|f|$ for every $n$.Then, using the dominated convergence theorem, we see that
\[\int f\,d\mu=\lim_n\int\phi_n\,d\mu=\lim_n\int\phi_n\circ T\,d\mu=\int f\circ T\,d\mu.\]
This shows that $(\ref{measure perserving iff integral of function-1})$ holds for every integrable function if $\mu$ is invariant. The converse is also contained in the arguments we just presented.
\end{proof}
\begin{corollary}
Let $(X,\mathcal{A},\mu)$ be a measure space and $T:X\to X$ a measure preserving transformation. Then for each $1\leq p\leq+\infty$, the Koopman operator $U_T:L^p(\mu)\to L^p(\mu)$ is an isometry.
\end{corollary}
\begin{example}[\textbf{Translation}]
For any $t\in\R$, define the translation by $\alpha$ to be the map
\[T:\R\to\R,\quad x\mapsto x+t.\]
By the shift invariance of the Lebesgue measure $\lambda$, it follows immediately that $\lambda$ is invariant for $T$. 
\end{example}
\begin{example}[\textbf{Rotation}]
Let $S^1\sub\C$ denote the complex unit circle. The measure we consider on the $\sigma$-algebra $\mathcal{B}(S^1)$ is the angular measure $\mu=d\theta$. Let $0<\theta<1$ and define rotation by angle $\theta$ on $S^1$ by
\[R_\theta:S^1\to S^1,\quad z\mapsto e^{2\pi i\theta}z.\]
One easily verifies that the collection of all half open arcs is a generating semi-algebra for $S^1$, so it is enough to check measure preservingness only for such arcs. Since $R_\theta$ is anisometry, it is clear that $\mu$ is $R_\theta$-invariant.\par
More generally, if $\theta=(\theta_1,\dots,\theta_d)\in\R^d$, then we can define the rotation $R_\theta:\T^d\to\T^d$ by
\[R_\theta(x_1,\dots,x_d)=(e^{2\pi i\theta_1}x_1,\dots,e^{2\pi i\theta_d}x_d).\]
It is clear that the angular measure $\mu=d\theta_1\cdots d\theta_d$ is invariant under $R_\theta$.
\end{example}
\begin{example}[\textbf{Doubling map}]
Let $T:[0,1]\to[0,1]$ be given by
\[Tx=2x\mod 1.\]
$T$ is called the \textbf{doubling map}. Note that the set of intervals $[a,b)$ form a generating semi-algebrafor $([0,1],\mathcal{B})$, so to verify that $T$ is measure preserving with respect to the Lebesgue measure $\lambda$, it is enough to only consider such intervals. For any interval $[a,b)$, we have
\[T^{-1}([a,b))=[\frac{a}{2},\frac{b}{2})\cup[\frac{a+1}{2},\frac{b+1}{2}),\]
so $\lambda$ is $T$-invariant. Although this map is very simple, it has in fact many facets. For example, iterations of this map yield the binary expansion of points in $[0,1]$. In other words, using $T$ one can associate with each point in $[0,1]$ an infinite sequence $\{a_n\}$ of $0$'s and $1$'s, such that $x=\sum_{n}\frac{a_n}{2^n}$. To do so, define the function $a_1$ by
\[a_1(x)=\begin{cases}
0&x\in[0,\frac{1}{2}),\\
1&x\in[\frac{1}{2},1).
\end{cases}\]
so that $Tx=2x-a_1(x)$. Inductively, we set $a_n(x)=a_1(T^{n-1}x)$. Then we see
\[T^nx=2T^{n-1}x-a_n(x).\]
Rewriting this equation, we get
\[x=\frac{a_1}{2}+\frac{Tx}{2}=\frac{a_1(x)}{2}+\frac{a_n(x)}{2^2}+\frac{T^2x}{2^2}=\cdots=\frac{a_1(x)}{2}+\frac{a_2(x)}{2^2}+\cdots+\frac{T^nx}{2^n}.\]
Since $T$ take its values in $[0,1]$, we then see
\[x-\sum_{n=1}^{N}\frac{a_n(x)}{2^n}=\frac{T^Nx}{2^N}\to 0.\]
Thus, we have found the binary expansion of $x$.
\end{example}
\begin{example}\label{measure preserving surjective homo eg}
Generalizing the previous example, let $X$ be a compact abelian group and let $T:X\to X$ be a surjective endomorphism. Then $T$ preserves the Haar measure $\mu_X$ on $X$ by the following argument. Let $x\in X$ and choose $y\in X$ such that $T(y)=x$. Then
\[\mu_X(T^{-1}(x+E))=\mu_X(y+T^{-1}(E))=\mu_X(T^{-1}(E)),\]
so $T_*\mu_X$ is a translation-invariant probability measure on $X$, which must coincide with $\mu_X$. This shows $T$ is measure preserving.
\end{example}
\subsection{Poincar\'e recurrence theorem}
One of the central themes in ergodic theory is that of recurrence, which is a circle of results concerning how points in measurable dynamical systems return close to themselves under iteration. The first and most important of these is a result due to Poincar\'e published in 1890; he proved this in the context of a natural invariant measure in the "three-body" problem of planetary orbits, before the creation of abstract measure theory. Poincar\'e recurrence is the pigeon-hole principle for ergodic theory; indeed on a finite measure space it is exactly the pigeon-hole principle.
\begin{theorem}[\textbf{Poincar\'e recurrence}]\label{Poincare recurrence thm}
Let $T:X\to X$ be a measurable transformation and $\mu$ be a finite measure invariant under $T$. Let $E\sub X$ be any measurable set with $\mu(E)>0$. Then, for $\mu$-almost every point $x\in E$ there exist infinitely many values of $n$ for which $T^n(x)$ is also in $E$.
\end{theorem}
\begin{proof}
Let $E_\infty$ denote the set of points in $E$ that never return to $E$. Then we can write $E_\infty$ as
\[E_\infty=E\cap\bigcap_{i=1}^{\infty}T^{-i}(E^c),\]
so $E_\infty$ is measurable. From this, we also get
\[T^{-n}(E_\infty)=T^{-n}(E)\cap\bigcap_{i=1}^{\infty}T^{-n-i}(E^c)\]
so the sets $\{T^{-n}(E_\infty)\}$ are pairwise disjoint and all have measure $\mu(E_\infty)$ since $T$ preserves $\mu$. Since $\mu$ is finite, we must have $\mu(E_\infty)=0$, so there is a set $F_1\sub E$ with $\mu(F_1)=\mu(E)$ and for which every point of $F_1$ returns to $E$ at least once under iterates of $T$. The same argument applied to the transformations $T^n$ defines subsets $F_n$ of $E$ with $\mu(F_n)=\mu(E)$ and with every point of $F_n$ returning to $E$ under $T^n$. Then the set $F=\bigcap F_n$ has $\mu(F)=\mu(E)$, and every point of $F$ returns to $E$ infinitely often.
\end{proof}
Poincar\'e recurrence is entirely a consequence of the measure space being of finite measure, as shown in the next example.
\begin{example}
The map $T:\R\to\R$ defined by $T(x)=x+1$ preserves the Lebesgue measure $\lambda$ on $\R$. However, for any bounded set $E\sub\R$ and $x\in E$ the set $\{n\in\N:T^n(x)\in E\}$ is finite, so the map $T$ exhibits no recurrence.
\end{example}
Note that the Poincar\'e recurrence theorem implies an analogous result for continuous time systems: if $\mu$ is a finite invariant measure of a flow $(\phi^t)$, then for every measurable set $E\sub X$ with positive measure and for $\mu$-almost every $x\in E$ there exist times $t_j\to+\infty$ such that $\phi^{t_j}(x)\in E$. Indeed, if $\mu$ is invariant under the flow then, in particular, it is invariant under the so-called time-$1$ map $\phi^1$. So, the statement we just made follows immediately from the recurrence theorem applied to $\phi^1$ (the times $t_j$ one finds in this way are integers). Similar observations apply to the other versions of the recurrence theorem that we present in the sequel.\par
We continue our discussion on recurrence. Let $T:X\to X$ be a measurable transformation and $\mu$ be a finite measure invariant under $T$. Let $E\sub X$ be any measurable set with $\mu(E)>0$. Consider the \textbf{first-return time function} $\rho_E:E\to\N\cup\{\infty\}$, defined by
\[\rho_E(x)=\min\{n\geq 1:T^n(x)\in E\}\]
if the set on the right-hand side is non-empty and $\rho_E=\infty$ if, on the contrary, $x$ has no iterate in $E$. According to Theorem~\ref{Poincare recurrence thm}, the second alternative occurs only on a set with zero measure.\par
The next result shows that this function is integrable and even provides the
value of the integral. For the statement we need the following notation:
\[E_\infty=\{x\in E:T^n(x)\notin E\text{ for $n\geq 1$}\},\quad E_\infty^*=\{x\in X:T^n(x)\notin E\text{ for $n\geq 0$}\}.\]
In other words, $E_\infty$ is the set of points in $E$ that never return to $E$ and $E_\infty^*$ is the set of points in $X$ that never enter $E$. We have seen in Theorem~\ref{Poincare recurrence thm} that $\mu(E_\infty)=0$.
\begin{theorem}[\textbf{Kac}]\label{Kac reccurence}
Let $T:X\to X$ be a measurable transformation, $\mu$ be a finite invariant measure and $E\sub X$ be a positive measure set. Then the function $\rho_E$ is integrable and
\[\int\rho_E\,d\mu=\mu(X)-\mu(E_\infty^*).\]
\end{theorem}
\begin{proof}
For each $n\geq 1$, we define
\[E_n=\{x\in E:T(x)\notin E,\dots,T^{n-1}(x)\notin E,T^n(x)\in E\}=\{x\in E:\rho_E(x)=n\},\]
and
\[E_n^*=\{x\in M:x\notin E,T(x)\notin E,\dots,T^{n-1}(x)\notin E,T^n(x)\in E\}.\]
That is, $E_n$ is the set of points of $E$ that return to $E$ for the first time exactly at time $n$, and $E_n^*$ is the set points that are not in $E$ and enter $E$ for the first time exactly at time $n$. It is clear that these sets are measurable and, hence, $\rho_E$ is a measurable function. Moreover, the sets $E_n$, $E^*_n$, $n\in\N\cup\{\infty\}$ constitute a partition of the ambient space $X$.
\begin{align}\label{Kac reccurence-1}
\mu(X)=\mu(E_\infty^*)+\sum_{n=1}^{\infty}(\mu(E_n)+\mu(E_n^*)).
\end{align}
Now we claim that
\begin{align}\label{Kac reccurence-2}
T^{-1}(E_n^*)=E_{n+1}^*\cup E_{n+1}
\end{align}
for each $n$. In fact, $T(y)\in E_n^*$ if and only if the first iterate of $T(y)$ that belongs to $E$ is $T^n(T(y))=T^{n+1}(y)$, which occurs if and only if $y\in E_{n+1}^*$ or else $y\in E_{n+1}$, depending on whether $y\in E$ or not. Now, since $\mu$ is invariant, we then get
\[\mu(E_n^*)=\mu(T^{-1}(E_n^*))=\mu(E_{n+1}^*)+\mu(E_{n+1}).\]
Applying this relation successively, we find that
\begin{align}\label{Kac reccurence-3}
\mu(E_n^*)=\mu(E_m^*)+\sum_{i=n+1}^{m}\mu(E_{i})\for m>n.
\end{align}
Note that the relation $(\ref{Kac reccurence-1})$ implies $\mu(E_m^*)\to 0$ as $m\to\infty$, so taking limit in the equality $(\ref{Kac reccurence-2})$, we find that
\[\mu(E_n^*)=\sum_{i=n+1}^{\infty}\mu(E_i).\]
Replacing this in $()$ then yields
\[\mu(X)-\mu(E_\infty^*)=\sum_{n=1}^{\infty}\Big(\mu(E_n)+\sum_{i=n+1}^{\infty}\mu(E_n)\Big)=\sum_{n=1}^{\infty}n\mu(E_n)=\int_E\rho_E\,d\mu.\]
This completes the proof.
\end{proof}
Finally, we consider recurrence in topological spaces. Suppose that $X$ is a topological space, endowed with its Borel $\sigma$-algebra $\mathcal{B}$. A point $x\in X$ is \textbf{recurrent} for a transformation $T:X\to X$ if there exists a sequence $n_j\to+\infty$ of natural numbers such that $T^{n_j}(x)\to x$. Analogously, we say that $x\in X$ is recurrent for a flow $(\phi^t)$ if there exists a sequence $t_j\to+\infty$ of real numbers such that $\phi^{t_j}(x)\to x$.\par
In the next theorem we assume that the topological space $X$ is second countable. This condition holds in most interesting examples.
\begin{theorem}[\textbf{Poincar\'e recurrence}]\label{Poincare recurrence topological}
Suppose that $X$ is a second countable topological space. Let $T:X\to X$ be a measurable transformation and $\mu$ be a finite measure on $X$ invariant under $T$. Then, $\mu$-almost every $x\in X$ is recurrent for $T$.
\end{theorem}
\begin{proof}
Let $\{U_n\}$ be a countable basis for $X$. For each $n$, let $\widetilde{U}_n$ be the set of points $x\in U_n$ that never return to $U_n$. According to Theorem~\ref{Poincare recurrence thm}, every $\widetilde{U}_n$ has zero measure. Consequently, the countable union
\[\widetilde{U}=\bigcup_n\widetilde{U}_n\]
also has zero measure. Hence, to prove the theorem it suffices to check that every point $x$ that is not in $\widetilde{U}$ is recurrent. That is easy, as we are going to see. Consider $x\in X\setminus\widetilde{U}$ and let $U$ be any neighborhood of $x$. By definition, there exists some element $U_n$ of the basis of open sets such that $x\in U_n\sub U$.
Since $x$ is not in $\widetilde{U}$, we also have that $x\notin\widetilde{U}_n$. In other words, there exists $N\geq 1$ such that $T^N(x)$ is in $U_n$. In particular, $T^N(x)$ is also in $U$. Since the neighborhood $U$ is arbitrary, this proves that $x$ is a recurrent point.
\end{proof}
\begin{theorem}[\textbf{Birkhoff recurrence}]
If $T:X\to X$ is a continuous transformation on a compact metric space $X$ then there exists some point $x\in X$ that is recurrent for $T$.
\end{theorem}
\begin{proof}
Consider the family $\mathscr{I}$ of all non-empty closed sets $F\sub X$ that are invariant under $T$, in the sense that $T(F)\sub F$. This family is non-empty, since $X\in\mathscr{I}$. We claim that an element $F\in\mathscr{I}$ is minimal for the inclusion relation if and only if the orbit of every $x\in F$ is dense in $F$. Indeed, it is clear that if $F$ is a closed invariant subset then $F$ contains the closure of the orbit of each one of its elements. Hence, in order to be minimal, $F$ must coincide with every one of these closures. Conversely, for the same reason, if $F$ coincides with the orbit closure of each one of its points then it has no proper subset that is closed and invariant. That is, $F$ is minimal. This proves our claim. In particular, every point $x$ in a minimal set is recurrent. Therefore, to prove the theorem it suffices to prove that there exists some minimal set.\par
We claim that every totally ordered set $\{F_\alpha\}\sub\mathscr{I}$ admits a lower bound. Indeed, consider $F=\bigcap_\alpha F_\alpha$. Observe that $F$ is non-empty, since the $F_\alpha$ are compact and they form a totally ordered family. It is clear that $F$ is closed and invariant under $T$ and it is equally clear that $T$ is a lower bound for the set $\{F_\alpha\}$. That proves our claim. Now it follows from Zorn's lemma that $\mathscr{I}$ does contain minimal elements.
\end{proof}
Next, we describe some simple examples of invariant measures for transformations and flows that help us interpret the significance of the Poincar\'e recurrence theorems and also lead to some interesting conclusions.
\begin{example}
Our first example is the transformation defined on the interval $[0,1]$ in the following way:
\[T(x)=10x\mod 1.\]
By Example~\ref{measure preserving surjective homo eg}, we know $T$ preserves the Lebesgue measure $\lambda$ on $[0,1]$. The transformation $T$ is directly related to the usual decimal expansion of a real number: if $x$ is given by
\[x=0.a_1a_2\cdots\]
with $a_i\in\{0,1,\dots,9\}$ and $a_i\neq 9$ for infinitely many values of $i$, then its image under $T$ is given by
\[T(x)=0.a_2a_3\cdots.\]
Thus, more generally, the $n$-th iterate of $T$ can be expressed in the following way, for every $n$:
\[T^n(x)=0.a_na_{n+1}\cdots.\]
Let $E$ be the subset of points $x\in[0,1]$ whose decimal expansion starts with the digit $7$, that is, such that $a_0=7$. According to Theorem~\ref{Poincare recurrence thm}, almost every element in $E$ has infinitely many iterates that are also in $E$. By the expression above, this means that there are infinitely many values of $n$ such that $a_n=7$. So, we have shown that almost every number $x$ whose decimal expansion starts with $7$ has infinitely many digits equal to $7$.
\end{example}
\begin{example}
Given any number $x_0\in(0,1)$, let
\[a_1=\Big[\frac{1}{x_0}\Big],\quad x_1=\frac{1}{x_0}-a_1.\]
Note that $a_1$ is a natural number, $x_1\in[0,1)$ and we have
\[x_0=\frac{1}{a_1+x_1}.\]
Supposing that $x_1$ is different from zero, we may repeat this procedure, defining
\[a_2=\Big[\frac{1}{x_1}\Big],\quad x_2=\frac{1}{x_1}-a_2.\]
Then we have
\[x_1=\frac{1}{a_2+x_2}\And x_0=\frac{1}{a_1+\frac{1}{a_2+x_2}}.\]
Now we may proceed by induction: for each $n\geq 1$ such that $x_{n-1}\in(0,1)$, define
\[a_n=\Big[\frac{1}{x_{n-1}}\Big],\quad x_n=\frac{1}{x_{n-1}}-a_n=:G(x_{n-1})\]
and observe that
\begin{align}\label{continued fraction expansion-1}
x_0=\frac{1}{a_1+\frac{1}{a_2+\frac{1}{\cdots+\frac{1}{a_n+x_n}}}}.
\end{align}
It can be show that the sequence
\begin{align}\label{continued fraction expansion-2}
z_n=\frac{1}{a_1+\frac{1}{a_2+\frac{1}{\cdots+\frac{1}{a_n}}}}
\end{align}
converges to $x_0$ when $n\to+\infty$. This is usually expressed through the expression
\begin{align}\label{continued fraction expansion-3}
x_0=\frac{1}{a_1+\frac{1}{a_2+\frac{1}{\cdots+\frac{1}{a_n+\frac{1}{\cdots}}}}}
\end{align}
which is called \textbf{continued fraction expansion} of $x_0$. Note that the sequence $\{z_n\}$ defined above consists of rational numbers. Indeed, one can show that these are the best rational approximations of the number x0, in the sense that each $z_n$ is closer to $x_0$ than any other rational number whose denominator is smaller than or equal to the denominator of $z_n$ (written in irreducible form). Observe also that to obtain $(\ref{continued fraction expansion-3})$ we had to assume that $x_n\in(0,1)$ for every $n\in\N$. If in the course of the process one encounters some $x_n=0$, then the algorithm halts and we consider $(\ref{continued fraction expansion-1})$ to be the continued fraction expansion of $x_0$. It is clear that this can happen only if $x_0$ itself is a rational number.\par
This continued fraction algorithm is intimately related to a certain dynamical system on the interval $[0,1]$ that we describe in the following. The Gauss map $G:[0,1]\to[0,1]$ is defined by
\[G(x)=\Big\{\frac{1}{x}\Big\}:=\frac{1}{x}-\Big[\frac{1}{x}\Big].\]
if $x\in(0,1]$ and $G(0)=0$. The graph of $G$ can be easily sketched, starting from the following observation: for every $x$ in each interval $I_n=(1/(n+1),1/n]$, the integer part of $1/x$ is equal to $n$ and so $G(x)=1/x-n$. The continued fraction expansion of any number $x\in(0,1)$ can be obtained from the Gauss map in the following way: for each $n\geq 1$, the natural number $a_n$ is determined by
\[G^{n-1}(x_0)\in I_{a_n}.\]
and the real number $x_n$ is simply the $n$-th iterate $G_n(x_0)$ of the point $x_0$. This process halts whenever we encounter some $x_n=0$; as we explained previously, this can only happen if $x_0$ is a rational number. In particular, there exists a full Lebesgue measure subset of $(0,1)$ such that all the iterates of $G$ are defined for all the points in that subset.\par
A remarkable fact that makes this transformation interesting from the point of view of ergodic theory is that $G$ admits an invariant probability measure that, in addition, is equivalent to the Lebesgue measure on the interval. Indeed, consider the measure defined by
\[\mu(E)=\frac{1}{\log 2}\int_E\frac{dx}{1+x}.\]
Then for any interval $(a,b)\sub[0,1]$, we observe that
\begin{align*}
\mu(G^{-1}(a,b))&=\frac{1}{\log 2}\sum_{n=1}^{\infty}\int_{\frac{1}{n+b}}^{\frac{1}{n+a}}\frac{dx}{1+x}=\frac{1}{\log 2}\sum_{n=1}^{\infty}\Big(\log\frac{n+a+1}{n+a}-\log\frac{n+b+1}{n+b}\Big)\\
&=\frac{1}{\log 2}\log\frac{1+b}{1+a}=\mu((a,b)).
\end{align*}
Thus $\mu$ is $T$-invariant. Since $\mu$ is a probability measure on $[0,1]$, we can use ideas from ergodic theory, applied to the Gauss map, to obtain interesting conclusions in number theory. For example, the natural number $7$ occurs infinitely many times in the continued fraction expansion of almost every number $x_0\in(1/8,1/7)$, that is, one has $a_n=7$ for infinitely many values of $n\in\N$. Later on, we will prove a much more precise statement, that contains the following conclusion: for almost every $x_0\in(0,1)$ the number $7$ occurs with frequency
\[\mu((\frac{1}{8},\frac{1}{7}))=\frac{1}{\log 2}\log\frac{64}{63}.\]
in the continued fraction expansion of $x_0$.
\end{example}
\begin{example}
Given $\theta\in\R$, we have shown that the rotation $R_\theta:S^1\to S^1$ preserves the Lebesgue measure on $S^1$. We also note that $\theta\mapsto R_\theta$ defines a flows on $S^1$, and if $\theta=p/q$, we then have $R_\theta^q(x)=x$ for all $x\in S^1$. Consequently, in this case every point $x\in S^1$ is periodic with period $q$. In the opposite case, if $\theta$ is irrational, then $\mathcal{O}(x)=\{R_\theta^n(x):n\in\N\}$ is dense in $S^1$, so we conclude that every point on the circle is recurrent for $R_\theta$ (this is also true when Î¸ is rational). The previous observation also leads to some interesting conclusions in the study of the invariant measures of $R_\theta$. Among other things, we will learn later that if $\theta$ is irrational then the Lebesgue measure is the unique probability measure that is preserved by $R_\theta$. Related to this, we will see that the orbits of $R_\theta$ are uniformly distributed subsets of $S^1$.
\end{example}
\subsection{Induced systems}
In this part we describe a general method, based on the Poincar\'e recurrence theorem, to construct from a given system $(T,\mu)$ other systems, that we refer to as systems induced by $(T,\mu)$. The reason this is interesting is the following. On the one hand, it is often the case that an induced system is easier to analyze, because it has better global properties than the original one. On the other hand, interesting conclusions about the original system can often be obtained from analyzing the induced one. Examples will appear in a while.
\subsubsection{First-return map}
Let $T:X\to X$ be a measurable transformation and $\mu$ be an invariant probability measure. Let $E\sub X$ be a measurable set with $\mu(E)>0$ and $\rho(x)=\rho_E(x)$ be the \textbf{first-return time} of $x$ to $E$. The \textbf{first-return map} to the domain $E$ is the map $S$ given by
\[R(x)=T^{\rho(x)}(x),\]
whenever $\rho(x)$ is finite. The Poincar\'e recurrence theorem ensures that this is the case for $\mu$-almost every $x\in E$ and so $R$ is defined on a full measure subset of $E$. We also denote by $\mu_E$ the restriction of $\mu$ to the measurable subsets $E$.
\begin{proposition}\label{invariant measure first return map}
The measure $\mu_E$ is invariant under the map $R:E\to E$.
\end{proposition}
\begin{proof}
For every $n\geq 1$, denote by $E_n$ the subset of points $x\in E$ such that $\rho(x)=n$, and $E_n^*$ the set points that are not in $E$ and enter $E$ for the first time exactly at time $n$. Let $B$ be any measurable subset of $E$. Then
\begin{align}\label{invariant measure first return map-1}
\mu(R^{-1}(B))=\sum_{n=1}^{\infty}\mu(T^{-n}(B)\cap E_n).
\end{align}
On the other hand, since $\mu$ is $T$-invariant,
\[\mu(B)=\mu(T^{-1}(B))=\mu(T^{-1}(B)\cap E_1)+\mu(T^{-1}(B)\cap E_1^*).\]
Analogously,
\[\mu(T^{-1}(B)\cap E_1^*)=\mu(T^{-2}(B)\cap T^{-1}(E_1^*))=\mu(T^{-2}(B)\cap E_2)+\mu(T^{-2}(B)\cap E_2^*).\]
Repeating this argument successively, we obtain
\[\mu(B)=\sum_{n=1}^{m}\mu(T^{-n}(B)\cap E_n)+\mu(T^{-m}(B)\cap E_m^*).\]
From the proof of Theorem~\ref{Kac reccurence}, we have $\mu(E_m^*)\to 0$, and thus
\[\mu(B)=\sum_{n=1}^{\infty}\mu(T^{-n}(B)\cap E_n).\]
Together with $(\ref{invariant measure first return map-1})$, this shows that $\mu(R^{-1}(B))=\mu(B)$ for every measurable subset $B$ of $E$. That is to say, the measure $\mu_E$ is invariant under $R$.
\end{proof}
\begin{example}
Consider the transformation $T:[0,\infty)\to [0,\infty)$ defined by
\[T(x)=\begin{cases}
0&x=0,\\[2pt]
\dfrac{1}{x}&x\in(0,1),\\[2pt]
x-1&x\in[1,\infty).
\end{cases}\]
Let $E=[0,1]$. The time $\rho$ of first return to $E$ is given by
\[\rho(x)=\begin{cases}
1&x=0,\\
n+1&x\in(\frac{1}{n+1},\frac{1}{n}].
\end{cases}\]
So, the first-return map to $E$ is given by
\[R(x)=\dfrac{1}{x}-n\for x\in(\frac{1}{n+1},\frac{1}{n}]\]
and $R(0)=0$. In other words, $R$ is the Gauss map.
\end{example}
\subsubsection{Induced transformations}
In an opposite direction, given any measure $\nu$ invariant under $R:E\to E$, we may construct a certain related measure $\nu_\rho$ that is invariant under $T:X\to X$. For this, $R$ does not even have to be a first-return map: the construction that we present below is valid for any map induced from $T$, that is, any map of the form
\begin{align}\label{invariant measure induced map}
R:E\to E,\quad R(x)=T^{\rho(x)}(x)
\end{align}
where $\rho:E\to\N$ is a measurable function (it suffices that $\rho$ is defined on some full measure subset of $E$). As before, we denote by $E_n$ the subset of points $x\in E$ such that $\rho(x)=n$. Then we define
\begin{align}\label{invariant measure induced measure}
\nu_\rho(B)=\sum_{n=0}^{\infty}\sum_{m>n}\nu(T^{-n}(B)\cap E_m)
\end{align}
for every measurable set $B\sub X$.
\begin{proposition}
The measure $\nu_\rho$ defined in $(\ref{invariant measure induced measure})$ is invariant under $T$ and satisfies $\nu_\rho(X)=\int_E\rho\,d\nu$. In particular, $\nu_\rho$ is finite if and only if the function $\rho$ is integrable with respect to $\nu$.
\end{proposition}
\begin{proof}
First, let us prove that $\nu_\rho$ is invariant. By the definition,
\[\nu_\rho(T^{-1}(B))=\sum_{n=0}^{\infty}\sum_{m>n}\nu(T^{-(n+1)}(B)\cap E_m)=\sum_{n=1}^{\infty}\sum_{m\geq n}\nu(T^{-n}(B)\cap E_m).\]
We may rewrite this expression as follows:
\begin{align}\label{invariant measure induced measure-1}
\nu_\rho(T^{-1}(B))=\sum_{n=1}^{\infty}\sum_{m>n}\nu(T^{-n}(B)\cap E_m)+\sum_{m=1}^{\infty}\nu(T^{-m}(B)\cap E_m).
\end{align}
Concerning the last term, observe that, from $(\ref{invariant measure induced map})$,
\[\sum_{m=1}^{\infty}\nu(T^{-m}(B)\cap E_m)=\nu(R^{-1}(B))=\nu(B)=\sum_{m=1}^{\infty}\nu(B\cap E_m).\]
since $\nu$ is invariant under $R$. Replacing this in $(\ref{invariant measure induced measure-1})$, we see that
\begin{align*}
\nu_\rho(T^{-1}(B))&=\sum_{n=1}^{\infty}\sum_{m>n}\nu(T^{-n}(B)\cap E_m)+\sum_{m=1}^{\infty}\nu(B\cap E_m)\\
&=\sum_{n=0}^{\infty}\sum_{m>n}\nu(T^{-n}(B)\cap E_m)=\nu_\rho(B).
\end{align*}
for every measurable set $B\sub E$. The second claim is a direct consequence of the definitions:
\begin{align*}
\nu_\rho(X)=\sum_{n=0}^{\infty}\sum_{m>n}\nu(T^{-n}(X)\cap E_m)=\sum_{n=0}^{\infty}\sum_{m>n}\nu(E_m)=\sum_{n=1}^{\infty}n\nu(E_n)=\int_E\rho\,d\nu.
\end{align*}
This completes the proof.
\end{proof}
It is interesting to analyze how this construction relates to the one in the previous one when $R$ is a first-return map of $T$ and the measure $\nu$ is the restriction $\mu_E$ of some invariant measure $\mu$ of $T$:
\begin{corollary}\label{invariant measure first return map induced measure}
If $R$ is the first-return map of $T$ to a measurable subset $E$ and $\nu=\mu_E$, then
\begin{itemize}
\item[(a)] $\nu_\rho(B)=\mu(B)$ for every measurable set $B\sub E$.
\item[(b)] $\nu_\rho(B)\leq\mu(B)$ for every measurable set $B\sub X$.
\end{itemize}
\end{corollary}
\begin{proof}
By definition, $T^{-n}(E)\cap E_m=\emp$ for every $m>n>0$. This implies that, given any measurable set $B\sub E$, all the terms with $n>0$ in the definition $(\ref{invariant measure induced measure})$ are zero. Hence, $\nu_\rho(B)=\sum_{m>0}\nu(B\cap E_m)=\nu(B)$ as claimed in the first part of the statement.\par
Consider any measurable set $B\sub X$. Then,
\begin{align}\label{invariant measure first return map induced measure-1}
\mu(B)=\nu(B\cap E)+\mu(B\cap E^c)=\sum_{n=1}^{\infty}\nu(B\cap E_n)+\mu(B\cap E^c).
\end{align}
Since $\mu$ is invariant, $\mu(B\cap E^c)=\mu(T^{-1}(B)\cap T^{-1}(E^c))$. Then, as in the previous equality,
\begin{align*}
\mu(B\cap E^c)&=\mu(T^{-1}(B)\cap T^{-1}(E^c)\cap E)+\mu(T^{-1}(B)\cap T^{-1}(E^c)\cap E^c)\\
&=\sum_{n=1}^{\infty}\nu(T^{-1}(B)\cap T^{-1}(E^c)\cap E_n)+\mu(T^{-1}(B)\cap T^{-1}(E^c)\cap E^c)\\
&=\sum_{n=2}^{\infty}\nu(T^{-1}(B)\cap E_n)+\mu(T^{-1}(B)\cap T^{-1}(E^c)\cap E^c).
\end{align*}
Replacing this in $(\ref{invariant measure first return map induced measure-1})$, we find that
\[\mu(B)=\sum_{n=0}^{1}\sum_{m>n}\nu(T^{-n}(B)\cap E_m)+\mu(T^{-1}(B)\cap\bigcap_{n=0}^{1}T^{-n}(E^c)).\]
Repeating this argument successively, we get that
\[\mu(B)=\sum_{n=0}^{N}\sum_{m>n}\mu(T^{-n}(B)\cap E_m)+\mu(T^{-N}(B)\cap\bigcap_{n=0}^{N}T^{-n}(E^c))\geq\sum_{n=0}^{N}\sum_{m>n}\mu(T^{-n}(B)\cap E_m).\]
Taking the limit as $N\to\infty$, we conclude that $\mu(B)\geq\nu_\rho(B)$.
\end{proof}
\subsubsection{Kakutani-Rokhlin towers}
It is possible, and useful, to generalize the previous constructions even further, by omitting the initial transformation $T:X\to X$ altogether. More precisely, given a transformation $R:E\to E$, a measure $\nu$ on $E$ invariant under $R$ and a measurable function $\rho:E\to\N$, we are going to construct a transformation $T:X\to X$ and a measure $\nu_\rho$ invariant under $T$ such that $E$ can be identified with a subset of $X$, $R$ is the first-return map of $T$ to $E$, with first-return time given by $\rho$, and the restriction of $\nu_\rho$ to $E$ coincides with $\nu$.\par
This transformation $T$ is called the \textbf{Kakutani-Rokhlin tower} of $R$ with time $\rho$. The measure $\nu_\rho$ is finite if and only if $\rho$ is integrable with respect to $\nu$. They are constructed as follows. Begin by defining
\[X=\{(x,n):x\in E:0\leq n<\rho(x)\}=\bigcup_{m=1}^{\infty}\bigcup_{n=0}^{m-1}E_m\times\{n\}.\]
In other words, $X$ consists of $m$ copies of each set $E_m$, "piled up" on top of each other. We call each $\bigcup_{m>n}E_m\times\{n\}$ the $n$-th floor of $X$.\par
Next, define $T:X\to X$ as follows:
\[T(x,n)=\begin{cases}
(x,n+1)&n<\rho(x)-1,\\
(R(x),0)&n=\rho(x)-1.
\end{cases}\]
In other words, each point $(x,n)$ is "lifted" one floor at a time, until reaching the floor $\rho(x)-1$; at that stage, the point "falls" directly to $(R(x),0)$ on the ground (zero-th) floor. The ground floor $E\times\{0\}$ is naturally identified with the set $E$. Besides, the first-return map to $E\times\{0\}$ corresponds precisely to $R:E\to E$.\par
Finally, the measure $\nu_\rho$ is defined by
\[\nu_\rho|_{E_m\times\{n\}}=\nu|_{E_m}\]
for every $0\leq n<m$. It is clear that the restriction of $\nu_\rho$ to the ground floor coincides with $\nu$. Moreover, $\nu_\rho$ is invariant under $T$ because $\nu$ is invariant under $R$. Also, we note that
\[\nu_\rho(M)=\sum_{m=1}^{\infty}m\nu(E_m)=\int_E\rho\,d\mu.\]
This completes the construction of the Kakutani-Rokhlin tower.
\subsection{Existence of invariant measures}
Conclude this section, we will prove an existence theorem for invariant measures on a compact space. So let $X$ be a compact space and $M(X)$ be the space of all complex measures on $X$. Since $X$ is compact, we have $C(X)^*=M(X)$, and we endow the weak$^*$ topology on $M(X)$. Let $M_1(X)$ be the subspace of $M(X)$ consists of probability measures on $X$, our first observation will be the following.
\begin{proposition}
The set $M_1(X)$ is compact under the weak$^*$ topology.
\end{proposition}
\begin{proof}
Recall that the unit ball $B_{M(X)}$ is weak$^*$ compact by the Alaoglu theorem. Now $M_1(X)$ is a closed subset of $B_{M(X)}$, so the claim follows.
\end{proof}
At this point, since it is easy to see the push out map $T_*:M(X)\to M(X)$ is weak$^*$ continuous, from the classical Schauder-Tychonoff fixed point theorem one can claim that there exists a fixed point of $T_*$ in $M_1(X)$, i.e., a $T$-invariant probability measure. However, the following construction we provide gives an elementary and concrete proof for this fact.
\begin{proposition}\label{invariant measure existence}
Let $\nu$ be a probability measure on $X$ and define a sequence $\{\mu_n\}$ by
\[\mu_n=\frac{1}{n}\sum_{i=0}^{n-1}T_*^i\nu\]
Then any limit point of $\{\mu_n\}$ is a $T$-invariant probability measure.
\end{proposition}
\begin{proof}
Let $\mu$ be a limit point of $\{\mu_n\}$ in the weak$^*$ topology, so that $\mu_{n_k}\to\mu$ for some subsequence. Given any family $\{\phi_1,\dots,\phi_r\}$ of continuous functions and given any $\eps>0$, we have
\begin{align}\label{invariant measure existence-1}
\Big|\frac{1}{n_k}\sum_{i=0}^{n_k-1}\int(\phi_j\circ T^i)\,d\nu-\int\phi_j\,d\mu\Big|<\eps/2
\end{align}
for $j=1,\dots,r$ and $k$ sufficiently large. On the other hand, applying $T_*$, we get
\[T_*\mu=T_*\lim_{k\to+\infty}\frac{1}{n_k}\sum_{i=0}^{n_k-1}T^i_*\nu=\lim_{k\to+\infty}\frac{1}{n_k}\sum_{i=1}^{n_k}T^i_*\nu.\] 
Also, we observe that, for each $j=1,\dots,r$,
\begin{align*}
\Big|\frac{1}{n_k}\sum_{i=0}^{n_k-1}\int(\phi_j\circ T^i)\,d\nu-\frac{1}{n_k}\sum_{i=1}^{n_k}\int(\phi_j\circ T^i)\,d\nu\Big|=\Big|\frac{1}{n_k}\int(\phi_j-\phi_j\circ T^{n_k})\,d\nu\Big|\leq\frac{2}{n_k}\|\phi_j\|.
\end{align*}
Combining this fact with $(\ref{invariant measure existence-1})$, we conclude that
\[\Big|\frac{1}{n_k}\sum_{i=1}^{n_k}\int(\phi_j\circ T^i)\,d\nu-\int\phi_j\,d\mu\Big|<\eps\]
for each $j=1,\dots,r$ and $k$ sufficiently large. This means that
\[T_*\mu=\lim_{k\to+\infty}\frac{1}{n_k}\sum_{i=1}^{n_k}T_*^i\nu\to\mu,\]
and the claim follows.
\end{proof}
\begin{example}
Consider $T:(0,1]\to (0,1]$ given by $T(x)=x/2$. Suppose that $T$ admits some invariant probability measure: we are going to show that this is actually not true. By the recurrence theorem, relative to that probability measure almost every point of $(0,1]$ is recurrent. However, it is clear that there are no recurrent points: the orbit of every $x\in(0,1]$ converges to zero and, in particular, does not accumulate on the initial point $x$. Hence, $T$ is an example of a continuous transformation (on a non-compact space) that does not have any invariant probability measure.
\end{example}
\section{Ergodicity and mixing}
\subsection{Ergodic theorems}
\subsubsection{Ergodic theorem of von Neumann}
Let $U:H\to H$ be a bounded linear operator on a Hilber space $H$. The set of invariant vectors of $U$ is defined by
\[I(U)=\{x\in H:Ux=x\}.\]
Observe that $I(U)$ is a closed vector subspace, since $U$ is continuous and linear. When $U$ is an isometry, we have that $I(U)=I(U^*)$:
\begin{proposition}\label{Hilbert space isometry invariant iff dual}
If $U:H\to H$ is an isometry then $Ux=x$ if and only if $U^*x=x$.
\end{proposition}
\begin{proof}
If $U$ is an isometry then $U^*U=I$, so $Ux=x$ implies $U^*x=x$. Conversely, if $U^*x=x$, then
\[\langle Ux,x\rangle=\langle x,U^*x\rangle=\|x\|^2.\]
So, using the fact that $U$ preserves the norm of $H$,
\[\|Ux-x\|^2=\|Ux\|^2+\|x\|^2-2\Re\langle Ux,x\rangle=\|Ux\|^2-\|x\|^2=0.\]
Therefore $Ux=x$.
\end{proof}
\begin{theorem}[\textbf{von Neumann}]
Let $U:H\to H$ be an isometry in a Hilbert space $H$ and $P$ be the orthogonal projection to the subspace $I(U)$ of invariant vectors of $U$. Then,
\[\lim_n\frac{1}{n}\sum_{i=0}^{n-1}U^ix=Px\]
for every $x\in H$.
\end{theorem}
\begin{proof}
Let $L(U)=R(U-I)$ and $\widebar{L}(U)$ be its closure. We claim that $I(U)=\widebar{L}(U)^\bot$. First, if $x\in I(U)$, then for any $y\in H$, we have
\[\langle x,Uy-y\rangle=\langle Ux,Uy\rangle-\langle x,y\rangle=0.\]
Therefore $I(U)\bot L(U)$. Conversely, if $x\in\widebar{L}(U)^\bot$, then for any $y\in H$ we have
\[0=\langle x,Uy-y\rangle=\langle x,Uy\rangle-\langle x,y\rangle=\langle U^*x-x,y\rangle.\]
This implies $U^*x=x$, and therefore $Ux=x$ by Proposition~\ref{Hilbert space isometry invariant iff dual}.\par
Now we prove the claim of the theorem. Begin by supposing that $x\in I(U)$. On the one hand, $Pv=v$. On the other hand,
\[\frac{1}{n}\sum_{i=0}^{n-1}Ux=\frac{1}{n}\sum_{i=0}^{n-1}x=x,\]
for every $n$, and so this sequence converges to $x$ when $n\to\infty$. Combining these two observations we get the claim in this case.\par
Next, suppose that $x\in L(U)$. Then, by definition, there exists $y\in H$ such that $x=Uy-y$. It is clear that
\[\frac{1}{n}\sum_{i=0}^{n-1}U^ix=\frac{1}{n}\sum_{i=0}^{n-1}(U^{i+1}x-U^ix)=\frac{1}{n}(U^ny-y).\]
The norm of this last expression is bounded by $2\|x\|/n$ and, consequently, converges to zero when $n\to\infty$. This shows that
\[\lim_n\frac{1}{n}\sum_{i=0}^{n-1}U^ix=0\for x\in L(U).\]
More generally, suppose that $x\in\widebar{L}(U)$. Then, there exist vectors $x_k\in L(U)$ converging to $x$. Observe that
\[\Big\|\frac{1}{n}\sum_{i=0}^{n-1}U^ix-\frac{1}{n}\sum_{i=0}^{n-1}U^ix_k\Big\|\leq\frac{1}{n}\sum_{i=0}^{n-1}\|U^i(x-x_k)\|\leq\|x-x_k\|,\]
so the previous result implies that
\[\lim_n\frac{1}{n}\sum_{i=0}^{n-1}U^ix=0\for x\in\widebar{L}(U).\]
The general case now follows immediately, as $H=I(U)\oplus\widebar{L}(U)$.
\end{proof}
Given a measurable transformation $T:X\to X$ and an invariant probability measure $\mu$ on $X$, we say that a measurable function $f$ is invariant if $f\circ T=f$ at $\mu$-almost every point. The following result is a special case of the previous theorem.
\begin{theorem}
Let $P$ be the orthogonal projection of $L^2(\mu)$ to the subspace of invariant functions under $T$. Then the sequence
\[\frac{1}{n}\sum_{i=0}^{n-1}f\circ T^i\]
converges to $Pf$ in $L^2(\mu)$ for every $f\in L^2(\mu)$.
\end{theorem}
\begin{proof}
By Proposition~\ref{measure perserving iff integral of function}, we see the Koopman operator $U_T:L^2(\mu)\to L^2(\mu)$ is an isometry, so the claim follows.
\end{proof}
\subsubsection{Subadditive ergodic theorem}
A sequence of functions $\{f_n\}$ on $X$ is said to be \textbf{subadditive} for a transformation $T:X\to X$ if
\[f_{m+n}\leq f_m+f_n\circ T^m\]
for every $m,n\geq 1$. It is called \textbf{additive} if the equality. For example,  the time sums
\[f_n=\sum_{i=0}^{n-1}f\circ T^i\]
of any function $f$ form an additive sequence. In fact, every additive sequence is of this form, with $f=f_1$. Of course, additive sequences are also subadditive.\par
Recall that, given any function $f:X\to\R$, we denote by $f^+$ its positive part, which is defined by $f^+(x)=\max\{f(x),0\}$.
\begin{theorem}[\textbf{Kingman}]\label{subadditive ergodic theorem}
Let $\mu$ be a probability measure invariant under a transformation $T:X\to X$ and let $\{f_n\}$ be a subadditive sequence of measurable functions on $X$ such that $f_1\in L^1(\mu)$. Then the sequence $\{f_n/n\}$ converges $\mu$-a.e. to some function $f:X\to\R$ that is invariant under $T$. Moreover, $f\in L^1(\mu)$ and
\[\int f\,d\mu=\lim_{n}\frac{1}{n}\int f_n\,d\mu=\inf_n\frac{1}{n}\int f_n\,d\mu.\]
\end{theorem}
A real sequence $\{a_n\}$ is said to be subadditive if $a_{m+n}\leq a_m+a_n$ for every $m,n\geq 1$.
\begin{lemma}[\textbf{Fekete's Subadditive Lemma}]\label{subadditive sequence limit}
If $\{a_n\}$ is a subadditive sequence then the following limit exists
\begin{align}\label{subadditive sequence limit-1}
\lim_n\frac{a_n}{n}=\inf_n\frac{a_n}{n}\in[-\infty,+\infty).
\end{align}
\end{lemma}
\begin{proof}
Fix $m\in\N$, we may write $n=pm+q$ where $p$ and $q$ are integers such that $p\geq 1$ and $1\leq q\leq m$. Then, by subadditivity,
\[a_n=a_{pm+q}\leq ma_p+a_q\leq ma_p+\alpha\]
where $\alpha:=\max\{a_q:1\leq q\leq m\}$. Dividing by $n$, we then get
\[\frac{a_n}{n}\leq\frac{pm}{n}\frac{a_m}{m}+\frac{\alpha}{n}.\]
Observe that $pm/n$ converges to $1$ and $\alpha/n$ converges to zero when $n\to+\infty$. So we have that
\begin{align}\label{subadditive sequence limit-2}
\varlimsup_n\frac{a_n}{n}\leq\frac{a_m}{m}.
\end{align}
Since $m$ is arbitrary, we then conclude that
\[\varlimsup_n\frac{a_n}{n}\leq\varliminf_m\frac{a_m}{m},\]
and therefore the sequence $\{a_n/n\}$ has a limit. The second claim is clear from $(\ref{subadditive sequence limit-2})$.
\end{proof}
Now let $\{f_n\}$ be as in Theorem~\ref{subadditive ergodic theorem}. By subadditivity,
\[f_n\leq f_1+f_1\circ T+\cdots+f_1\circ T^{n-1}.\]
Hence, the hypothesis that $f_1\in L^1(\mu)$ implies $f_n\in L^1(\mu)$ for all $n$. Moreover, the hypothesis that $\{f_n\}$ is subadditive implies that $a_n=\int f_n\,d\mu$ is a subadditive sequence in $\R$. Therefore, by Lemma~\ref{subadditive sequence limit}, the limit
\[L=\lim_n\frac{a_n}{n}=\inf_n\frac{a_n}{n}\]
exists. Define $f_+$ and $f_-$ through
\[f_-(x)=\varliminf_n\frac{f_n(x)}{n},\quad f_+(x)=\varlimsup_n\frac{f_n(x)}{n}.\]
Clearly, $f_-(x)\leq f_+(x)$ for every $x\in X$. We are going to prove 
\begin{align}\label{subadditive ergodic theorem-1}
\int f_-\,d\mu\geq L\geq\int f_+\,d\mu
\end{align}
as long as each function $f_n$ is bounded. Consequently, the two functions $f_-$ and $f_+$ coincide at $\mu$-almost every point and their integral is equal to $L$. Thus, the theorem will be proven in this case, with $f=f_+=f_-$.
\begin{lemma}
The functions $f_-$ and $f_+$ are $T$-invariant.
\end{lemma}
\begin{proof}
By the subadditivity, we have
\[f_-(x)\leq\varliminf_{n\to\infty}\frac{f_1(x)+f_{n-1}(Tx)}{n}=f_-(Tx).\]
In fact, it is a general fact that if a function $f$ satisfies $f\leq f\circ T$ then it is $T$-invariant. To see this, let $c\in\R$, then we get
\[T^{-1}(\{x:f(x)>c\})=\{x:f(T(x))>c\}\sub\{x:f(x)>c\}.\]
Since $\mu$ is invariant under $T$, we also have
\[\mu(\{x:f(x)>c\})=\mu(T^{-1}(\{x:f(x)>c\})).\]
Combining this two equations, we conclude that
\[\mu(\{x:f(x)-f(T(x))>c\})=0\]
for all $c\in\R$. This then means $f\circ T-f\equiv 0$, thus $f$ is invariant.
\end{proof}
\subsubsection{Birkhoff ergodic theorem}
For every integrable function $f\in L^1(\mu)$, we have note that the sequence
\[f_n=\sum_{i=0}^{n-1}f\circ T^i\]
is subadditive, we get the following consequence of subadditive ergodic theorem.
\begin{theorem}[\textbf{Birkhoff Ergodic Theorem}]
Let $T:X\to X$ be a measurable transformation and $\mu$ be a probability measure invariant under $T$. Given any integrable function $f:X\to\R$, the limit
\[\tilde{f}(x)=\lim_{n}\frac{1}{n}\sum_{i=0}^{n-1}f\circ T^i(x)\]
exists at $\mu$-almost every point $x\in X$. Moreover, the function $\tilde{f}$ defined in this way is $T$-invariant, integrable, and satisfies
\[\int\tilde{f}\,d\mu=\int f\,d\mu.\]
\end{theorem}
In particular, taking $f=\chi_E$ in the previous theorem, we get the following result for mean sojourn times:
\begin{theorem}[\textbf{Birkhoff}]
Let $T:X\to X$ be a measurable transformation and $\mu$ be a probability measure invariant under $T$. Given any measurable set $E\sub M$, the mean sojourn time
\[\tau(E,x):=\lim_n\frac{\#\{i=0,\dots,n-1:T^i(x)\in E\}}{n}=\lim_n\frac{1}{n}\sum_{i=0}^{n-1}\chi_E\circ T^i(x)\]
exists at $\mu$-almost every point $x\in X$. Moreover, $\int_X\tau(E,x)\,d\mu(x)=\mu(E)$.
\end{theorem}
\begin{example}
Consider the number $x\in(0,1)$ defined by the decimal expansion $x=0.a_1a_2\dots$, where
\[a_i=\begin{cases}
1&\text{if $2^k\leq i<2^{k+1}$ with $k$ even},\\
0&\text{if $2^k\leq i<2^{k+1}$ with $k$ odd}.
\end{cases}\]
In other words,
\[x=0.10011110000000011111111111111110\dots\]
where the lengths of the alternating blocks of $0$s and $1$s are given by successive powers of $2$. Let $T:[0,1]\to[0,1]$ be the transformation defined by $T(x)=10x$ mod $1$ and let $E=[0,1/10)$. That is, $E$ is the set of all points whose decimal expansion starts with the digit $0$. It is easy to check that if $n=2^k-1$ with $k$ even then
\[\frac{1}{n}\sum_{i=0}^{n-1}\chi_E(T^i(x))=\frac{2^1+2^3+\cdots+2^{k-1}}{2^k-1}=\frac{2}{3}.\]
On the other hand, if one takes $n=2^k-1$ with $k$ odd then
\[\frac{1}{n}\sum_{i=0}^{n-1}\chi_E(T^i(x))=\frac{2^1+2^3+\cdots+2^{k-2}}{2^k-1}=\frac{2}{3}.\]
\end{example}
The theorem of von Neumann may also be deduced directly from the theorem of Birkhoff, as we are going to explain.\par
Consider any $f\in L^2(\mu)$ and let $\tilde{f}$ be the corresponding time average. We start by showing that $\tilde{f}\in L^2(\mu)$ and its norm satisfies $\|\tilde{f}\|_2\leq\|f\|$. Indeed,
\[|\tilde{f}|\leq\lim_n\frac{1}{n}\sum_{i=0}^{n-1}|f\circ T^i|\quad\text{and hence}\quad|\tilde{f}|^2\leq\lim_n\Big(\frac{1}{n}\sum_{i=0}^{n-1}|f\circ T^i|\Big)^2.\]
Then, by Fatou's lemma,
\[\Big(\int|\tilde{f}|^2\,d\mu\Big)^{1/2}\leq\varliminf_n\Big[\int\Big(\frac{1}{n}\sum_{i=0}^{n-1}|f\circ T^i|\Big)^2\,d\mu\Big]^{1/2}.\]
We can use the Minkowski inequality to bound the sequence on the right-hand side from above:
\[\Big[\int\Big(\frac{1}{n}\sum_{i=0}^{n-1}|f\circ T^i|\Big)^{1/2}\,d\mu\Big]^2\leq\frac{1}{n}\sum_{i=0}^{n-1}\int|f\circ T^i|^2\,d\mu\Big]^{1/2}=\Big[\int|f|^2\,d\mu\Big]^{1/2}.\]
Thus we get $\|\tilde{f}\|_2\leq\|f\|_2<+\infty$.\par
Now let us show that $(1/n)\sum_{i=0}^{n-1}f\circ T^i$ converges to $\tilde{f}$ in $L^2(\mu)$. Initially, suppose that the function $f$ is bounded, that is, there exists $C>0$ such that $|f|\leq C$. Then,
\[\Big|\frac{1}{n}\sum_{i=0}^{n-1}f\circ T^i\Big|\leq C\]
for each $n$, and therefore $|\tilde{f}|\leq C$. Then we may use the dominated convergence theorem to conclude that
\[\lim_n\int\Big(\frac{1}{n}\sum_{i=0}^{n-1}f\circ T^i-\tilde{f}\Big)^2\,d\mu=\int\lim_n\Big(\frac{1}{n}\sum_{i=0}^{n-1}f\circ T^i-\tilde{f}\Big)^2\,d\mu=0.\]
In other words, $(1/n)\sum_{i=0}^{n-1}f\circ T^i$ converges to $\tilde{f}$ in the space $L^2(\mu)$. We are left to extend this conclusion to arbitrary functions $f$ in $L^2(\mu)$. For that, let us consider some sequence $\{\varphi_k\}$ of bounded functions such that $\{\varphi_k\}$ converges to $f$. Note that $\|(f-\phi_k)\circ T^i\|_2=\|f-\phi_k\|_2$ for every $i\geq 0$, because the measure $\mu$ is invariant. Thus,
\[\Big\|\frac{1}{n}\sum_{i=0}^{n-1}(f-\phi_k)\circ T^i\Big\|_2\leq\|f-\phi_k\|_2\to 0.\]
Observe also that $\tilde{f}-\tilde{\varphi}_k$ is the time average of the function $f-\varphi_k$. So, the argument in the previous paragraph gives the claim in the general case.
\begin{proposition}
The time average $\tilde{f}$ of any function $f\in L^2(\mu)$ coincides with the orthogonal projection $Pf$ of $f$ to the subspace of invariant functions.
\end{proposition}
\begin{proof}
On the one hand, von Neumann's ergodic theorem gives that $(1/n)\sum_{i=0}^{n-1}f\circ T^i$ converges to $Pf$ in $L^2(\mu)$. On the other hand, we have just shown that this sequence converges to $\tilde{f}$ in the space $L^2(\mu)$. So, by uniqueness of the limit, we see $\tilde{f}=Pf$.
\end{proof}
\begin{corollary}
If $T:X\to X$ is invertible then the time averages of any function $f\in L^2(\mu)$ relative to $T$ and to $T^{-1}$ coincide at $\mu$-almost every point.
\end{corollary}
\begin{proof}
The orthogonal projection of $f$ to the subspace of functions invariant under $T^{-1}$ coincides with the orthogonal projection of $f$ to the subspace of functions invariant under $T$.
\end{proof}
\subsection{Ergodicity}
Ergodicity is the natural notion of indecomposability in ergodic theory. The definition of ergodicity for $(X,\mathcal{A},\mu,T)$ means that it is impossible to split $X$ into two subsets of positive measure each of which is invariant under $T$.
\begin{definition}
A measure preserving transformation $T:X\to X$ of a probability space $(X,\mathcal{A},\mu)$ is \textbf{ergodic} if for any $A\in\mathcal{A}$,
\[T^{-1}(A)=A\Longrightarrow\mu(A)\in\{0,1\}.\]
\end{definition}
When the emphasis is on the map $T$ and we are studying different $T$ -invariant measures, we will also say that $\mu$ is an \textbf{ergodic measure} for $T$. 
\begin{example}
Let $T:[0,1]\to[0,1]$ be the decimal expansion transformation (that is, $T(x)=10x$ mod $1$), and $\mu$ be the Lebesgue measure. Clearly, the set $A=\Q\cap[0,1]$ of rational numbers is invariant. Other interesting examples are the sets of points $x=0.a_1a_2\dots$ in $[0,1]$ with prescribed proportions of digits $a_i$ with each value $k\in\{0,\dots,9\}$. More precisely, given any vector $p=(p_0,\dots,p_9)$ such that $p_i\geq 0$ for every $i$ and $\sum_ip_i=1$, define
\[A_p=\{x:\lim_n\frac{\#\{1\leq i\leq n:a_i=k\}}{n}=p_k\text{ for $k=0,\dots,9$}\}.\]
Observe that if $x=0.a_1a_2\dots$ then every point $y\in T^{-1}(x)$ may be written as $y=0.ba_1a_2\dots$ with $b\in\{0,\dots,9\}$. It is clear that the extra digit $b$ does not affect the proportion of digits with any of the values $0,\dots,9$ in the decimal expansion. Thus, $y\in A_p$ if and only if $x\in A_p$. This implies that $A_p$ is indeed invariant under $T$.
\end{example}
\begin{example}
Let $f:[0,1]\to\R$ be a function in $L^1(\mu)$. According to the ergodic theorem of Birkhoff, the time average $\tilde{f}$ is an invariant function. So, every level set of $\tilde{f}$ is an invariant set. Observe also that every invariant function is of this form: it is clear that if $f$ is invariant then it coincides with its time average $\tilde{f}$ at $\mu$-almost every point.
\end{example}
It is useful to have several different characterizations of ergodicity, and these are provided by the following propositions.
\begin{proposition}\label{ergodic iff invariant function constant}
Let $\mu$ be an invariant probability measure of a measurable transformation $T:X\to X$. The following conditions are all equivalent:
\begin{itemize}
\item[(\rmnum{1})] $T$ is ergodic.
\item[(\rmnum{2})] For every measurable set $E\sub X$ one has $\tau(E,x)=\mu(E)$ for $\mu$-almost every point.
\item[(\rmnum{3})] For every measurable set $E\sub X$ the function $\tau(E,x)$ is constant at $\mu$-almost every point.
\item[(\rmnum{4})] For every integrable function $f:X\to\R$ one has $\tilde{f}=\int f\,d\mu$ for $\mu$-almost every point.
\item[(\rmnum{5})] For every integrable function $f:X\to\R$ the time average $\tilde{f}:X\to\R$ is constant at $\mu$-almost every point.
\item[(\rmnum{6})] For every invariant integrable function $g:X\to\R$ one has $g(x)=\int g\,d\mu$ for $\mu$-almost every point.
\item[(\rmnum{7})] Every invariant integrable function $g:X\to\R$ is constant at $\mu$-almost every point.   
\end{itemize}
\end{proposition}
\begin{proof}
It is immediate that (\rmnum{2}) implies (\rmnum{3}), that (\rmnum{4}) implies (\rmnum{5}) and that (\rmnum{6}) implies (\rmnum{7}). It is also clear that (\rmnum{6}) implies (\rmnum{4}) and (\rmnum{7}) implies (\rmnum{5}), because the time average is an invariant function and we have
\[\int\tau(E,x)\,d\mu(x)=\mu(E).\]
Analogously, (\rmnum{4}) implies (\rmnum{2}) and (\rmnum{5}) implies (\rmnum{3}), because the mean sojourn time is a time average (of the characteristic function of $E$). We are left to prove the following implications:
(\rmnum{3}) implies (\rmnum{1}): Let $A\sub X$ be an invariant set. Then $\tau(A,x)=1$ for $\mu$-almost every $x\in A$ and $\tau(A,x)=0$ for $\mu$-almost every $x\in A^c$. Since $\tau(A,x)$ is assumed to be constant at $\mu$-almost every point, it follows that $\mu(A)=0$ or $\mu(A)=1$.\par
(\rmnum{1}) implies (\rmnum{6}): Let $g$ be an invariant integrable function. Then every level set
\[B_c:=\{x:g(x)\leq c\}\]
is an invariant set. So, the hypothesis implies that $\mu(B_c)=\{0,1\}$ for every $c\in\R$. Since $c\mapsto\mu(B_c)$ is non-decreasing, it follows that there exists $c_0\in\R$ such that $\mu(B_{c})=0$ for every $c<c_0$ and $\mu(B_{c})=1$ for every $c\geq c_0$. Then $g=c_0$ at $\mu$-almost every point. Hence, $\int g\,d\mu=c_0$ and $g=\int g\,d\mu$ at $\mu$-almost every point.
\end{proof}
\begin{proposition}\label{ergodic iff Koopman operator}
Let $\mu$ be an invariant probability measure of a measurable transformation $T:X\to X$. The following conditions are equivalent:
\begin{itemize}
\item[(\rmnum{1})] $T$ is ergodic.
\item[(\rmnum{2})] For any pair of measurable sets $A$ and $B$ one has
\[\lim_n\frac{1}{n}\sum_{i=0}^{n-1}\mu(T^{-i}(A)\cap B)=\mu(A)\mu(B).\] 
\item[(\rmnum{3})] For any functions $f\in L^p(\mu)$ and $g\in L^q(\mu)$, with $1/p+1/q=1$, one has
\[\lim_n\frac{1}{n}\sum_{i=0}^{n-1}\int(U_T^if)g\,d\mu=\int f\,d\mu\int g\,f\mu.\] 
\end{itemize}
\end{proposition}
\begin{proof}
It is clear that (\rmnum{3}) implies (\rmnum{2}): just take $f=\chi_A$ and $g=\chi_B$. To show that (\rmnum{2}) implies (\rmnum{1}), let $A$ be an invariant set. Taking $A=B$ in hypothesis (\rmnum{2}), we get that
\[\mu(A)=\lim_n\frac{1}{n}\sum_{i=0}^{n-1}\mu(T^{-i}(A))=\mu(A)^2,\]
which implies $\mu(A)=0$ or $\mu(A)=1$.\par
Now it suffices to prove that (\rmnum{1}) implies (\rmnum{3}). Consider any $f\in L^p(\mu)$ and $g\in L^q(\mu)$. By ergodicity and the ergodic theorem of Birkhoff we have that $(1/n)\sum_{i=0}^{n-1}U_T^if\to\int f\,d\mu$ at $\mu$-almost every point. Initially, assume that $|f|\leq k$ for some $k>1$. Then, for every $n\in\N$,
\[\Big|\Big(\frac{1}{n}\sum_{i=0}^{n-1}U_T^if\Big)g\Big|\leq k|g|.\]
So we may use the dominated convergence theorem to conclude that
\[\int\Big(\frac{1}{n}\sum_{i=0}^{n-1}U_T^if\Big)g\,d\mu\to\int f\,d\mu\int g\,d\mu.\]
This proves the claim when $f$ is bounded. All that is left to do is remove
this restriction. Given any $f\in L^p(\mu)$ and $k\geq 1$, define
\[f_k(x)=\begin{cases}
k&f(x)>k,\\
f(x)&f(x)\in[-n,n],\\
-k&f(x)<-k.
\end{cases}\]
Fix $\eps>0$. By the previous argument, for every $k\geq 1$ one has
\begin{align}\label{ergodic iff Koopman operator-1}
\Big|\int\Big(\frac{1}{n}\sum_{i=0}^{n-1}U_T^if\Big)g\,d\mu-\int f_k\,d\mu\int g\,d\mu\Big|<\eps
\end{align}
if $n$ is large enough (depending on $k$). Next, observe that $\|f_k-f\|_p\to 0$, so using the H\"older inequality we have that
\begin{align}\label{ergodic iff Koopman operator-2}
\Big|\int(f_k-f)\,d\mu\int g\,d\mu\Big|\leq\|f_k-f\|_p\Big|\int g\,d\mu\Big|<\eps
\end{align}
for every $k$ sufficiently large. Similarly,
\begin{equation}\label{ergodic iff Koopman operator-3}
\begin{aligned}
\Big|\int\Big(\frac{1}{n}\sum_{i=0}^{n-1}U_T^i(f_k-f)\Big)g\Big|&\leq\frac{1}{n}\sum_{i=0}^{n-1}\|U_T^i(f_k-f)\|_p\|g\|_q=\|f_k-f\|_p\|g\|_q<\eps
\end{aligned}
\end{equation}
for every $n$ and every $k$ sufficiently large, independent of $n$. Fix $k$ so that $(\ref{ergodic iff Koopman operator-2})$ and $(\ref{ergodic iff Koopman operator-3})$ hold and then take $n$ sufficiently large such that $(\ref{ergodic iff Koopman operator-1})$ also holds, we then get that
\[\Big|\int\Big(\frac{1}{n}\sum_{i=0}^{n-1}U_T^if\Big)g\,d\mu-\int f\,d\mu\int g\,d\mu\Big|<3\eps\]
for every $n$ sufficiently large. This gives condition (\rmnum{3}).
\end{proof}
\begin{proposition}\label{ergodic iff preimage has full measure}
Let $\mu$ be an invariant probability measure of a measurable transformation $T:X\to X$. Then the following are equivalent:
\begin{itemize}
\item[(\rmnum{1})] $T$ is ergodic.
\item[(\rmnum{2})] For any measurable subset $A\sub X$, $\mu(A\Delta T^{-1}(A))=0$ implies $\mu(A)=0$ or $\mu(A)=1$.
\item[(\rmnum{3})] For each measurable subset $E\sub X$, $\mu(E)>0$ implies that $\mu(\bigcup_{n=1}^{\infty}T^{-n}(E))=1$.
\end{itemize}
\end{proposition}
\begin{proof}
It is clear that (\rmnum{2}) implies (\rmnum{1}). To show the converse, assume that $T$ is ergodic, and let $A$ be an almost invariant measurable set---that is, a measurable set $A$ with $\mu(A\Delta T^{-1}(A))=0$. We wish to construct an invariant set from $A$, and this is achieved by means of the following limsup construction. Let $\tilde{A}=\varlimsup_nT^{-n}(A)$. Then for each $m\geq 0$, we have
\[\Big(\bigcup_{n=m}^{\infty}T^{-n}(A)\Big)\Delta A\sub\bigcup_{n=m}^{\infty}T^{-n}(A)\Delta A\sub\bigcup_{n=m}^{\infty}\bigcup_{i=0}^{n-1}T^{-i}(A)\Delta T^{-(i+1)}(A),\]
hence $\mu(A\Delta\bigcup_{n=m}^{\infty}T^{-n}(A))=0$ for each $m$, which implies $\mu(A\Delta\tilde{A})=0$. Now
\[T^{-1}(\tilde{A})=\bigcap_{m=0}^{\infty}\bigcup_{n=m}^{\infty}T^{-(n+1)}(A)=\bigcap_{m=0}^{\infty}\bigcup_{n=m+1}^{\infty}T^{-n}(A)=\tilde{A},\]
so by ergodicity $\mu(\tilde{A})=0$ or $\mu(\tilde{A})=1$. Since $\mu(A)=\mu(\tilde{A})$, this implies condition (\rmnum{2}).\par
Now we prove the implication (\rmnum{2})$\Rightarrow$(\rmnum{3}). Let $E$ be a measurable subset with positive measure, and let $A=\bigcup_{n=1}^{\infty}T^{-n}(E)$. Since $\mu(T^{-1}(A))=\mu(A)$ and $T^{-1}(A)\sub A$, we then get $\mu(A\Delta T^{-1}(A))=0$, and therefore $\mu(A)=0$ or $\mu(A)=1$. Since $T^{-1}(E)\sub A$, the former case is impossible, so $\mu(A)=1$ as required.\par
Finally, assume (\rmnum{3}). Then for an invariant subset $A$ we have $\mu(\bigcup_{n=1}^{\infty}T^{-n}(A))=A$, so $\mu(A)=0$ or $1$. This proves $T$ is ergodic.
\end{proof}
Now we use a number of examples to illustrate different methods for checking whether a system is ergodic or not.
\begin{example}\label{rotation on torus erdogic}
Let us consider the case of a rotation $R_\theta:S^1\to S^1$ on the circle $S^1=\R/\Z$. As we have observed, the angular measure $\mu=d\theta$ is invariant under $R_\theta$. We want to analyze the ergodic behavior of the system $(R_\theta,\mu)$ for different values of $\theta$.\par
If $\theta$ is rational, say $\theta=p/q$ in irreducible form, $R_\theta^q(x)=x$ for every $x\in S^1$. Then, given any segment $I\sub S^1$ with length less than $1/q$, the set
\[A=I\cup R_\theta(I)\cup\cdots\cup R_\theta^{q-1}(I)\]
is invariant under $R_\theta$ and its measure satisfies $0<\mu(A)<1$. Thus, if $\theta$ is rational then the angular measure $\mu$ is not ergodic.\par
Now assume that $\theta$ is rational. We will see that $\mu$ is ergodic in this case. First, lets recall that the functions $\{e^{2\pi inx}:n\in\Z\}$ is a basis for the Hilbert space $L^2(\mu)$. Assume that $f$ is invariant. Then we have
\[f(x)=\sum_{n\in\Z}a_ne^{2\pi inx},\quad f(R_\theta(x))=\sum_{n\in\Z}a_n e^{2\pi in\theta}e^{2\pi in x}.\]
Since $f=f\circ R_\theta$ almost everywhere, we then get $a_n=e^{2\pi in\theta}a_n$ for each $n\in\Z$. The hypothesis that $\theta$ is irrational means that $e^{2\pi in\theta}\neq 1$ for every $n\neq 0$. Hence, the relation that we just obtained implies that $a_n=0$ for every $n\neq 0$. In other words, $f(z)=a_0$ for $\mu$-almost every $x\in S^1$. This proves that every invariant $L^2$ function is constant $\mu$-almost everywhere. In particular, the characteristic function $\chi_A$ of any invariant set $A\sub S^1$ is constant at $\mu$-almost every point. By Proposition~\ref{ergodic iff invariant function constant}, this implies $\mu$ is ergodic.\par
If $\theta=(\theta_1,\dots,\theta_d)\in\R^d$, we say $\theta$ is \textbf{rationally independent} if $1,\theta_1,\dots,\theta_d$ are linearly independent over $\Z$. A similar argument can be used to show that, if $\theta\in\R^d$ is rationally independent then the rotation $R_\theta:\T^d\to T^d$ is ergodic relative to the angular measure $\mu$.\par
In fact, the irrational rotations on the circle or, more generally, on any torus have a much stronger property than ergodicity: they are uniquely ergodic, meaning that they admit a unique invariant probability measure. 
\end{example}
\begin{example}\label{decimal expansion erdogic}
Consider the transformation $T:[0,1]\to[0,1]$ given by $T(x)=10x-[10x]$. We have seen that $T$ preserves the Lebesgue measure $\lambda$. We now show that $T$ is ergodic relative to the Lebesgue measure $\lambda$. For this, it suffices to prove that every invariant set $A$ has total measure. The main ingredient is the derivation theorem, according to which almost every point of $A$ is a Lebesgue density point of $A$. More precisely, $\lambda$-almost every point $x\in A$ satisfies
\begin{align}
\lim_{\eps\to 0^+}\Big\{\frac{\lambda(I\cap A)}{\lambda(I)}:\text{$I$ is an interval such that $x\in I$ with diameter smaller than $\eps$}\Big\}=1.
\end{align}
Let us fix a density point $x\in A$. Since the set of points of the form $m/10^k$, $k\in\N$, $0\leq m<\leq 10^k$ has zero measure, it is no restriction to suppose that $A$ is not of that form. Let us consider the family of intervals
\[I(k,m)=\Big(\frac{m-1}{10^k},\frac{m}{10^k}\Big),\quad k\in\N,0\leq m\leq 10^k.\]
It is clear that for each $k\in\N$ there exists a unique $m=m_k$ such that $I(k,m_k)$ contains the point $x$. Denote $I_k=I(k,m_k)$. The property $()$ implies that
\[\lim_{k\to\infty}\frac{\lambda(I_k\cap A)}{\lambda(I_k)}=1.\]
Observe also that each $T^k$ is an affine bijection from $I_k$ to the interval $(0,1)$. This has the following immediate consequence, which is crucial for our argument: For every $k\in\N$, one has
\[\frac{\lambda(T^k(E_1))}{\lambda(T^k(E_2))}=\frac{\lambda(E_1)}{\lambda(E_2)}\]
for any measurable subsets $E_1$ and $E_2$ of $I_k$. Applying this fact to $E_1=I_k\cap A$ and $E_2=I_k$ we find that
\[\frac{\lambda(T^k(I_k\cap A))}{\lambda((0,1))}=\frac{\lambda(I_k\cap A)}{\lambda(I_k)}.\]
Clearly, $\lambda((0,1))=1$. Moreover, as we take $A$ to be invariant, $T^k(I_k\cap A)$ is contained in $A$. In this way we get that
\[\lambda(A)\geq\frac{\lambda(I_k\cap A)}{\lambda(I_k)}\]
for every $k$. Since the sequence on the right-hand side converges to $1$ when $k\to\infty$, it follows that $\lambda(A)=1$, as we wanted to prove.
\end{example}
\begin{example}
As we have seen, the gauss map $G(x)=1/x-[1/x]$ has an invariant probability measure $\mu$ equivalent to the Lebesgue measure, namely:
\[\mu(E)=\int_E\frac{dx}{1+x}.\]
Now we prove the system $(G,\mu)$ is ergodic. Let $A$ be an invariant set with positive measure. We want to show that $\mu(A)=1$. On the one hand, it remains true that for almost every point $x\in[0,1]$ there exists a sequence of intervals $I_k$ containing $x$ and such that $G_k$ maps $I_k$ bijectively and differentiably onto $(0,1)$. Indeed, such intervals can be found as follows. First, consider
\[I(1,m)=\Big(\frac{1}{m+1},\frac{1}{m}\Big)\]
for each $m\geq 1$. Next, define, by recurrence,
\[I(k,m_1,\dots,m_k)=I(1,m_1)\]
\end{example}

